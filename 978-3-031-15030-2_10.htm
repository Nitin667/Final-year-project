

<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="applicable-device" content="pc,mobile">
    <meta name="access" content="Yes">

    
    
    <meta name="twitter:site" content="SpringerLink"/>
    <meta name="twitter:card" content="summary"/>
    <meta name="twitter:image:alt" content="Content cover image"/>
    <meta name="twitter:title" content="Android Malware Detection Using Deep Learning"/>
    <meta name="twitter:description" content="This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode..."/>
    <meta name="twitter:image" content="https://static-content.springer.com/cover/book/978-3-031-15030-2.jpg"/>
    <meta name="dc.identifier" content="10.1007/978-3-031-15030-2_10"/>
    <meta name="DOI" content="10.1007/978-3-031-15030-2_10"/>
    <meta name="dc.description" content="This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode..."/>
    <meta name="citation_pdf_url" content="https://link-springer-com.vtutest.mapmyaccess.com/content/pdf/10.1007/978-3-031-15030-2_10.pdf"/>
    <meta name="citation_fulltext_html_url" content="https://link-springer-com.vtutest.mapmyaccess.com/chapter/10.1007/978-3-031-15030-2_10"/>
    <meta name="citation_abstract_html_url" content="https://link-springer-com.vtutest.mapmyaccess.com/chapter/10.1007/978-3-031-15030-2_10"/>
    <meta name="citation_inbook_title" content="Artificial Intelligence and Cybersecurity"/>
    <meta name="citation_title" content="Android Malware Detection Using Deep Learning"/>
    <meta name="citation_publication_date" content="2023"/>
    <meta name="citation_firstpage" content="209"/>
    <meta name="citation_lastpage" content="246"/>
    <meta name="citation_language" content="en"/>
    <meta name="citation_doi" content="10.1007/978-3-031-15030-2_10"/>
    <meta name="size" content="311147"/>
    <meta name="description" content="This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode..."/>
    <meta name="citation_author" content="Millar, Stuart"/>
    <meta name="citation_author_email" content="stuart_millar@rapid7.com"/>
    <meta name="citation_author_institution" content="Rapid 7 LLC"/>
    <meta name="citation_author" content="McLaughlin, Niall"/>
    <meta name="citation_author_email" content="n.mclaughlin@qub.ac.uk"/>
    <meta name="citation_author_institution" content="CSIT, Queen’s University Belfast"/>
    <meta name="citation_author" content="Rincon, Jesus Martinez del"/>
    <meta name="citation_author_email" content="j.martinez-del-rincon@qub.ac.uk"/>
    <meta name="citation_author_institution" content="CSIT, Queen’s University Belfast"/>
    <meta name="citation_author" content="Miller, Paul"/>
    <meta name="citation_author_email" content="p.miller@qub.ac.uk"/>
    <meta name="citation_author_institution" content="CSIT, Queen’s University Belfast"/>
    <meta name="citation_publisher" content="Springer, Cham"/>
    <meta name="citation_springer_api_url" content="http://api.springer-com.vtutest.mapmyaccess.com/xmldata/jats?q=doi:10.1007/978-3-031-15030-2_10&amp;api_key="/>
    <meta name="format-detection" content="telephone=no"/>
    

    
    
    <meta property="og:url" content="https://link-springer-com.vtutest.mapmyaccess.com/chapter/10.1007/978-3-031-15030-2_10"/>
    <meta property="og:type" content="Paper"/>
    <meta property="og:site_name" content="SpringerLink"/>
    <meta property="og:title" content="Android Malware Detection Using Deep Learning"/>
    <meta property="og:description" content="This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode..."/>
    <meta property="og:image" content="https://static-content.springer.com/cover/book/978-3-031-15030-2.jpg"/>
    


    <title>Android Malware Detection Using Deep Learning | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    
    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) { a{text-decoration:underline;text-decoration-skip-ink:auto}html{text-size-adjust:100%;-webkit-font-smoothing:subpixel-antialiased;box-sizing:border-box;color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:100%;height:100%;line-height:1.61803;overflow-y:scroll}body{background:#fcfcfc;font-size:1.125rem;line-height:1.5;max-width:100%;min-height:100%}article,aside,header,main,nav,section{display:block}h1{font-size:2em;margin:.67em 0}a{background-color:transparent;color:#004b83;overflow-wrap:break-word;word-break:break-word}sup{font-size:75%;line-height:0;position:relative;top:-.5em;vertical-align:baseline}img{border:0;height:auto;max-width:100%;vertical-align:middle}svg:not(:root){overflow:hidden}button,input{font-family:sans-serif;font-size:100%}input{line-height:1.15}button,input{overflow:visible}button{text-transform:none}[type=submit],button,html [type=button]{-webkit-appearance:button}[hidden]{display:none}button{border-radius:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;line-height:inherit}h1,h2{font-family:Georgia,Palatino,serif;font-weight:400}h1{font-size:2.25rem}.u-h3,h1{font-style:normal;margin-bottom:1em}.u-h3{font-family:Georgia,Palatino,serif;font-weight:400;line-height:1.4}.u-h3,h2{font-size:1.75rem}.u-h3{font-size:1.5rem}h2{font-style:normal;margin-bottom:1em}label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}*{box-sizing:inherit}body,button,div,form,input{margin:0;padding:0}p{padding:0}h1,h2{line-height:1.4}p{margin:0}h1,h2,ul{margin-top:0}p{margin-bottom:1.5em;overflow-wrap:break-word;word-break:break-word}p:last-child{margin-bottom:0}p:empty{display:none}.c-app-header__theme{border-top-left-radius:2px;border-top-right-radius:2px;height:50px;margin:-16px -16px 0;overflow:hidden;position:relative}@media only screen and (min-width:1024px){.c-app-header__theme:after{background-color:hsla(0,0%,100%,.15);bottom:0;content:"";position:absolute;right:0;top:0;width:456px}}.c-app-header__content{padding-top:16px}@media only screen and (min-width:1024px){.c-app-header__content{display:flex}}.c-app-header__main{display:flex;flex:1 1 auto}.c-app-header__cover{margin-right:16px;margin-top:-50px;position:relative;z-index:5}.c-app-header__cover img{border:2px solid #fff;border-radius:4px;box-shadow:0 0 5px 2px hsla(0,0%,50%,.2);max-height:125px;max-width:96px}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}.c-ad--728x90 iframe{height:90px;max-width:970px}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}.js .u-show-following-ad+.c-ad--728x90{display:block}}.c-ad iframe{border:0;overflow:auto;vertical-align:top}.c-ad__label{color:#333;font-weight:400;line-height:1.5;margin-bottom:4px}.c-ad__label,.c-skip-link{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem}.c-skip-link{background:#f7fbfe;bottom:auto;color:#004b83;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#004b83}.c-pagination{align-items:center;display:flex;flex-wrap:wrap;font-size:.875rem;list-style:none;margin:0;padding:16px}@media only screen and (min-width:540px){.c-pagination{justify-content:center}}.c-pagination__item{margin-bottom:8px;margin-right:16px}.c-pagination__item:last-child{margin-right:0}.c-pagination__link{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;min-width:30px;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link svg,.c-pagination__link--disabled svg{fill:currentcolor}.c-pagination__link:visited{color:#004b83}.c-pagination__link:focus,.c-pagination__link:hover{border:1px solid #666;text-decoration:none}.c-pagination__link:focus,.c-pagination__link:hover{background-color:#666;background-image:none;color:#fff}.c-pagination__link:focus svg path,.c-pagination__link:hover svg path{fill:#fff}.c-pagination__link--disabled{align-items:center;background-color:transparent;background-image:none;border-radius:2px;color:#333;cursor:default;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;opacity:.67;padding:8px;position:relative;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.c-pagination__link--disabled:visited{color:#333}.c-pagination__link--disabled,.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{border:1px solid #ccc;text-decoration:none}.c-pagination__link--disabled:focus,.c-pagination__link--disabled:hover{background-color:transparent;background-image:none;color:#333}.c-pagination__link--disabled:focus svg path,.c-pagination__link--disabled:hover svg path{fill:#333}.c-pagination__link--active{background-color:#666;background-image:none;border-color:#666;color:#fff;cursor:default}.c-pagination__ellipsis{background:0 0;border:0;min-width:auto;padding-left:0;padding-right:0}.c-pagination__icon{fill:#999;height:12px;width:16px}.c-pagination__icon--active{fill:#004b83}.c-box{background-color:#fff;border:1px solid #ccc;border-radius:2px;line-height:1.3;padding:16px}.c-box--shadowed{box-shadow:0 0 5px 0 hsla(0,0%,50%,.1)}.c-header{background-color:#fff;border-bottom:4px solid #00285a;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;padding:16px 0}.c-header__container,.c-header__menu{align-items:center;display:flex;flex-wrap:wrap}@supports (gap:2em){.c-header__container,.c-header__menu{gap:2em 2em}}.c-header__menu{list-style:none;margin:0;padding:0}.c-header__item{color:inherit}@supports not (gap:2em){.c-header__item{margin-left:24px}}.c-header__container{justify-content:space-between;margin:0 auto;max-width:1280px;padding:0 16px}@supports not (gap:2em){.c-header__brand{margin-right:32px}}.c-header__brand a{display:block;text-decoration:none}.c-header__link{color:inherit}.c-popup-search{background-color:#eee;box-shadow:0 3px 3px -3px rgba(0,0,0,.21);padding:16px 0;position:relative;z-index:10}@media only screen and (min-width:1024px){.js .c-popup-search{position:absolute;top:100%;width:100%}.c-popup-search__container{margin:auto;max-width:70%}}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin-bottom:16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg{margin:1px 4px 0 0}.c-article-author-list__button:hover{background:#069;border-color:transparent;color:#fff}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:0 0 16px}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-main-column{font-family:Georgia,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-code-block{border:1px solid #f2f2f2;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-associated-content__container .c-article-associated-content__collection-label{line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fcfcfc;border-bottom:1px solid #fcfcfc;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__section-item .c-article-section__title-number{display:none}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff}.c-pdf-download__link .u-icon{padding-top:2px}.save-data .c-article-author-institutional-author__sub-division,.save-data .c-article-equation__number,.save-data .c-article-figure-description,.save-data .c-article-fullwidth-content,.save-data .c-article-main-column,.save-data .c-article-satellite-article-link,.save-data .c-article-satellite-subtitle,.save-data .c-article-table-container,.save-data .c-blockquote__body,.save-data .c-code-block__heading,.save-data .c-reading-companion__figure-title,.save-data .c-reading-companion__reference-citation,.save-data .c-site-messages--nature-briefing-email-variant .serif,.save-data .c-site-messages--nature-briefing-email-variant.serif,.save-data .serif,.save-data .u-serif,.save-data h1,.save-data h2,.save-data h3{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%;padding:13px 24px!important}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container{flex-wrap:wrap;width:100%}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}.app-search__content{display:flex}.app-search__label{color:#666;display:inline-block;font-size:.875rem;margin-bottom:8px}.app-search__input{border:1px solid #b3b3b3;border-bottom-left-radius:3px;border-top-left-radius:3px;box-shadow:inset 0 1px 3px 0 rgba(0,0,0,.21);flex:0 1 auto;font-size:.875rem;line-height:1.2;padding:.75em 1em;vertical-align:middle;width:100%}.app-search__button{align-items:center;background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);border-radius:0 2px 2px 0;color:#fff;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-align:center;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:50px}.app-search__button svg,.u-button svg,.u-button--primary svg{fill:currentcolor}.u-button{align-items:center;background-color:#f2f2f2;background-image:linear-gradient(#fff,#f2f2f2);border:1px solid #ccc;border-radius:2px;color:#004b83;cursor:pointer;display:inline-flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#33629d;background-image:linear-gradient(#4d76a9,#33629d);border:1px solid rgba(0,59,132,.5);color:#fff}.u-button--full-width{display:flex;width:100%}.u-clearfix:after,.u-clearfix:before{content:"";display:table}.u-clearfix:after{clear:both}.u-display-block{display:block}.u-display-flex{display:flex;width:100%}.u-align-items-center{align-items:center}.u-justify-content-space-between{justify-content:space-between}.u-flex-shrink{flex:0 1 auto}.u-flex-static{flex:0 0 auto}.u-display-none{display:none}.js .u-js-hide{display:none;visibility:hidden}@media print{.u-hide-print{display:none}}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-list-reset{list-style:none;margin:0;padding:0}.u-button-reset{background-color:transparent;border:0;padding:0}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-position-relative{position:relative}.u-mt-0{margin-top:0}.u-mr-24{margin-right:24px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.u-ml-8{margin-left:8px}.u-float-left{float:left}.u-hide{display:none;visibility:hidden}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.u-text-sm{font-size:1rem}.u-text-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.hide{display:none;visibility:hidden}.visually-hidden{clip:rect(1px,1px,1px,1px);height:1px;position:absolute!important;width:1px}.c-article-section__content p{line-height:1.8}.c-pagination__input{border:1px solid #bfbfbf;border-radius:2px;box-shadow:inset 0 2px 6px 0 rgba(51,51,51,.2);box-sizing:initial;display:inline-block;height:28px;margin:0;max-width:64px;min-width:16px;padding:0 8px;text-align:center;transition:width .15s ease 0s}.c-pagination__input::-webkit-inner-spin-button,.c-pagination__input::-webkit-outer-spin-button{-webkit-appearance:none;margin:0}.c-article-associated-content__container .c-article-associated-content__collection-label{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.063rem}.c-article-associated-content__container .c-article-associated-content__collection-title{font-size:1.063rem;font-weight:400}.c-reading-companion__sections-list{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-section__title,.c-article-title{font-weight:400}.c-chapter-book-series{font-size:1rem}.c-chapter-identifiers{margin:16px 0 8px}.c-chapter-book-details{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative}.c-chapter-book-details__title{font-weight:700}.c-chapter-book-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-chapter-book-details a{color:inherit}@media only screen and (max-width:539px){.c-chapter-book-details__meta{display:block}}.c-header__cart-icon{margin-right:12px}.c-header__navigation{display:flex}.c-cover-image-lightbox{align-items:center;bottom:0;display:flex;justify-content:center;left:0;opacity:0;position:fixed;right:0;top:0;transition:all .15s ease-in 0s;visibility:hidden;z-index:-1}.js-cover-image-lightbox--close{background:0 0;border:0;color:#fff;cursor:pointer;font-size:1.875rem;padding:13px;position:absolute;right:10px;top:0}.c-cover-image-lightbox__image{max-height:90vh;width:auto}.c-expand-overlay{background:#fff;color:#333;opacity:.5;padding:2px;position:absolute;right:3px;top:3px} }</style>
    <link rel="stylesheet" data-test="critical-css-handler" data-inline-css-source="critical-css" href="/oscar-static/app-springerlink/css/enhanced-article-9314391185.css" media="print" onload="this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null">


    
    <script>
        window.dataLayer = [{"GA Key":"UA-26408784-1","DOI":"10.1007/978-3-031-15030-2_10","Page":"chapter","page":{"attributes":{"environment":"live"}},"Country":"IN","japan":false,"doi":"10.1007-978-3-031-15030-2_10","Keywords":"","kwrd":[],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"N","hasAccess":"N","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"pw-vgzm.415900-10.1007-978-3-031-15030-2","Full HTML":"N","session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{},"book":{"doi":"10.1007/978-3-031-15030-2","title":"Artificial Intelligence and Cybersecurity","pisbn":"978-3-031-15029-6","eisbn":"978-3-031-15030-2","bookProductType":"ContributedVolume"},"chapter":{"doi":"10.1007/978-3-031-15030-2_10"},"type":"Chapter","category":{"pmc":{"primarySubject":"Computer Science","primarySubjectCode":"SCI","secondarySubjects":{"1":"Artificial Intelligence","2":"Privacy","3":"Cryptology","4":"Mobile and Network Security"},"secondarySubjectCodes":{"1":"SCI21000","2":"SCI28010","3":"SCI28020","4":"SCI28050"}},"sucode":"SUCO11645"},"attributes":{"deliveryPlatform":"oscar"},"country":"IN","Has Preview":"N","subjectCodes":"SCI,SCI21000,SCI28010,SCI28020,SCI28050","PMC":["SCI","SCI21000","SCI28010","SCI28020","SCI28050"]},"Event Category":"Chapter","ConferenceSeriesId":"","productId":"9783031150302"}];
    </script>

    <script>
    window.dataLayer.push({
        ga4MeasurementId: 'G-B3E4QL2TPR',
        ga360TrackingId: 'UA-26408784-1',
        twitterId: 'o47a7',
        ga4ServerUrl: 'https://collect.springer-com.vtutest.mapmyaccess.com',
        imprint: 'springerlink'
    });
</script>

    <script data-test="gtm-head">
    window.initGTM = function() {
        if (window.config.mustardcut) {
            (function (w, d, s, l, i) {
                w[l] = w[l] || [];
                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                var f = d.getElementsByTagName(s)[0],
                        j = d.createElement(s),
                        dl = l != 'dataLayer' ? '&l=' + l : '';
                j.async = true;
                j.src = 'https://collect.springer-com.vtutest.mapmyaccess.com/gtm.js?id=' + i + dl;
                f.parentNode.insertBefore(j, f);
            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');
        }
    }
</script>
    <script>
    (function(w,d,t) {
        function cc() {
            var h = w.location.hostname;
            var e = d.createElement(t),
                    s = d.getElementsByTagName(t)[0];

            if (h.indexOf('springer-com.vtutest.mapmyaccess.com') > -1) {
                e.src = 'https://cmp-static.springer-com.vtutest.mapmyaccess.com/production_live/consent-bundle-17-26.js';
                e.setAttribute('onload', "initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')");
            } else {
                e.src = '/static/js/lib/cookie-consent.min.js';
                e.setAttribute('data-consent', h);
            }
            s.insertAdjacentElement('afterend', e);
        }

        cc();
    })(window,document,'script');
</script>

    <script>
    (function(w, d) {
        w.config = w.config || {};
        w.config.mustardcut = false;

        
        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {
            w.config.mustardcut = true;
            d.classList.add('js');
            d.classList.remove('grade-c');
        }
    })(window, document.documentElement);
</script>

    
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>


    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
                window.suppressShareButton = false;
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-1b7e24bf66.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-b5b00885bf.js', 'async': false},
            ];

            var bodyScripts = [
                
                    {'src': '/oscar-static/js/app-es5-bundle-bd11d7e283.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/app-es6-bundle-85e2a51854.js', 'async': false, 'module': true}
                
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-44b22c1a09.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-30815be4d0.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link-springer-com.vtutest.mapmyaccess.com/chapter/10.1007/978-3-031-15030-2_10"/>
    

    
    <script type="application/ld+json">{"headline":"Android Malware Detection Using Deep Learning","pageEnd":"246","pageStart":"209","image":"https://media.springernature.com/w153/springer-static/cover/book/978-3-031-15030-2.jpg","genre":["Computer Science","Computer Science (R0)"],"isPartOf":{"name":"Artificial Intelligence and Cybersecurity","isbn":["978-3-031-15030-2","978-3-031-15029-6"],"@type":"Book"},"publisher":{"name":"Springer International Publishing","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Millar, Stuart","affiliation":[{"name":"Rapid 7 LLC","address":{"name":"Rapid 7 LLC, Boston, USA","@type":"PostalAddress"},"@type":"Organization"}],"email":"stuart_millar@rapid7.com","@type":"Person"},{"name":"McLaughlin, Niall","affiliation":[{"name":"CSIT, Queen’s University Belfast","address":{"name":"CSIT, Queen’s University Belfast, Belfast, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Rincon, Jesus Martinez del","affiliation":[{"name":"CSIT, Queen’s University Belfast","address":{"name":"CSIT, Queen’s University Belfast, Belfast, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Miller, Paul","affiliation":[{"name":"CSIT, Queen’s University Belfast","address":{"name":"CSIT, Queen’s University Belfast, Belfast, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"}],"keywords":"","description":"This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode sequences from disassembled programs and other complementary features such as API calls and permissions, with features indicative of malware automatically learned by the network. This removes the need for hand-engineered malware features while performing classification. Using the Drebin and AMD benchmark datasets, the benefits of this multi-view architecture to combine multiple feature sources are demonstrated in our findings. We conclude the use of deep learning architectures enables state-of-art results in automatic malware detection, while reducing the dependency on feature engineering and domain expertise. Using multi-view compared to single-view architectures improves performance through exposure to simultaneous sources of information, learning a more effective set of features. The model achieves state-of-the art detection performance in a challenging zero-day scenario, reducing false positives by 77% in relative terms on average, an important metric for potential real-world deployment.","datePublished":"2023","isAccessibleForFree":false,"hasPart":{"isAccessibleForFree":false,"cssSelector":".main-content","@type":"WebPageElement"},"@type":"ScholarlyArticle","@context":"https://schema.org"}</script>

</head>
<body class="shared-article-renderer">
    
    
    
        
            <!-- Google Tag Manager (noscript) -->
            <noscript data-test="gtm-body">
                <iframe src="https://collect.springer-com.vtutest.mapmyaccess.com/ns.html?id=GTM-MRVXSHQ"
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
            </noscript>
            <!-- End Google Tag Manager (noscript) -->
        
    


    <div class="u-vh-full">
        <a class="c-skip-link" href="#main-content">Skip to main content</a>
        
            <div class="u-hide u-show-following-ad"></div>
            <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
                <div class="c-ad__inner">
                    <p class="c-ad__label">Advertisement</p>
                    <div id="div-gpt-ad-LB1" data-pa11y-ignore data-gpt data-test="LB1-ad"
                         data-gpt-unitpath="/270604982/springerlink/book/chapter" data-gpt-sizes="728x90"
                         style="min-width:728px;min-height:90px" data-gpt-targeting="pos=LB1;"></div>
                </div>
            </aside>


<div class="u-position-relative u-mbs-0">
        <header class="c-header u-mb-24" data-test="publisher-header">
    
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-6c9a864b59.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                <span>Search</span>
                <svg class="u-icon u-flex-static u-ml-8" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>

        <div class="c-header__cart-icon">
            <div id="ecommerce-header-cart-icon-link" class="c-header__item ecommerce-cart" style="display:inline-block;margin-right:10px">
 <form action="https://order.springer-com.vtutest.mapmyaccess.com/public/precheckout" method="post">
  <button class="c-header__link" type="submit" style="appearance:none;border:none;background:none;color:inherit;position:relative">
   <svg aria-hidden="true" focusable="false" height="18" viewbox="0 0 18 18" width="18" xmlns="http://www.w3.org/2000/svg" style="vertical-align:text-bottom">
    <path d="m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z" fill="#333"></path>
   </svg><span class="u-screenreader-only visually-hidden">Go to cart</span><span class="cart-info" style="display:none;position:absolute;top:-4px;right:-10px;background-color:#C40606;color:#fff;width:18px;height:18px;font-size:11px;border-radius:50%;line-height:17.5px;text-align:center"></span></button>
 </form>
 <script>(function () { var exports = {}; if (window.fetch) {
            
            "use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.headerWidgetClientInit = void 0;
var headerWidgetClientInit = function (getCartInfo) {
    console.log("listen to updatedCart event");
    document.body.addEventListener("updatedCart", function () {
        console.log("updatedCart happened");
        updateCartIcon().then(function () { return console.log("Cart state update upon event"); });
    }, false);
    return updateCartIcon().then(function () { return console.log("Initial cart state update"); });
    function updateCartIcon() {
        return getCartInfo()
            .then(function (res) { return res.json(); })
            .then(refreshCartState)
            .catch(function () { return console.log("Could not fetch cart info"); });
    }
    function refreshCartState(json) {
        var indicator = document.querySelector("#ecommerce-header-cart-icon-link .cart-info");
        /* istanbul ignore else */
        if (indicator && json.itemCount) {
            indicator.style.display = 'block';
            indicator.textContent = json.itemCount > 9 ? '9+' : json.itemCount.toString();
            var moreThanOneItem = json.itemCount > 1;
            indicator.setAttribute('title', "there ".concat(moreThanOneItem ? "are" : "is", " ").concat(json.itemCount, " item").concat(moreThanOneItem ? "s" : "", " in your cart"));
        }
        return json;
    }
};
exports.headerWidgetClientInit = headerWidgetClientInit;

            
            headerWidgetClientInit(
              function () {
                return window.fetch("https://cart.springer-com.vtutest.mapmyaccess.com/cart-info", {
                  credentials: "include",
                  headers: { Accept: "application/json" }
                })
              }
            )
        }})()</script>
</div>
        </div>

        <nav>
            <ul class="c-header__menu">
                
        
            <li class="c-header__item">
                <a
                    data-test="login-link"
                    class="c-header__link"
                    href="https://link-springer-com.vtutest.mapmyaccess.com/signup-login?previousUrl=https%3A%2F%2Flink-springer-com.vtutest.mapmyaccess.com%2Fchapter%2F10.1007%2F978-3-031-15030-2_10"
                    data-track="click"
                    data-track-category="header"
                    data-track-action="login header"
                    data-track-label="link">Log in</a>
            </li>
        

        


            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        
            <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
                <div class="c-popup-search__content">
                    <div class="u-container">
                        <div class="c-popup-search__container" data-test="springerlink-popup-search">
                            <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                        </div>
                    </div>
                </div>
            </div>
        
    
</div>

        

<div class="u-container u-mb-32 u-clearfix" id="main-content" data-component="article-container">
    
    <div class="u-hide-at-lg js-context-bar-sticky-point-mobile">
        
    </div>
    

    <header class="u-mb-24" data-test="chapter-information-header">
        <div class="c-box c-box--shadowed"><div class="c-app-header"><div class="c-app-header__theme" style="background-image: url('//media.springernature.com/dominant-colour/springer-static/cover/book/978-3-031-15030-2.jpg')"></div><div class="c-app-header__content"><div class="c-app-header__main"><div class="c-app-header__cover"><div class="c-app-expand-overlay-wrapper"><a data-component="cover-zoom" data-img-src="//media.springernature.com/full/springer-static/cover-hires/book/978-3-031-15030-2" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/cover"><picture><source type="image/webp" srcset="                                                         //media.springernature.com/w92/springer-static/cover/book/978-3-031-15030-2.jpg?as=webp 1x,                                                         //media.springernature.com/w184/springer-static/cover/book/978-3-031-15030-2.jpg?as=webp 2x"><img src="//media.springernature.com/w92/springer-static/cover/book/978-3-031-15030-2.jpg" width="90" height="130" alt="Book cover"></picture><svg data-component="expand-icon" class="c-expand-overlay u-icon u-hide" width="18" height="18" aria-hidden="true" focusable="false"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-expand-image"></use></svg></a></div></div><div class="c-cover-image-lightbox u-hide" data-component="cover-lightbox"></div><div class="u-flex-shrink"><p class="c-chapter-book-details"><a class="c-chapter-book-details__title" data-test="book-link" data-track="click" data-track-action="open book series" data-track-label="link" href="/book/10.1007/978-3-031-15030-2">Artificial Intelligence and Cybersecurity</a><span class="c-chapter-book-details__meta"> pp 209–246<a href="#citeas" class="c-chapter-book-details__cite-as u-hide-print" data-track="click" data-track-action="cite this chapter" data-track-label="link">Cite as</a></span></p></div></div></div></div></div>
    </header>

    
    
        <nav class="u-mb-16" aria-label="breadcrumbs" data-test="article-breadcrumbs">
            <ol class="c-breadcrumbs c-breadcrumbs--truncated" itemscope itemtype="https://schema.org/BreadcrumbList">
                
                    <li class="c-breadcrumbs__item" id="breadcrumb0" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="Chapter" data-track-action="breadcrumbs" data-track-label="breadcrumb1"><span itemprop="name">Home</span></a><meta itemprop="position" content="1">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb1" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <a href="/book/10.1007/978-3-031-15030-2" class="c-breadcrumbs__link" itemprop="item" data-track="click" data-track-category="Chapter" data-track-action="breadcrumbs" data-track-label="breadcrumb2"><span itemprop="name">Artificial Intelligence and Cybersecurity</span></a><meta itemprop="position" content="2">
                            <svg class="c-breadcrumbs__chevron" role="img" aria-hidden="true" focusable="false" height="10" viewBox="0 0 10 10" width="10" xmlns="http://www.w3.org/2000/svg">
                                <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="#666" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
                            </svg>
                    </li>
                
                    <li class="c-breadcrumbs__item" id="breadcrumb2" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
                        <span itemprop="name">Chapter</span><meta itemprop="position" content="3">
                    </li>
                
            </ol>
        </nav>
    


    <main class="c-article-main-column u-float-left js-main-column u-text-sans-serif" data-track-component="chapter">
        
            
            <div class="c-context-bar u-hide"
                 data-test="context-bar"
                 data-context-bar
                 aria-hidden="true">
                <div class="c-context-bar__container u-container">
                    <div class="c-context-bar__title">
                        Android Malware Detection Using Deep Learning
                    </div>
                    
                </div>
            </div>
        

        <article lang="en">
            <header data-test="chapter-detail-header">
                <div class="c-article-header">
                    <h1 class="c-article-title" data-test="chapter-title" data-chapter-title="">Android Malware Detection Using Deep Learning</h1>
                    <ul class="c-article-author-list c-article-author-list--short" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Stuart-Millar" data-author-popup="auth-Stuart-Millar" data-corresp-id="c1">Stuart Millar<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a><sup class="u-js-hide"><a href="#Aff4">4</a></sup>, </li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Niall-McLaughlin" data-author-popup="auth-Niall-McLaughlin">Niall McLaughlin</a><sup class="u-js-hide"><a href="#Aff5">5</a></sup>, </li><li class="c-article-author-list__item c-article-author-list__item--hide-small-screen"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Jesus_Martinez_del-Rincon" data-author-popup="auth-Jesus_Martinez_del-Rincon">Jesus Martinez del Rincon</a><sup class="u-js-hide"><a href="#Aff5">5</a></sup> &amp; </li><li class="c-article-author-list__show-more" aria-label="Show all 4 authors for this article" title="Show all 4 authors for this article">…</li><li class="c-article-author-list__item"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Paul-Miller" data-author-popup="auth-Paul-Miller">Paul Miller</a><sup class="u-js-hide"><a href="#Aff5">5</a></sup> </li></ul><button aria-expanded="false" class="c-article-author-list__button"><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-plus"></use></svg><span>Show authors</span></button>
                    <ul class="c-article-identifiers c-chapter-identifiers">
                        
    
        <li class="c-article-identifiers__item" data-test="article-category">Chapter</li>
    
    

                        
    

                        <li class="c-article-identifiers__item"><a href="#chapter-info" data-track="click" data-track-action="publication date" data-track-label="link">First Online: <time datetime="2022-08-01">01 August 2022</time></a></li>
                    </ul>

                    <div data-test="article-metrics">
                        <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">382 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                
            
            
                
            
        </ul>
    </div>
</div>

                    </div>

                    
                    
                </div>
            </header>

            <div data-article-body="true" class="c-article-body">

                
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 id="Abs1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>This chapter investigates the potential of deep learning architectures for Android malware detection, specifically convolutional neural networks (CNNs) using natural language processing (NLP) concepts. The proposed solution is based on static analysis of raw opcode sequences from disassembled programs and other complementary features such as API calls and permissions, with features indicative of malware automatically learned by the network. This removes the need for hand-engineered malware features while performing classification. Using the Drebin and AMD benchmark datasets, the benefits of this multi-view architecture to combine multiple feature sources are demonstrated in our findings. We conclude the use of deep learning architectures enables state-of-art results in automatic malware detection, while reducing the dependency on feature engineering and domain expertise. Using multi-view compared to single-view architectures improves performance through exposure to simultaneous sources of information, learning a more effective set of features. The model achieves state-of-the art detection performance in a challenging zero-day scenario, reducing false positives by 77% in relative terms on average, an important metric for potential real-world deployment.</p></div></div></section>
                

                

                

                
                <div data-test="chapter-cobranding-and-download">
                    
    <div class="note test-pdf-link" id="cobranding-and-download-availability-text">
        
            <div class="c-article-access-provider" data-component="provided-by-box">
                
                
                    <p class="c-article-access-provider__text">
                        <a href="/content/pdf/10.1007/978-3-031-15030-2_10.pdf?pdf=inline%20link" class="c-pdf-download__link" style="display: inline; padding:0px!important;" target="_blank" rel="noopener"
                        data-track="click" data-track-action="Pdf download" data-track-label="inline link" download>Download</a> chapter PDF
                    </p>
                
            </div>
        
    </div>

                </div>

                

                
                    
                        <div class="main-content">
                        <section data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 id="Sec1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">1 </span>Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Malware detection is a growing problem, especially in mobile platforms. Given the proliferation of mobile devices and their associated app-stores, the volume of new applications is too large to manually examine each application for malicious behavior. The Android OS from Google is widely used with over 2.5 billion active Android devices, including smartphones, wearables and in-car implementations. This creates a plethora of attack opportunities for malware authors, and consequently a need for effective Android malware detection techniques.</p><p>Malware detection has traditionally been based on manually examining the behavior and/or de-compiled code of known malware programs in order to design malware signatures by hand. This process does not easily scale to large numbers of applications, especially given the static nature of signature based malware detection, meaning that new malware can be designed to evade existing signatures.</p><p>Consequently, there has recently been a large volume of work on automatic malware detection using ideas from machine learning (ML). Various methods have been proposed based on examining the dynamic application behavior [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Shabtai, A., Kanonov, U., Elovici, Y., Glezer, C., Weiss, Y.: Andromaly: a behavioral malware detection framework for android devices. J. Intell. Inform. Syst. 38(1), 161–190 (2012)" href="#ref-CR59" id="ref-link-section-d59495552e419">59</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Su, X., Chuah, M.C., Tan, G.: Smartphone dual defense protection framework: detecting malicious applications in android markets. In: 2012 Eighth Int. Conf. on Mobile Ad-hoc and Sensor Networks (MSN) (2012)" href="#ref-CR62" id="ref-link-section-d59495552e422">62</a>], requested permissions [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Liu, X., Liu, J.: A two-layered permission-based android malware detection scheme. In: 2014 2nd IEEE Int. Conf. on Mobile Cloud Computing, Services and Engineering (MobileCloud) (2014)" href="#ref-CR39" id="ref-link-section-d59495552e425">39</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Sanz, B., Santos, I., Laorden, C., X. Ugarte-Pedrero, P.G.B., Alvarez, G.: Puma: permission usage to detect malware in android. In: Int. Joint Conf. CISIS’12-ICEUTE’12-SOCO’12 (2012)" href="#ref-CR57" id="ref-link-section-d59495552e428">57</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Sharma, A., Dash, S.K.: Mining api calls and permissions for android malware detection. In: Cryptology and Network Security (2014)" href="#ref-CR60" id="ref-link-section-d59495552e431">60</a>] and the n-grams present in the application byte-code [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Kang, B., Kang, B., Kim, J., Im, E.G.: Android malware classification method: Dalvik bytecode frequency analysis. In: Proc. of the 2013 Research in Adaptive and Convergent Systems (2013)" href="#ref-CR33" id="ref-link-section-d59495552e435">33</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Jerome, Q., Allix, K., State, R., Engel, T.: Using opcode-sequences to detect malicious android applications. In: 2014 IEEE Int. Conf. on Communications (ICC) (2014)" href="#ref-CR31" id="ref-link-section-d59495552e438">31</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Canfora, G., Mercaldo, F., Visaggio, C.A.: Mobile malware detection using op-code frequency histograms. In: Proc.of Int. Conf. on Security and Cryptography (SECRYPT) (2015)" href="#ref-CR11" id="ref-link-section-d59495552e441">11</a>]. However, expert Android malware knowledge is regularly required to hand-craft input features to such detectors. This also leaves them potentially more vulnerable to zero-day attacks, until such time as the new malware can firstly be detected and reverse-engineered, after which features for detection are updated.</p><p>In this chapter, we show how to decouple these domain insights from the input features and the learning process. As a result our method is attractive in terms of real-world use and maintenance, particularly from a zero-day perspective. We propose a deep neural network incorporating convolutional methods, with multiple views learning from three raw input feature sets of low-level opcodes, app permissions and proprietary Android API packages, all of which are extracted from each app directly.</p><p>Recently, convolutional networks have been shown to perform well on a variety of tasks related to natural language processing. Thus, we investigate the application of convolutional networks to malware detection by treating the disassembled byte-code and API calls of an application as a text to be analyzed, in combination with the permissions requested by the app. This approach has the advantage that three complementary feature sets are automatically learned from raw data, and hence removes the need for malware signatures to be designed by hand. The usefulness of each feature set is tested to show its effectiveness despite not requiring domain insight for feature ranking or selection. We provide evidence that these feature sets in combination with a multi-view architecture outperform the state-of-the-art, both in a zero-day scenario and for the conventional detection case.</p><p>Our proposed malware detection method is computationally efficient as training and testing time is linearly proportional to the number of malware examples. The detection network can be run on a GPU, which is now a standard component of many mobile devices, meaning a large number of malware files can be scanned per-second. In addition, it is expected that as more training data is provided the accuracy of malware detection will improve because neural networks have been shown to have a very high learning capacity, and hence can benefit from very large training-sets in the future.</p></div></div></section><section data-title="Related Work"><div class="c-article-section" id="Sec2-section"><h2 id="Sec2" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">2 </span>Related Work</h2><div class="c-article-section__content" id="Sec2-content"><h3 class="c-article__sub-heading" id="Sec3"><span class="c-article-section__title-number">2.1 </span>Traditional ML Techniques</h3><p>Learning based approaches using hand-designed features have been applied extensively to both static analysis, using derived signatures with no code execution, and dynamic analysis, where an attempt is made to execute malware in real-time for behavioural study. Traditional ML approaches were adopted in early work, including SVMs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e466">7</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Zhu, J., Wu, Z., Guan, Z., Chen, Z.: Api sequences based malware detection for android. In: 2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and its associated Workshops (UIC-ATC-ScalCom), pp. 673–676 (2015)" href="#ref-CR79" id="ref-link-section-d59495552e469">79</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Mariconti, E., Onwuzurike, L., Andriotis, P., Cristofaro, E.D., Ross, G.J., Stringhini, G.: Mamadroid: Detecting android malware by building Markov chains of behavioral models. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2017 (2017)" href="#ref-CR43" id="ref-link-section-d59495552e472">43</a>], naive Bayes [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Yerima, S.Y., Sezer, S., Muttik, I.: Android malware detection using parallel machine learning classifiers. In: Proceedings of the 2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies, NGMAST ’14, pp. 37–42. IEEE Computer Society (2014)" href="#ref-CR73" id="ref-link-section-d59495552e475">73</a>], kNN, k-means clustering [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Saracino, A., Sgandurra, D., Dini, G., Martinelli, F.: Madam: Effective and efficient behavior-based android malware detection and prevention. IEEE Trans. Dependable Secure Comput. 15(1), 83–97 (2018)" href="#ref-CR58" id="ref-link-section-d59495552e478">58</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Sun, M., Li, X., Lui, J.C.S., Ma, R.T.B., Liang, Z.: Monet: A user-oriented behavior-based malware variants detection system for android. IEEE Trans. Inform. Forensics Secur. 12(5), 1103–1112 (2017)" href="#ref-CR63" id="ref-link-section-d59495552e482">63</a>] and decision trees [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Yerima, S.Y., Sezer, S., Muttik, I.: Android malware detection using parallel machine learning classifiers. In: Proceedings of the 2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies, NGMAST ’14, pp. 37–42. IEEE Computer Society (2014)" href="#ref-CR73" id="ref-link-section-d59495552e485">73</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Chen, S., Xue, M., Tang, Z., Xu, L., Zhu, H.: Stormdroid: A streaminglized machine learning-based system for detecting android malware. In: Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security, ASIA CCS ’16, pp. 377–388. ACM, New York (2016)" href="#ref-CR13" id="ref-link-section-d59495552e488">13</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Garcia, J., Hammad, M., Malek, S.: Lightweight, obfuscation-resilient detection and family identification of android malware. ACM Trans. Softw. Eng. Methodol. 26(3), 11:1–11:29 (2018)" href="#ref-CR22" id="ref-link-section-d59495552e491">22</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Aafer, Y., Du, W., Yin, H.: Droidapiminer: Mining API-level features for robust malware detection in android. In: Security and Privacy in Communication Networks. 9th International ICST Conference, SecureComm 2013 (2014)" href="#ref-CR1" id="ref-link-section-d59495552e494">1</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Chen, W., Aspinall, D., Gordon, A.D., Sutton, C., Muttik, I.: More semantics more robust: improving android malware classifiers. In: Proceedings of the 9th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks, WiSec ’16, pp. 147–158. ACM, New York (2016)" href="#ref-CR14" id="ref-link-section-d59495552e497">14</a>]. Such methods tend to have hand-crafted, manual rankings or selections of input features [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Yerima, S.Y., Sezer, S., Muttik, I.: Android malware detection using parallel machine learning classifiers. In: Proceedings of the 2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies, NGMAST ’14, pp. 37–42. IEEE Computer Society (2014)" href="#ref-CR73" id="ref-link-section-d59495552e501">73</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Aafer, Y., Du, W., Yin, H.: Droidapiminer: Mining API-level features for robust malware detection in android. In: Security and Privacy in Communication Networks. 9th International ICST Conference, SecureComm 2013 (2014)" href="#ref-CR1" id="ref-link-section-d59495552e504">1</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alzaylaee, M.K., Yerima, S.Y., Sezer, S.: Emulator vs real phone: android malware detection using machine learning. In: Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, IWSPA ’17, pp. 65–72. ACM, New York (2017)" href="#ref-CR5" id="ref-link-section-d59495552e507">5</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Faruki, P., Laxmi, V., Bharmal, A., Gaur, M., Ganmoor, V.: Androsimilar: Robust signature for detecting variants of android malware. J. Infor. Secur. Appl. 22, 66–80 (2015). Special issue on Security of Information and Networks" href="#ref-CR17" id="ref-link-section-d59495552e510">17</a>]. These include pre-selected APIs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Sun, M., Li, X., Lui, J.C.S., Ma, R.T.B., Liang, Z.: Monet: A user-oriented behavior-based malware variants detection system for android. IEEE Trans. Inform. Forensics Secur. 12(5), 1103–1112 (2017)" href="#ref-CR63" id="ref-link-section-d59495552e513">63</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Zhu, J., Wu, Z., Guan, Z., Chen, Z.: Api sequences based malware detection for android. In: 2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and its associated Workshops (UIC-ATC-ScalCom), pp. 673–676 (2015)" href="#ref-CR79" id="ref-link-section-d59495552e516">79</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Aafer, Y., Du, W., Yin, H.: Droidapiminer: Mining API-level features for robust malware detection in android. In: Security and Privacy in Communication Networks. 9th International ICST Conference, SecureComm 2013 (2014)" href="#ref-CR1" id="ref-link-section-d59495552e520">1</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Skovoroda, A., Gamayunov, D.: Automated static analysis and classification of android malware using permission and api calls models. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 243–24309 (2017)" href="#ref-CR61" id="ref-link-section-d59495552e523">61</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Onwuzurike, L., Almeida, M., Mariconti, E., Blackburn, J., Stringhini, G., De Cristofaro, E.: A family of droids-android malware detection via behavioral modeling: Static vs dynamic analysis. In: 2018 16th Annual Conference on Privacy, Security and Trust (PST), pp. 1–10 (2018)" href="#ref-CR50" id="ref-link-section-d59495552e526">50</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Maiorca, D., Mercaldo, F., Giacinto, G., Visaggio, C.A., Martinelli, F.: R-packdroid: Api package-based characterization and detection of mobile ransomware. In: Proceedings of the Symposium on Applied Computing, SAC ’17, pp. 1718–1723. ACM, New York (2017)" href="#ref-CR42" id="ref-link-section-d59495552e529">42</a>], permissions [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Skovoroda, A., Gamayunov, D.: Automated static analysis and classification of android malware using permission and api calls models. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 243–24309 (2017)" href="#ref-CR61" id="ref-link-section-d59495552e532">61</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Sanz, B., Santos, I., Laorden, C., Ugarte-Pedrero, X., Bringas, P.G., Marañón, G.A.: Puma: Permission usage to detect malware in android. In: CISIS/ICEUTE/SOCO Special Sessions 2012, Advances in Intelligent Systems and Computing, vol. 189, pp. 289–298. Springer, Berlin (2012)" href="#ref-CR56" id="ref-link-section-d59495552e535">56</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Alazab, M., Alazab, M., Shalaginov, A., Mesleh, A., Awajan, A.: Intelligent mobile malware detection using permission requests and API calls. Future Generation Computer Systems 107, 509–521 (2020)" href="#ref-CR3" id="ref-link-section-d59495552e539">3</a>], network traffic [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Lashkari, A.H., A.Kadir, A.F., Gonzalez, H., Mbah, K.F., A. Ghorbani, A.: Towards a network-based framework for android malware detection and characterization. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 233–23309 (2017)" href="#ref-CR37" id="ref-link-section-d59495552e542">37</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Wang, S., Yan, Q., Chen, Z., Yang, B., Zhao, C., Conti, M.: Detecting android malware leveraging text semantics of network flows. IEEE Trans. Inform. Forensics Secur. 13(5), 1096–1109 (2018)" href="#ref-CR67" id="ref-link-section-d59495552e545">67</a>], network addresses [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e548">7</a>], malicious system call traces [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Burguera, I., Zurutuza, U., Nadjm-Tehrani, S.: Crowdroid: Behavior-based malware detection system for android. In: Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices, SPSM ’11, pp. 15–26. ACM, New York (2011)" href="#ref-CR9" id="ref-link-section-d59495552e551">9</a>], and embedded call graphs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Gascon, H., Yamaguchi, F., Arp, D., Rieck, K.: Structural detection of android malware using embedded call graphs. In: Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security, AISec ’13, pp. 45–54. ACM, New York (2013)" href="#ref-CR23" id="ref-link-section-d59495552e554">23</a>]. The drawback to this prior work is that depending on expert knowledge for feature engineering makes a detector more vulnerable to change, rather than if such knowledge was encapsulated inside the detector itself and learned end-to-end. There is also a problem with the use of too small or unbalanced datasets, giving rise to some uncertainty regarding effectiveness in the wild. Almost none of these methods have been thoroughly tested in arguably the toughest of scenarios, that is, a comprehensive zero-day situation where the task is to detect never-before-encountered malware.</p><h3 class="c-article__sub-heading" id="Sec4"><span class="c-article-section__title-number">2.2 </span>Neural Network Techniques</h3><p>Recently, detection methods have begun to implement deep learning neural networks, following the state-of-the-art performance that convolutional neural networks (CNNs) have shown for object recognition in images and natural language processing (NLP). Techniques such as CNNs have huge potential to be applied in the field of malware detection, inspired by those methods originally developed for NLP. These systems benefit from a data-centric approach where features are learned from training examples rather than being manually derived by experts. This allows creation of models that are easier to train, update and maintain when new malware samples are available, and they may also be able to extract discriminative features not immediately obvious to human experts.</p><p>A variety of approaches to malware detection using other neural network architectures have been proposed. Yuan et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 75" title="Yuan, Z., Lu, Y., Xue, Y.: Droiddetector: android malware characterization and detection using deep learning. Tsinghua Sci. Technol. 21(1), 114–123 (2016)" href="#ref-CR75" id="ref-link-section-d59495552e568">75</a>] was an early neural net detector using a series of autoencoders in a deep belief network. Xu et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Xu, K., Li, Y., Deng, R.H., Chen, K.: Deeprefiner: Multi-layer android malware detection system applying deep neural networks. In: 2018 IEEE European Symposium on Security and Privacy (Euro SP), pp. 473–487 (2018)" href="#ref-CR70" id="ref-link-section-d59495552e571">70</a>] built a neural network that included a long short-term memory unit (LSTM), though with 18 million learnable parameters in three hidden layers alone, there is a questions over its generalisation capability given the amount of training data was many orders of magnitude smaller. Kim et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Kim, T., Kang, B., Rho, M., Sezer, S., Im, E.G.: A multimodal deep learning method for android malware detection using various features. IEEE Trans. Inform. Forensics Secur. 14(3), 773–788 (2019)." href="#ref-CR35" id="ref-link-section-d59495552e574">35</a>] also presented a network to include multi-modal features such as opcodes or APIs, though seemingly offered no significant improvement over their baseline. Oak et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Oak, R., Du, M., Yan, D., Takawale, H., Amit, I.: Malware detection on highly imbalanced data through sequence modeling. In: Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security, AISec’19, pp. 37–48. Association for Computing Machinery (2019)" href="#ref-CR49" id="ref-link-section-d59495552e577">49</a>] experimented with both an LSTM and a BERT model for the malware detection task, showing promising results, however the dataset used was a set of dynamic analysis traces produced by Palo Alto Networks using their Wildfire [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Palo Alto Networks: WildFire malware analysis service. &#xA;                https://docs.paloaltonetworks.com/wildfire.html&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR51" id="ref-link-section-d59495552e580">51</a>] tool. These are not easily reproducible given Wildfire is not open-sourced and the apps used are not publicly available.</p><p>Few approaches have used CNNs effectively in Android malware detection. McLaughlin et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="McLaughlin, N., Martinez del Rincon, J., Kang, B., Yerima, S., Miller, P., Sezer, S., Safaei, Y., Trickel, E., Zhao, Z., Doupé, A., Joon Ahn, G.: Deep android malware detection. In: Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, CODASPY ’17. ACM, New York (2017)" href="#ref-CR45" id="ref-link-section-d59495552e586">45</a>] presented a CNN to learn solely from opcode patterns, and [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Martinelli, F., Marulli, F., Mercaldo, F.: Evaluating convolutional neural network for effective mobile malware detection. Procedia Comput. Sci. 112(C), 2372–2381 (2017)" href="#ref-CR44" id="ref-link-section-d59495552e589">44</a>] built a CNN to learn from system calls extracted via dynamic analysis. Ding et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Ding, Y., Zhao, W., Wang, Z., Wang, L.: Automaticlly learning features of android apps using CNN. In: 2018 International Conference on Machine Learning and Cybernetics (ICMLC), vol. 1, pp. 331–336 (2018)" href="#ref-CR15" id="ref-link-section-d59495552e592">15</a>] pre-selected 245 sensitive APIs as input to their system but only reported results on part of a benchmark dataset. Evaluations in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Karbab, E.B., Debbabi, M., Derhab, A., Mouheb, D.: Maldozer: Automatic framework for android malware detection using deep learning. Digital Invest. 24, S48–S59 (2018)" href="#ref-CR34" id="ref-link-section-d59495552e595">34</a>] showed strong detection performance though their CNN had several hundred thousand trainable parameters plus an arbitrary API dictionary with one hundred thousand entries that could be viewed as brittle. Lee et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Lee, W.Y., Saxe, J., Harang, R.: Seqdroid: Obfuscated android malware detection using stacked convolutional and recurrent neural networks. In: Deep Learning Applications for Cyber Security, pp. 197–210. Springer, Cham (2019)" href="#ref-CR38" id="ref-link-section-d59495552e598">38</a>] used stacked RNNs and CNNs with packages, permissions, certificate info and intent actions as input features. Nix and Zhang [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Nix, R., Zhang, J.: Classification of android apps and malware using deep neural networks. In: 2017 International Joint Conference on Neural Networks, IJCNN 2017, Anchorage, AK, USA, May 14–19, 2017, pp. 1871–1878 (2017)" href="#ref-CR48" id="ref-link-section-d59495552e602">48</a>] helped introduce recurrency using a CNN with an LSTM to learn program flows of system API call sequences.</p><p>Like the traditional ML models, neural network methods were also not rigorously tested in the zero-day scenario. A summary of these prior methods, both traditional and neural network based, are provided in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab1">1</a>. </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption class="c-article-table__figcaption"><b id="Tab1" data-test="table-caption">Table 1 Related work summary for detection techniques</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/1" aria-label="Full size table 1"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec5"><span class="c-article-section__title-number">2.3 </span>API Features for Detection</h3><p>It can be seen from the listing in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab1">1</a> that APIs are regularly used as input features for Android malware detection, however they are heavily hand-crafted using expert knowledge. For example, an app can be statically scanned for a select number of predefined sensitive or malicious APIs [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e1648">74</a>], either for their presence, or to measure their frequency of use. Alternatively this analysis can be dynamic, for example when building sequences of temporal API call invocations [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Ma, Z., Ge, H., Liu, Y., Zhao, M., Ma, J.: A combination method for android malware detection based on control flow graphs and machine learning algorithms. IEEE Access 7, 21235–21245 (2019)" href="#ref-CR41" id="ref-link-section-d59495552e1651">41</a>]. However considering a benchmark dataset can have tens of thousands of apps, this is time-consuming, with upwards of several minutes execution time per app. In addition, anti-emulation and anti-sandbox techniques are used by malware authors to keep malicious functionality dormant if instrumentation is detected [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alzaylaee, M.K., Yerima, S.Y., Sezer, S.: Emulator vs real phone: android malware detection using machine learning. In: Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, IWSPA ’17, pp. 65–72. ACM, New York (2017)" href="#ref-CR5" id="ref-link-section-d59495552e1654">5</a>], so these dynamic sequences may not be as useful as expected.</p><p>Regarding static analysis of APIs, the Drebin detector [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e1660">7</a>] has a hand-engineered mapping of APIs in a total of eight feature sets, including suspicious API calls and restricted API calls. Many other state-of-the-art detectors used APIs in some form as features too. Chen et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Chen, S., Xue, M., Tang, Z., Xu, L., Zhu, H.: Stormdroid: A streaminglized machine learning-based system for detecting android malware. In: Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security, ASIA CCS ’16, pp. 377–388. ACM, New York (2016)" href="#ref-CR13" id="ref-link-section-d59495552e1663">13</a>] built a group of 240 sensitive API calls that were then ranked to select a top 90. Skovoroda et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Skovoroda, A., Gamayunov, D.: Automated static analysis and classification of android malware using permission and api calls models. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 243–24309 (2017)" href="#ref-CR61" id="ref-link-section-d59495552e1666">61</a>] created a list of hand-engineered protected API calls plus a list of unprotected API calls, totalling 384 API features. Fan et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Fan, M., Liu, J., Luo, X., Chen, K., Tian, Z., Zheng, Q., Liu, T.: Android malware familial classification and representative sample selection via frequent subgraph analysis. IEEE Trans. Inform. Forensics Secur. 13(8), 1890–1905 (2018)" href="#ref-CR16" id="ref-link-section-d59495552e1669">16</a>] adopted a weighted sensitive API call-based matching approach to detection, with a pool of 26,322 sensitive API calls. Kim et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Kim, T., Kang, B., Rho, M., Sezer, S., Im, E.G.: A multimodal deep learning method for android malware detection using various features. IEEE Trans. Inform. Forensics Secur. 14(3), 773–788 (2019)." href="#ref-CR35" id="ref-link-section-d59495552e1672">35</a>] used method invocation within APIs as a feature, parsing apps for hand-chosen dangerous APIs, both for existence and frequency of use. Garcia et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Garcia, J., Hammad, M., Malek, S.: Lightweight, obfuscation-resilient detection and family identification of android malware. ACM Trans. Softw. Eng. Methodol. 26(3), 11:1–11:29 (2018)" href="#ref-CR22" id="ref-link-section-d59495552e1676">22</a>] also counted various API invocations as features, with a package-level count of occurrences, grouped into purpose, in addition to a method-level count. Yerima et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e1679">74</a>] produced a listing of 56 malicious API calls, Android commands and Linux terminal commands, while [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Tian, K., Yao, D., Ryder, B.G., Tan, G., Peng, G.: Detection of repackaged android malware with code-heterogeneity features. IEEE Trans. Dependable Secure Comput. 17(1), 64–77 (2020)" href="#ref-CR64" id="ref-link-section-d59495552e1682">64</a>] engineered sensitive Android-specific and Java-specific API features for detecting repackaged malware.</p><p>Of methods that adopt dynamic analysis of APIs, [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Ma, Z., Ge, H., Liu, Y., Zhao, M., Ma, J.: A combination method for android malware detection based on control flow graphs and machine learning algorithms. IEEE Access 7, 21235–21245 (2019)" href="#ref-CR41" id="ref-link-section-d59495552e1688">41</a>] focused on what APIs were used, their frequency and their dynamic sequence, forming one-hot vectors derived from control flow graphs. They considered all APIs both in the JDK and Android SDK, likely to run into the thousands. Cai et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Cai, H., Meng, N., Ryder, B., Yao, D.: Droidcat: Effective android malware detection and categorization via app-level profiling. IEEE Transactions on Information Forensics and Security 14(6), 1455–1470 (2019)" href="#ref-CR10" id="ref-link-section-d59495552e1691">10</a>] engineered features from a behavioural characterisation study, using security-relevant APIs they described as sensitive. This involved hand-crafting 122 different features, with feature selection pruning this list to 70. Alzaylaee et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alzaylaee, M.K., Yerima, S.Y., Sezer, S.: Emulator vs real phone: android malware detection using machine learning. In: Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, IWSPA ’17, pp. 65–72. ACM, New York (2017)" href="#ref-CR5" id="ref-link-section-d59495552e1694">5</a>] used API call signatures, part of a wider ranked list of 100 features, generated during dynamic instrumentation. However they admit anti-emulator techniques meant it was possible for some API calls not to be logged. Wong and Lie [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Wong, M., Lie, D.: Intellidroid: A targeted input generator for the dynamic analysis of android malware. In: Proceedings of the 2016 Symposium on Network and Distributed System Security (NDSS) (2016)" href="#ref-CR69" id="ref-link-section-d59495552e1697">69</a>] used a list of 62 targeted Android APIs, whilst [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Afonso, V., Amorim, M., Grégio, A., Junquera, G., De Geus, P.: Identifying android malware using dynamically obtained features. J. Comput. Virol. Hacking Tech. 11, 9–17 (2014)" href="#ref-CR2" id="ref-link-section-d59495552e1700">2</a>] traced invocations of APIs in specified lists, using call frequencies in classification, and [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 71" title="Ye, Y., Hou, S., Chen, L., Lei, J., Wan, W., Wang, J., Xiong, Q., Shao, F.: Out-of-sample node representation learning for heterogeneous graph in real-time android malware detection. In: Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19, pp. 4150–4156 (2019)" href="#ref-CR71" id="ref-link-section-d59495552e1704">71</a>] extracted API calls as a one-hot encoding using a heterogeneous information network, again requiring significant expertise.</p><p>Considering this previous work collectively, it is clear that in general the use of APIs as features in Android malware detection has required a significant amount of feature-engineering and domain insight.</p><h3 class="c-article__sub-heading" id="Sec6"><span class="c-article-section__title-number">2.4 </span>Zero Day</h3><p>In the Android domain this translates into circumstances where a given malware family has not been encountered before. Hence the research focus of zero-day detection is developing malware detectors that are effective in classifying apps that belong to new malware families never seen previously, i.e. not available in the training set. This contrasts the more general case of traditionally detecting an app belonging to a previously seen family as malicious, i.e. with samples belonging to that family in the training set.</p><p>The zero-day setting is therefore much more challenging and will expose the weaknesses of existing systems to real-world complexity and test the generality of a learned model to new and never-before-seen malicious attacks. In this setting, signature-based systems will likely be compromised since no signature has been yet derived to detect the new threat. Similarly, ML-based systems may suffer or fail to detect new threats since they were not been exposed to the new malware type during training. This fact is exacerbated if feature engineering based on obsolete data has been extensively used or over-fitting to the training data rather than generalisation has occurred.</p></div></div></section><section data-title="Methodology"><div class="c-article-section" id="Sec7-section"><h2 id="Sec7" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">3 </span>Methodology</h2><div class="c-article-section__content" id="Sec7-content"><h3 class="c-article__sub-heading" id="Sec8"><span class="c-article-section__title-number">3.1 </span>Motivation</h3><p>Traditional ML systems learn from hand-crafted features engineered from raw data in order to make predictions or classifications. In order for this to be effective a significant level of domain knowledge is required, and previous methods often rely on a single feature set. For example, an Android app will make various API calls that can be statically extracted from reversed source code, or dynamically recorded, but thereafter malicious API sequences still need identified by hand. ML however can be extended beyond the prediction step to include automatic learning and encapsulation of information-rich encodings for raw input features, with minimal or sometimes even no manual feature-engineering. A multi-view approach can further decouple this expensive domain expertise by automatically creating a salient complex representation from several feature sets. Instead of individual features being hand-crafted externally to the model, relevant knowledge is acquired in the training phase by learning individual features and fusing them together. Moreover, this may result in features not obvious to human experts, and the multi-view model is easier to re-train and update when new apps are available, compared to repeating a costly feature-engineering stage. The presented Android malware detection model incorporates three views learning from raw input feature sets of low-level opcodes, app permissions and proprietary Android API packages. These individual raw feature sets are extracted from each app directly, per Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig1">1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig1_HTML.png" alt="figure 1" loading="lazy" width="500" height="925"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>Extracting raw input features</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Separate extraction of each raw feature set allows the combination and fusing of these three sources of complementary information in the architectural design. Generalisation to unseen apps in the zero-day scenario may also benefit, as it is more difficult for new malware to avoid scrutiny. Note this is straight-forward raw feature extraction, with neither any feature-selection and ranking used by other approaches, nor statistical analysis to pre-categorise input features. Hence domain insight is not required, with the relative importance of these features and their contribution to classification learnt and encapsulated within the model during the learning process. The desire to decouple specialist knowledge, lessening the involvement of the human analyst, is key in this approach. Each app’s <i>.dex</i> file is first disassembled into <i>.smali</i> files using baksmali [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Jesus Freke: Baksmali. &#xA;                https://github.com/JesusFreke/smali&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR32" id="ref-link-section-d59495552e1764">32</a>] and apktool [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Apktool: Apktool—a tool for reverse engineering 3rd party, closed, binary Android aps. &#xA;                https://ibotpeaches.github.io/Apktool/&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR6" id="ref-link-section-d59495552e1767">6</a>]. The following raw input feature sets are extracted from every app used in the study: </p><ol class="u-list-style-none">
                <li>
                  <span class="u-custom-list-number">1.</span>
                  
                    <p>opcode instruction sequences.</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">2.</span>
                  
                    <p>Android permissions usage.</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">3.</span>
                  
                    <p>arbitrary API package usage.</p>
                  
                </li>
                <li>
                  <span class="u-custom-list-number">4.</span>
                  
                    <p>proprietary Android API package [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Google: Android API Developer Reference. &#xA;                https://developer.android.com/reference/packages&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR25" id="ref-link-section-d59495552e1813">25</a>] usage.</p>
                  
                </li>
              </ol>
<h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec9"><span class="c-article-section__title-number">3.1.1 </span>Opcodes</h4><p>An opcode is the lowest level instruction used by the Android Dalvik run-time, with 218 possible opcode instructions. Each method in a <i>.smali</i> file is made up of a set of opcodes, for example <i>invoke</i>, <i>goto</i> or <i>move</i>, with arguments, also known as operands. These opcode instructions can include methods calls, changing program control flows or performing calculations. They are statically extracted from an app’s <i>.smali</i> files and concatenated to give a sequence representing one single app. This sequence is a series of one-hot vectors, with each containing 218 elements to represent the range of all opcodes. To encode the opcode used at a given point in the sequence, the corresponding element in the one-hot vector is set to 1 and all the other elements are 0. The operands are discarded as they represent an unmanageable range of references to low-level aspects like floats, longs, objects and registers, compared to the limited set of 218 opcodes. Attempting to understand operands at such a granular level of machine or assembly code also requires expertise beyond the scope of this work, with the aim being to avoid this very type of costly, non-trivial knowledge.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec10"><span class="c-article-section__title-number">3.1.2 </span>Permissions</h4><p>Permissions enable special access to mobile device functionality and must be requested by apps, potentially for sensitive purposes. For example, the permissions SENDSMS, RECEIVESMS, ACCESSNETWORKSTATE or INTERNET have been previously identified as being strongly associated with malware. An app contains an <i>AndroidManifest.xml</i> file that lists its requested Android permissions in order for the app to run correctly. Permissions are extracted for each app by parsing this manifest, generating a multi-hot vector representing 138 Android permissions. This extraction occurs for all apps, regardless of their release date, by matching against a predefined list which is a snapshot from 2016. In future, updating this list will automatically adapt the feature extraction to newly released apps.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec11"><span class="c-article-section__title-number">3.1.3 </span>Arbitrary API Packages</h4><p>Android malware apps can be produced en-masse, with simultaneous development and packaging via a standardised process [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Allix, K., Jerome, Q., Bissyandé, T.F., Klein, J., State, R., Traon, Y.L.: A forensic analysis of android malware—how is malware written and how it could be detected? In: 2014 IEEE 38th Annual Computer Software and Applications Conference, pp. 384–393 (2014)" href="#ref-CR4" id="ref-link-section-d59495552e1862">4</a>]. Large amounts of malware created at once using this batch compilation likely means recurring automatic injection of the same malicious code. Therefore the intuition in using API package feature sets is that there may be repeated invocation patterns across a dataset to indicate malicious behaviour which could be learned by the model without any manual analysis. Two variations of arbitrary API usage are selected for comparison to this study’s choice of proprietary Android APIs. These feature sets are named <i>APIs</i> and <i>GoogleAPIs</i> respectively. <i>APIs</i> represents any and all APIs that are invoked in an app’s methods, and has the broadest scope. <i>GoogleAPIs</i> differs by representing only only invocations of APIs written by Google, thus has somewhat more focus by disregarding any non-Google invocation. By treating APIs as a type of vocabulary, a dictionary-style approach is used to build each feature set separately, one for <i>APIs</i> and one for <i>GoogleAPIs</i>. These approaches are inspired by NLP methods for vocabulary selection, and bear similarities to others [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Karbab, E.B., Debbabi, M., Derhab, A., Mouheb, D.: Maldozer: Automatic framework for android malware detection using deep learning. Digital Invest. 24, S48–S59 (2018)" href="#ref-CR34" id="ref-link-section-d59495552e1884">34</a>]. Details are as follows:</p>
                  <ul class="u-list-style-bullet">
                    <li>
                      <p>
<i>APIs</i>: A single Java class in an app has a corresponding <i>.smali</i> file containing the methods of that class. For each app in turn, all its <i>.smali</i> files are parsed line-by-line for API usage. Given a line of code, if the term <i>‘invoke’</i> is present, the API invoked is extracted and added to a dictionary as a key-value mapping. In such a mapping, the key is a unique API, and its value a unique integer ID.</p>
                    </li>
                    <li>
                      <p>
<i>GoogleAPIs</i>: This is similar to the creation of the <i>APIs</i> feature set, except only invoked APIs that start with <i>‘com.google.’</i> are added to the dictionary. These are parsed by matching against a predefined list in line with official Android documentation as of April 2020 [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Google: Google APIs for Android. &#xA;                https://developers.google.com/android/reference/packages&#xA;                &#xA;               Accessed April 2020" href="#ref-CR27" id="ref-link-section-d59495552e1923">27</a>].</p>
                    </li>
                  </ul>
                <p>Per Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="#FPar1">1</a>, when creating each of these feature sets the full dataset is scanned once to build an empty data structure of key-value mappings, with each key being a unique API, and the corresponding value being an integer ID between 1 and the total number of keys. A count is stored for each API to track how often it is invoked, initialised at 0 to begin with.</p>
                  <h3 class="c-article__sub-heading" id="FPar1">Algorithm 1 Generating an API dictionary <i>dict</i>
</h3>
                  
                    <img src="//media.springernature.com/lw554/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Figaaa_HTML.png" alt="">
                  
                <p>Some APIs will be invoked often across a dataset, and some rarely, so a dictionary of relevant APIs can be created automatically by selecting the most frequently used APIs, being possible common malicious calls or perhaps indicators of normality, plus the less frequent as potential anomalous indicators. To do this, after the initial <i>dict</i> is created from a given dataset, the total number of times each API was invoked can be calculated with a second scan, and the count of invocations for each API updated. To ensure such a dictionary systematically represents APIs used both often and seldom, a threshold <i>T</i> is set for a minimum number of invocations that must be reached for an API to be included. After setting <i>T</i>, a newly thresholded dictionary of size <i>S</i> is generated, containing the <i>S</i>/2 most used and <i>S</i>/2 least used APIs. Each app is scanned for a third time to build its API sequence, excluding the APIs that are not in the dictionary. This API sequence is translated to a sequence of integers, where each value matches the original dictionary integer ID of the API invoked at a given point in the sequence. The dictionary size <i>S</i> and threshold <i>T</i> are later varied to study how this type of vocab selection impacts performance.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec12"><span class="c-article-section__title-number">3.1.4 </span>Proprietary Android API Packages</h4><p>These are at the heart of the Android platform [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Google: Android API Developer Reference. &#xA;                https://developer.android.com/reference/packages&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR25" id="ref-link-section-d59495552e1989">25</a>] and so it is logical to expect they may hold a degree of predictive power. Given proprietary Android APIs are less likely to change over time compared to the wider selection that is available to app developers generally, this may be of benefit in zero-day scenarios defending against future, unseen apps. This rationale, along with their lack of use in previous research, is the motivation to experiment with them, and avoids both arbitrary decisions about which APIs to consider from other vendors, as well as library dependency issues. During extraction, a dictionary data structure is first built using all 210 Android API packages, eliminating the need to define a dictionary size or a threshold compared to the previous API feature sets outlined. Each entry is once more a key-value mapping, where each key is a unique Android API, and its value an integer ID between 1 and 210. Again, for each app in turn all its <i>.smali</i> files are parsed line-by-line for API invocations. Android API usage is registered if in a given line of code the term <i>’invoke’</i> is used and the API matches one in the Android API dictionary. Like the arbitrary API feature sets, this results in a sequence of integers for each app, where each value matches the dictionary integer ID of the proprietary Android API invoked at a given point in the sequence, as illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig2">2</a>. This feature set is referred to as <i>AndroidAPIs</i> throughout.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="133"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>
<i>AndroidAPIs</i> sequence creation</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec13"><span class="c-article-section__title-number">3.2 </span>Neural Architecture</h3><p>An end-to-end, multi-view deep learning model is proposed for Android malware detection, both under zero-day conditions and for the conventional detection case, with domain insight decoupled. The architecture, illustrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig3">3</a>, consists of three views; one CNN learning from opcodes, a fully-connected neural net learning from permissions, and a second CNN learning from APIs. CNNs are selected for opcodes and APIs as these feature sets have a sequential nature that convolutional methods can learn sub-patterns from. In contrast, while relationships are envisaged between permissions, these associations are not sequential in nature. Therefore permissions are better suited to a fully-connected neural net, as each one is simply either present in an app, or not.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="250"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>Multi-view Deep Learning Network Architecture for Android malware detection</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>These feature sets are then combined together in a fully-connected network that gives a final classification as to whether an Android app is malicious or benign. The multi-view approach is adopted since the representations for each feature set are inherently different due to their modalities, and allows analysis of each part of the architecture separately. This design decision also enables more refined tuning of the model, and performance comparisons between each view permutation.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec14"><span class="c-article-section__title-number">3.2.1 </span>Opcodes CNN</h4><p>Outside computer vision, many successful applications of convolutional architectures occur when the task can be modelled as a Natural Language Processing (NLP) problem using word embeddings [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Kim, Y.: Convolutional neural networks for sentence classification. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1746–1751. Association for Computational Linguistics (2014)" href="#ref-CR36" id="ref-link-section-d59495552e2067">36</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Mikolov, T., Chen, K., Corrado, G.S., Dean, J.: Efficient estimation of word representations in vector space (2013). CoRR abs/1301.3781" href="#ref-CR46" id="ref-link-section-d59495552e2070">46</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 76" title="Zhang, X., Zhao, J., LeCun, Y.: Character-level convolutional networks for text classification. In: Proceedings of the 28th International Conference on Neural Information Processing Systems—Volume 1, NIPS’15, pp. 649–657. MIT Press, Cambridge (2015)" href="#ref-CR76" id="ref-link-section-d59495552e2073">76</a>]. This work is connected to these methods however instead of using pre-trained embeddings, a dense embedding layer is trained from the data simultaneously with the rest of the network parameters, considering each opcode as a word or a token whilst attempting to capture their semantics. The purpose of this CNN is to automatically learn salient patterns from each app’s sequence of opcodes that discriminate between malicious and benign. In this way knowledge is encapsulated inside the architecture, rather than being provided by a human expert via feature engineering and ranking.</p><p>The CNN aims to learn discriminative patterns from each sample’s sequence of raw opcode instructions that can be used to differentiate between malicious and benign. This decoupling of expert knowledge means these concepts are learnt directly and encapsulated inside the CNN. Thus, effort needed to handle changes introduced by opcode authoring variations over time is significantly less compared to repeating complex mathematical ranking and feature engineering. This is a differentiator between our method and previous work where more manual, hand-engineered features are required. We need only to extract the raw opcodes from each sample, which is purely an implementation task and needs no Android malware domain knowledge. The CNN does not need to be informed what the most malicious opcode patterns are, nor which ones are safe to be overlooked.</p><p>A raw input opcode sequence <i>I</i>
<sub><i>o</i></sub> for a single app is a series of one-hot vectors and can be written as <i>I</i>
<sub><i>o</i></sub> = {<i>x</i>
<sub>1</sub>…<i>x</i>
<sub><i>n</i></sub>}, where <i>x</i>
<sub><i>n</i></sub> represents the <i>n</i>th opcode in a sequence of length <i>n</i>
<sub><i>o</i></sub>. Each vector <i>x</i> is a one-hot vector, which has <i>d</i>
<sub><i>o</i></sub> = 218 elements to represent the range of all opcodes. The element corresponding to the opcode used at position <i>n</i> in <i>I</i>
<sub><i>o</i></sub> is set to 1, and all other elements are set to 0. CNN filters learn feature representations containing relationships between nearby opcodes, which enables learning of sub-patterns. However, due to the use of one-hot vectors, <i>I</i>
<sub><i>o</i></sub> has a degree of sparsity, reducing the amount of useful information for a filter to learn from without that filter being inefficiently large from a computational standpoint. To mitigate this sparsity and improve learning, the one-hot vectors are projected into a dense, information rich <i>k</i>
<sub><i>o</i></sub>-dimensional embedding space <i>P</i>
<sub><i>o</i></sub>. This is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig4">4</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-4" data-title="Fig. 4"><figure><figcaption><b id="Fig4" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 4</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="189"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-4-desc"><p>Creating the embedding projection <i>P</i>
<sub><i>o</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>In doing so, each vector in <i>I</i>
<sub><i>o</i></sub> is multiplied by an embedding weight matrix <span class="mathjax-tex">\(W_{E_o}\)</span> of size <i>d</i>
<sub><i>o</i></sub> × <i>k</i>
<sub><i>o</i></sub>. The weights in <span class="mathjax-tex">\(W_{E_o}\)</span> are randomly initialised at the start of the training procedure and updated during the learning process. The resulting embedding projection <i>P</i>
<sub><i>o</i></sub> is a matrix of size <i>n</i>
<sub><i>o</i></sub> × <i>k</i>
<sub><i>o</i></sub>, processed by one convolutional layer with <i>r</i> filters. Each filter has size <i>s</i>
<sub><i>o</i></sub> × <i>k</i>
<sub><i>o</i></sub>, with <i>s</i>
<sub><i>o</i></sub> being the number of consecutive opcodes analysed by each filter. Each of the <i>r</i> filters perform a 1D convolution over the full embedding matrix <i>P</i>
<sub><i>o</i></sub> generating an activation map <span class="mathjax-tex">\(a_{o_r}\)</span> of size <i>n</i>
<sub><i>o</i></sub> as follows: </p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} a_{o_r} = ReLU(Conv(P_o)_{{W_r}_{b_r}}) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (1)
                </div></div>
<p>where <i>W</i>
<sub><i>r</i></sub> and <i>b</i>
<sub><i>r</i></sub> are the trainable weight and bias parameters of the <i>r</i>th filter. The rectified linear activation function <i>ReLU</i>(<i>x</i>) = <i>max</i>{0, <i>x</i>} is used post-convolution. The activation maps produced from each filter are stacked to produce the activation matrix <i>A</i>
<sub><i>o</i></sub> of size <i>n</i>
<sub><i>o</i></sub> × <i>r</i>, denoted as: </p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} A_o = [a_{o_1}|a_{o_2}|\ldots|a_{o_r}] \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (2)
                </div></div>
<p>Global max-pooling subsamples <i>A</i>
<sub><i>o</i></sub> and produces a vector <i>q</i>
<sub><i>o</i></sub> of length <i>r</i> containing the maximum activation of each filter over the opcode sequence length <i>n</i>
<sub><i>o</i></sub>, written as: </p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} q_o = [max(a_{o_1})|max(a_{o_2})|\ldots|max(a_{o_r})] \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (3)
                </div></div>
<p>The static analysis in this study aims to highlight presence of malicious code that could be injected in any arbitrary location. Hence global max-pooling is a logical choice as it identifies sections of the opcode sequence that cause the maximum activation of each filter can be thought of those that model deems most important in classifying an app, regardless of the location of that section in the overall sequence. Max-pooling also ensures an input opcode sequence of arbitrary length is represented as a fixed-length vector ahead of being passed to the classification layer. <i>q</i>
<sub><i>o</i></sub> is fed through a fully-connected layer with <i>o</i>
<sub><i>o</i></sub> output neurons, producing the feature vector <i>f</i>
<sub><i>o</i></sub>: </p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} f_o = ReLU(W_oq_o + b_o) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (4)
                </div></div>
<p>where <i>W</i>
<sub><i>o</i></sub> and <i>b</i>
<sub><i>o</i></sub> are the weight and bias parameters of the hidden layer learned during training.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec15"><span class="c-article-section__title-number">3.2.2 </span>Permissions Neural Net</h4><p>The permissions contain useful information pertaining to malware detection that complements features derived from the opcodes CNN and the APIs CNN. For the permissions input, given an app and its manifest file, a multi-hot 1D array, or vector, of length 138 is generated. Each element maps to one of 138 Android permissions, with its value being 1 if a permission is in the manifest, or 0 if not. This permissions vector <i>i</i>
<sub><i>p</i></sub> is input to a fully-connected layer to allow the model to learn relationships between permissions for classification, giving the feature vector <i>f</i>
<sub><i>p</i></sub>, denoted as: </p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} f_p = ReLU(W_pi_p + b_p) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (5)
                </div></div>
<p>where <i>W</i>
<sub><i>p</i></sub> and <i>b</i>
<sub><i>p</i></sub> are the learnable weight and bias parameters of the permissions input layer. The output layer in this neural net has <i>o</i>
<sub><i>p</i></sub> neurons.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec16"><span class="c-article-section__title-number">3.2.3 </span>APIs CNN</h4><p>This CNN is concerned with learning discriminative patterns from API input sequences. Its architecture is similar to that of the opcodes CNN. Again, these API sequences are only extracted, with no ranking or feature-engineering being undertaken. There is no manual identification of individual APIs or patterns of APIs that are indicative of malware or benign apps. Like the opcodes CNN, a raw input API sequence <i>I</i>
<sub><i>g</i></sub> for an app is a series of one-hot vectors, <i>I</i>
<sub><i>g</i></sub> = {<i>x</i>
<sub>1</sub>…<i>x</i>
<sub><i>n</i></sub>}, representing a sequence of length <i>n</i>
<sub><i>g</i></sub>. In this case each <i>x</i> has length <i>d</i>
<sub><i>g</i></sub> elements to represent all potential APIs.</p><p>Similar to <i>I</i>
<sub><i>o</i></sub>, <i>I</i>
<sub><i>g</i></sub> also is a sparse matrix, and is projected into a <i>k</i>
<sub><i>g</i></sub>-dimensional embedding space <i>P</i>
<sub><i>g</i></sub> of size <i>n</i>
<sub><i>g</i></sub> × <i>k</i>
<sub><i>g</i></sub>, processed by a single convolutional layer with <i>m</i> filters. Each filter has size <i>s</i>
<sub><i>g</i></sub> × <i>k</i>
<sub><i>g</i></sub>, with <i>s</i>
<sub><i>g</i></sub> being the number of consecutive APIs analysed by each filter. Each of the <i>m</i> filters perform a 1D convolution operation over the full embedding matrix <i>P</i>
<sub><i>g</i></sub> generating an activation map <span class="mathjax-tex">\(a_{g_m}\)</span> of size <i>n</i>
<sub><i>g</i></sub> as follows: </p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} a_{g_m} = ReLU(Conv(P_g)_{{W_m}_{b_m}}) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (6)
                </div></div>
<p>where <i>W</i>
<sub><i>m</i></sub> and <i>b</i>
<sub><i>m</i></sub> are the trainable weight and bias parameters of the <i>m</i>th filter. Again <i>ReLU</i> is used post-convolution. The activation maps produced from each filter are stacked to produce the activation matrix <i>A</i>
<sub><i>g</i></sub>, of size <i>n</i>
<sub><i>g</i></sub> × <i>m</i>, denoted as: </p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} A_g = [a_{g_1}|a_{g_2}|\ldots|a_{g_m}] \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (7)
                </div></div>
<p>Global max-pooling subsamples <i>A</i>
<sub><i>g</i></sub> and produces a vector <i>q</i>
<sub><i>g</i></sub> of length <i>m</i> containing the maximum activation of each filter over the opcode sequence length <i>n</i>
<sub><i>g</i></sub>, written as: </p><div id="Equ8" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} q_g = [max(a_{g_1})|max(a_{g_2})|\ldots|max(a_{g_m})] \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (8)
                </div></div>
<p>
<i>q</i>
<sub><i>g</i></sub> is fed through a fully-connected layer with <i>o</i>
<sub><i>g</i></sub> output neurons, producing the feature vector <i>f</i>
<sub><i>g</i></sub>: </p><div id="Equ9" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} f_g = ReLU(W_gq_g + b_g) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (9)
                </div></div>
<p>where <i>W</i>
<sub><i>g</i></sub> and <i>b</i>
<sub><i>g</i></sub> are the weight and bias parameters of the hidden layer learned during training.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec17"><span class="c-article-section__title-number">3.2.4 </span>Classification Layer</h4><p>Per Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig3">3</a>, each feature vector is concatenated into a single feature representation <i>f</i>. The make-up of <i>f</i> depends on which permutation of input feature sets are used. It can be denoted as: </p><div id="Equ10" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} f = [f_g|f_o|f_p] \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (10)
                </div></div>
<p>Dropout is applied at a rate of 0.5, then <i>f</i> is input to a multi-layer perceptron (MLP) with an input layer of size <i>t</i>=<i>o</i>
<sub><i>g</i></sub>+<i>o</i>
<sub><i>o</i></sub>+<i>o</i>
<sub><i>p</i></sub>, a hidden layer <i>h</i> of size <i>o</i>
<sub><i>h</i></sub> neurons, and an output layer of size 2 neurons, since this malware classification problem is two-class, either malicious or benign. <i>z</i> can be denoted as: </p><div id="Equ11" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} z = ReLU(W_hf + b_h) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (11)
                </div></div>
<p>where <i>W</i>
<sub><i>h</i></sub> and <i>b</i>
<sub><i>h</i></sub> are the trainable weight and bias parameters of the hidden layer. This final output from the MLP, <i>z</i>, is a vector with each element giving a score that the app is associated with each class. <i>z</i> is passed to the SoftMax classification layer, which outputs the normalized probability of the app belonging to each class in the problem, formally: </p><div id="Equ12" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} p(y=i|z) = \frac{\exp(w_i^{\intercal}z+ b_i)}{\sum_{i^i}^{I}\exp(w_{i^\prime}^{\intercal}z + b_i)} \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (12)
                </div></div>
<p>where <i>w</i>
<sub><i>i</i></sub> and <i>b</i>
<sub><i>i</i></sub> are the trainable weight and bias parameters of the SoftMax layer learned for each of the <i>i</i> classes, <span class="mathjax-tex">\(w_i^{\intercal }z\)</span> is the inner product of <i>w</i>
<sub><i>i</i></sub> and <i>z</i>, with <i>y</i> being the predicted label.</p><h3 class="c-article__sub-heading" id="Sec18"><span class="c-article-section__title-number">3.3 </span>Cost Function</h3><p>The model’s cost function <i>C</i> to be minimized for a batch of <i>B</i> training samples, {<i>I</i>
<sub>(1)</sub>, …, <i>I</i>
<sub>(<i>B</i>)</sub>}, can be written as: </p><div id="Equ13" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} C = -\frac{1}{B}\sum_{j=1}^{B}\sum_{i=1}^{c} 1\{{y^{\prime}_{(j)}}=i\}\log p(y_{(j)}=i|z_{(j)}) \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (13)
                </div></div>
<p>where <i>c</i> is the number of classes in the task, <span class="mathjax-tex">\({y^{\prime }_{(j)}}\)</span> is the ground truth for sample <i>I</i>
<sub>(<i>j</i>)</sub> and <i>z</i>
<sub>(<i>j</i>)</sub> is the resulting output after the forward pass of <i>I</i>
<sub>(<i>j</i>)</sub> through the network. The function <span class="mathjax-tex">\(1\{{y^{\prime }_{mal{(j)}}}=i\}\)</span> returns 1 if the condition is true, and 0 if false. Learning is performed by stochastic gradient descent which updates the network parameters via backpropagation after each sample is forwarded using the gradient of the cost function with respect to these parameters. A learning rate <i>α</i> is used in this process. During training the network is repeatedly presented with batches of training samples in random order until the parameters converge, and the cost function is minimized.</p></div></div></section><section data-title="Experimental Setup"><div class="c-article-section" id="Sec19-section"><h2 id="Sec19" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">4 </span>Experimental Setup</h2><div class="c-article-section__content" id="Sec19-content"><p>The experiments are presented in four stages. The first covers hyper-parameter tuning for the opcodes CNN and the APIs CNN, with the second an analysis of features learned by the permissions network. The third evaluates the single and multi-view settings for malware detection to prove the proposed model is effective in a conventional detection setting. The fourth is a series of zero-day experiments to recreate a challenging scenario where a malware detector is tested against a new family of malware it has never encountered before. To do this each family is excluded in turn from training, keeping it held out only for testing. State-of-the-art comparisons are provided throughout and the focus is on F1 score and false positive (or false alarm) rate, as per convention in previous work [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e4951">7</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="McLaughlin, N., Martinez del Rincon, J., Kang, B., Yerima, S., Miller, P., Sezer, S., Safaei, Y., Trickel, E., Zhao, Z., Doupé, A., Joon Ahn, G.: Deep android malware detection. In: Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, CODASPY ’17. ACM, New York (2017)" href="#ref-CR45" id="ref-link-section-d59495552e4954">45</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Karbab, E.B., Debbabi, M., Derhab, A., Mouheb, D.: Maldozer: Automatic framework for android malware detection using deep learning. Digital Invest. 24, S48–S59 (2018)" href="#ref-CR34" id="ref-link-section-d59495552e4957">34</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Mariconti, E., Onwuzurike, L., Andriotis, P., Cristofaro, E.D., Ross, G.J., Stringhini, G.: Mamadroid: Detecting android malware by building Markov chains of behavioral models. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2017 (2017)" href="#ref-CR43" id="ref-link-section-d59495552e4960">43</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Millar, S., McLaughlin, N., Martinez del Rincon, J., Miller, P., Zhao, Z.: Dandroid: a multi-view discriminative adversarial network for obfuscated android malware detection. In: Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy, CODASPY ’20 (2020)" href="#ref-CR47" id="ref-link-section-d59495552e4963">47</a>]. The false positive rate of a detector is particularly important as it allows further evaluation to select optimal models, especially in the case where several achieve similarly high or saturated F1 scores. Moreover, from a real-world standpoint false alarms should be minimised to reduce noise and alert fatigue. The F1 score and false positive rate are calculated formally as: </p><div id="Equ14" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} F{\mathit{1}} = \frac{2 \times precision \times recall}{precision + recall} \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (14)
                </div></div>

              <div id="Equ15" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} precision= \frac{TP}{TP + FP} \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (15)
                </div></div>
            
              <div id="Equ16" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} recall = \frac{TP}{TP + FN} \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (16)
                </div></div>
            
              <div id="Equ17" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">
$$\displaystyle \begin{aligned} \mathit{false}\ \mathit{positive}\ \mathit{rate}\ = \frac{FP}{FP + TN} \end{aligned} $$
</span></div><div class="c-article-equation__number">
                    (17)
                </div></div>
            <p>where <i>TP</i>, <i>FP</i>, <i>TN</i>, <i>FN</i> are true positives, false positives, true negatives and false negatives respectively, with the false positive rate expressed as a percentage in the results. The positive case is where an app is malicious, and the negative case is where an app is benign.</p><h3 class="c-article__sub-heading" id="Sec20"><span class="c-article-section__title-number">4.1 </span>Datasets</h3><p>Four different datasets are used (1) Malgenome [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Zhou, Y., Jiang, X.: Dissecting android malware: characterization and evolution. In: 2012 IEEE Symposium on Security and Privacy (SP), pp. 95–109. IEEE, Piscataway (2012)" href="#ref-CR78" id="ref-link-section-d59495552e5323">78</a>], which contains 1260 malware apps across 49 different families, (2) an Intel Security dataset of 9902 malware apps from their own internal repository, (3) Drebin [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e5326">7</a>], with 5560 malware apps from 179 families, and (4) AMD [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Wei, F., Li, Y., Roy, S., Ou, X., Zhou, W.: Deep ground truth analysis of current android malware. In: International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA’17), pp. 252–276. Springer, Bonn (2017)" href="#ref-CR68" id="ref-link-section-d59495552e5329">68</a>], consisting of 24,553 malware apps from 71 families. The Malgenome dataset is only used for designing the initial architecture and hyperparameter tuning, not in the detection or zero-day experiments given its small size, and the Intel dataset is only used for investigating dictionary parameters since it is a proprietary set that does not allow comparison. For the evaluations and state-of-the-art comparison, the Drebin and AMD benchmark datasets are selected. This avoids overfitting and artificially inflated performance since neither Drebin or AMD are used in the tuning phase. These datasets are publicly available, and are chosen due to their continual use in the Android malware detection domain, allowing direct comparisons between the proposed approach and others, both in this work and in future. Every dataset is balanced with the addition of equivalent numbers of benign apps collected from Google Play, and then each dataset is split into 80% for training, 10% for validation, and 10% for testing, with the 50/50 balance of malware and benign apps maintained in each split. For the avoidance of doubt, these test apps are kept totally unseen and are not used in training or validation at any stage.</p></div></div></section><section data-title="Experimental Results: Tuning and Learning Analysis"><div class="c-article-section" id="Sec21-section"><h2 id="Sec21" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">5 </span>Experimental Results: Tuning and Learning Analysis</h2><div class="c-article-section__content" id="Sec21-content"><p>A thorough set of ablation experiments are performed to define the architecture design and investigate the influence of each of the hyperparameters. Architectures used in tuning the opcodes CNN and the APIs CNN have only a single convolutional layer, as in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="McLaughlin, N., Martinez del Rincon, J., Kang, B., Yerima, S., Miller, P., Sezer, S., Safaei, Y., Trickel, E., Zhao, Z., Doupé, A., Joon Ahn, G.: Deep android malware detection. In: Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, CODASPY ’17. ACM, New York (2017)" href="#ref-CR45" id="ref-link-section-d59495552e5341">45</a>]. Given the relatively small datasets available, larger numbers of layers are likely to be prone to overfitting and have a greater amount of trainable parameters with little performance improvement [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Zhang, Y., Wallace, B.C.: A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification. In: IJCNLP (2015)" href="#ref-CR77" id="ref-link-section-d59495552e5344">77</a>].</p><h3 class="c-article__sub-heading" id="Sec22"><span class="c-article-section__title-number">5.1 </span>Opcodes CNN</h3><p>Hyperparameters for the opcodes CNN are empirically set applying ablation [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Fawcett, C., Hoos, H.H.: Analysing differences between algorithm configurations through ablation. J. Heuristics 22(4), 431–458 (2016)." href="#ref-CR18" id="ref-link-section-d59495552e5354">18</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Wang, C., Dong, S., Zhao, X., Papanastasiou, G., Zhang, H., Yang, G.: Saliencygan: Deep learning semisupervised salient object detection in the fog of IoT. IEEE Trans. Ind. Inform. 16(4), 2667–2676 (2020)" href="#ref-CR66" id="ref-link-section-d59495552e5357">66</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Cashman, D., Perer, A., Chang, R., Strobelt, H.: Ablate, variate, and contemplate: Visual analytics for discovering neural architectures. IEEE Trans. Visualization Comput. Graph. 26(1), 863–873 (2020). &#xA;                https://doi.org/10.1109/TVCG.2019.2934261&#xA;                &#xA;              &#xA;" href="#ref-CR12" id="ref-link-section-d59495552e5360">12</a>], where one parameter is varied while all others are held constant, and using the Malgenome dataset. In summary, the resulting settings are: <i>s</i>
<sub><i>o</i></sub> = 8, <i>r</i> = 64, <i>k</i>
<sub><i>o</i></sub> = 8 and <i>n</i>
<sub><i>o</i></sub> = 8192. These are the default settings unless specified otherwise in an ablation.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec23"><span class="c-article-section__title-number">5.1.1 </span>Filter Length <i>s</i>
<sub><i>o</i></sub> and Number of Filters <i>r</i>
</h4><p>The filter length <i>s</i>
<sub><i>o</i></sub> was varied from <i>s</i>
<sub><i>o</i></sub> = 2 to <i>s</i>
<sub><i>o</i></sub> = 32, while the number of convolutional filters was held constant at <i>r</i> = 64 and the filter stride held at 1. Longer filter lengths let the network learn longer patterns of opcodes and detect long-range dependencies between them. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig5">5</a> shows an increase in F1 using longer filters, until around <i>s</i>
<sub><i>o</i></sub> = 8.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-5" data-title="Fig. 5"><figure><figcaption><b id="Fig5" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 5</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="178"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-5-desc"><p>Hyperparameter tuning for <i>s</i>
<sub><i>o</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>This result may be unsurprising, as very short opcode sequences are presumably statistically common and hence less discriminative, while very long sequences are too specific to a single sample. There likely exists an in-between length where opcode sequences both discriminate and generalise well. The filter length is set at <i>s</i>
<sub><i>o</i></sub> = 8, given the F1 improvement is marginal using filters twice or three times longer. In addition, since Dalvik is optimised for devices with constrained resources, it has a more powerful instruction set than conventional ×86, meaning less use of the stack and registers. With over 1000 ×86 opcodes [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Intel Developer Zone: Intel 64 and IA-32 Architectures Software Developer’s Manual: Volume 2. &#xA;                https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR30" id="ref-link-section-d59495552e5477">30</a>] compared to 218 opcodes in Dalvik [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Google: Dalvik. &#xA;                https://source.android.com/devices/tech/dalvik/dalvik-bytecode.html&#xA;                &#xA;              . Accessed April 2020" href="#ref-CR26" id="ref-link-section-d59495552e5480">26</a>], fewer instructions are likely to be needed by Dalvik for standard code constructs such as switch statements or for loops. These architectural differences are further motivation to select <i>s</i>
<sub><i>o</i></sub> = 8 over a unnecessarily longer filter length of 16 or 32.</p><p>The number of filters <i>r</i> affects the network’s ability to learn a diverse set of features from the opcode sequences. This may be especially important if different malware families do not share many common characteristics, thus requiring different sequences of opcodes to be detected. All other network hyper-parameters are held constant while the number of filters is varied from <i>r</i> = 2 to <i>r</i> = 128 in powers of two. Note that regardless of the number of filters used, they are all of length <i>s</i>
<sub><i>o</i></sub> = 8. As per Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig6">6</a>, the trend is an increase in F1 as the number of filters is increased. Approximately a 10% improvement in F1 is seen when moving from <i>r</i> = 2 to <i>r</i> = 128 filters. Performance plateaus at around 32 filters. Therefore, <i>r</i> = 64 filters are used to ensure satisfactory performance while keeping the number of parameters small, thus reducing the chance of overfitting.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-6" data-title="Fig. 6"><figure><figcaption><b id="Fig6" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 6</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="210"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-6-desc"><p>Hyperparameter tuning for <i>r</i>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec24"><span class="c-article-section__title-number">5.1.2 </span>Embedding Dimension <i>k</i>
<sub><i>o</i></sub>
</h4><p>The embedding layer takes a list of raw opcodes and learns to represent each opcode as a vector in an embedding space. The dimension of the embedding space <i>k</i>
<sub><i>o</i></sub> affects the network’s internal representation of opcodes. In this experiment the dimension of the embedding space is varied from <i>k</i>
<sub><i>o</i></sub> = 2 to <i>k</i>
<sub><i>o</i></sub> = 16 in powers of two. Furthermore, to validate the use of the embedding layer, an experiment with no embedding layer is performed—note that in this case each opcode is simply represented using its corresponding index value, i.e. a real number in the range 1 to 218, and thus filters of size <i>s</i>
<sub><i>o</i></sub> × 1 are used. From Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig7">7</a> firstly it can be seen that use of the embedding layer is crucial to good performance. Once an embedding layer is used, there is only a weak correlation between increasing the embedding dimension and increasing F1.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-7" data-title="Fig. 7"><figure><figcaption><b id="Fig7" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 7</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig7_HTML.png?as=webp"><img aria-describedby="Fig7" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="241"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-7-desc"><p>Hyperparameter tuning for <i>k</i>
<sub><i>o</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/7" data-track-dest="link:Figure7 Full size image" aria-label="Full size image figure 7" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>This may be due to the fact that there are only a relatively small number of possible opcodes, with many opcodes representing similar underlying instructions. This contrasts with human language, where high dimensional embeddings are needed to encode the rich semantic relationships between words [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Mikolov, T., Chen, K., Corrado, G.S., Dean, J.: Efficient estimation of word representations in vector space (2013). CoRR abs/1301.3781" href="#ref-CR46" id="ref-link-section-d59495552e5622">46</a>]. The results of this experiment indicate that, while using an embedding layer produces much better F1 performance, the use of a high-dimensional embedding is not required. Therefore a small embedding can be used, and <i>k</i>
<sub><i>o</i></sub> is set to 8, which in turn reduces the number of parameters in the opcodes CNN, and hence the network may generalize better to new data.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec25"><span class="c-article-section__title-number">5.1.3 </span>Number of Convolutional Layers <i>l</i>
</h4><p>In this experiment the number of convolutional layers, <i>l</i>, is varied from <i>l</i> = 1 to <i>l</i> = 6, while the number of convolutional filters and their length are held constant at <i>r</i> = 64 and <i>s</i>
<sub><i>o</i></sub> = 8 for all layers. Increasing the number of layers potentially allows the network to learn increasingly complex relationships between widely separated parts of the opcode sequence, by increasing the receptive field of the deeper filters.</p><p>However, the results in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig8">8</a> show that performance does not significantly improve when adding more layers. This suggests that, at least in the Malgenome dataset being used for tuning, features based on sequences of consecutive opcodes are sufficient for the task of malware detection.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-8" data-title="Fig. 8"><figure><figcaption><b id="Fig8" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 8</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig8_HTML.png?as=webp"><img aria-describedby="Fig8" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="248"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-8-desc"><p>Hyperparameter tuning for <i>l</i>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/8" data-track-dest="link:Figure8 Full size image" aria-label="Full size image figure 8" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Higher level features, based on the combinations and ordering of sets of lower level features, appear not to be required. For static analysis this may be expected as the large-scale ordering of instructions, classes and other program constructs when coded originally is only loosely related to how those instructions are then executed at run-time after compilation. As a result of this experiment, only one layer in the opcodes CNN in used, since adding more layers will only increase the number of parameters, hence increasing the likelihood of over-fitting, while also reducing computational efficiency.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec26"><span class="c-article-section__title-number">5.1.4 </span>Effect of Max-Pooling Layer <i>e</i>
</h4><p>Using max-pooling after the convolutional layer serves two main purposes. Firstly, it allows any program, regardless of the length, to be represented as a fixed-length feature vector, which is a prerequisite to enable classification. Given that each Android app has a different number of instructions, this normalisation is required. Secondly, by only selecting the maximum activation of each convolution, the presence of a relevant sequence of opcodes can be detected anywhere in the program regardless of its location. However, compressing the full feature map, which gives magnitude of activation and location of each filter response, down to just the maximum activation value from each filter may discard too much potentially relevant information, such as the repetition of the relevant opcode sequence over the program length. To validate the max-pooling approach and explore alternatives that may retain additional information, a comparison is made between the performance of max-pooling over the full length, also known as global max-pooling, and max-pooling applied over regular program segments. This alternative max-pooling approach aims to preserve more information as well as enable the network to detect repetitions of filter activations.</p><p>For this experiment, the full program length is divided in a given number of segments <i>e</i>, where <i>e</i> = 1 is equivalent to the default of max-pooling over all instructions, and <i>e</i> = <i>n</i> corresponds to dividing the full program length into <i>n</i> equal sized blocks, before applying max-pooling to each block. The length of the feature vector passed to the classifier is thus <i>e</i> × <i>m</i>. Note each app has a different number of opcodes, and each program is divided into the same number of segments, therefore the segment length will vary depending on each individual program length. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig9">9</a> indicates changing the number of segments, <i>e</i>, does not significantly affect performance. Hence these results justify the architectural choice of applying the max-pooling over the full program length.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-9" data-title="Fig. 9"><figure><figcaption><b id="Fig9" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 9</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/9" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig9_HTML.png?as=webp"><img aria-describedby="Fig9" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig9_HTML.png" alt="figure 9" loading="lazy" width="685" height="236"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-9-desc"><p>Hyperparameter tuning for <i>e</i>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/9" data-track-dest="link:Figure9 Full size image" aria-label="Full size image figure 9" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec27"><span class="c-article-section__title-number">5.1.5 </span>Input Length <i>n</i>
<sub><i>o</i></sub>
</h4><p>Accurate classification decisions may not require the entire sequence of an app’s opcodes. Instead it may be possible to detect malware by examining only a short sample of contiguous instructions from the complete program. This improves computational efficiency and could be useful in the future design of a cascade classifier [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Viola, P., Jones, M.J.: Rapid object detection using a boosted cascade of simple features. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 511–518. IEEE, Piscataway (2001)" href="#ref-CR65" id="ref-link-section-d59495552e5777">65</a>] where certain programs likely to be benign are quickly excluded from further consideration, while programs that appear malicious are examined more thoroughly. To study how performance is affected by limiting the number of opcodes <i>n</i>
<sub><i>o</i></sub> seen by the network, the maximum input length of the opcode sequence for each app is varied from <i>n</i>
<sub><i>o</i></sub> = 256 to <i>n</i>
<sub><i>o</i></sub> = 524, 288, increasing two-fold for each step. Where the number of opcodes in an app is less than this maximum length, the full sequence is used. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig10">10</a> shows using longer lengths of opcode instructions improves performance.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-10" data-title="Fig. 10"><figure><figcaption><b id="Fig10" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 10</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/10" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig10_HTML.png?as=webp"><img aria-describedby="Fig10" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig10_HTML.png" alt="figure 10" loading="lazy" width="685" height="421"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-10-desc"><p>Hyperparameter tuning for <i>n</i>
<sub><i>o</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/10" data-track-dest="link:Figure10 Full size image" aria-label="Full size image figure 10" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>However it can also be seen even relatively short opcode sequences can be used to detect malware effectively, which may be useful in resource constrained Android environments such as smartphones or in-vehicle systems. As much higher orders of magnitude do not produce a large enough corresponding improvement in performance, the setting <i>n</i>
<sub><i>o</i></sub> = 8192 provides an optimal balance of performance and computation.</p><h3 class="c-article__sub-heading" id="Sec28"><span class="c-article-section__title-number">5.2 </span>APIs CNN</h3><p>Similar ablation studies are performed for the APIs CNN. The <i>APIs</i> feature set is used in this tuning step as it is the broadest and most arbitrary compared to <i>GoogleAPIs</i> and <i>AndroidAPIs</i>. To avoid overfitting, the selected optimal hyperparameter settings for <i>APIs</i> are then fixed and also used in the <i>GoogleAPIs</i> and <i>AndroidAPIs</i> CNNs in the later evaluations. Holding CNN hyperparameters constant for the architecture itself whilst varying the API features used allows fairer comparison between the discriminative capability of each API feature set. As with the opcodes CNN, the model hyperparameters are empirically set using the Malgenome dataset. In summary, the results are <i>s</i>
<sub><i>g</i></sub> = 8, <i>m</i> = 64 and <i>k</i>
<sub><i>g</i></sub> = 8, with the Intel dataset then used to empirically set the dictionary hyperparameters, resulting in <i>S</i> = 250, <i>T</i> = 1 and <i>n</i>
<sub><i>g</i></sub> = 10, 000. These are the default settings unless specified otherwise in an ablation.</p><p>In the first of these experiments, API sequences created from an unthresholded arbitary dictonary are used, before then introducing <i>S</i> and <i>T</i>. It is interesting to note some of the final APIs CNN hyperparameter settings are the same as for the opcodes CNN, though it should be stressed both were tuned independently. Perhaps this is to be expected on reflection, given the opcodes sequences and API sequences used in these ablation studies are derived from the same <i>.smali</i> files. For this reason a single convolutional layer and global max-pooling were again used, as both were already varied when tuning the opcodes CNN and thus these experiments were not repeated for the APIs CNN.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec29"><span class="c-article-section__title-number">5.2.1 </span>Filter Length <i>s</i>
<sub><i>g</i></sub> and Number of Filters <i>m</i>
</h4><p>Like the opcodes CNN, increasing the length of the convolutional filters allows the network to learn longer patterns of APIs and learn long-range dependencies between APIs, while the number of filters impacts the diversity of features learnt from the API sequences. The Malgenome dataset is used in this experiment and a grid search performed. The range of hyper-parameters in the grid search are: <i>s</i>
<sub><i>g</i></sub> = [4, 8, 16, 32] and <i>m</i> = [4, 8, 16, 32, 64]. The filter stride is held at 1, with <i>k</i>
<sub><i>g</i></sub> = 4 and <i>n</i>
<sub><i>g</i></sub> = 50. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig11">11</a> shows a noticeable F1 increase when <i>s</i>
<sub><i>g</i></sub> increases from 4 to 8, and when <i>m</i> = 64. Hence the settings are <i>s</i>
<sub><i>g</i></sub> = 8 and <i>m</i> = 64.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-11" data-title="Fig. 11"><figure><figcaption><b id="Fig11" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 11</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/11" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig11_HTML.png?as=webp"><img aria-describedby="Fig11" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig11_HTML.png" alt="figure 11" loading="lazy" width="685" height="390"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-11-desc"><p>Hyperparameter tuning for <i>s</i>
<sub><i>g</i></sub> and <i>m</i>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/11" data-track-dest="link:Figure11 Full size image" aria-label="Full size image figure 11" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec30"><span class="c-article-section__title-number">5.2.2 </span>Embedding Dimension <i>k</i>
<sub><i>g</i></sub>
</h4><p>The embedding layer learns to represent each API as a vector in an embedding space and the dimension of this space affects the model’s internal representation of APIs. Another grid search is performed using <i>k</i>
<sub><i>g</i></sub> = [2, 4, 8] and <i>T</i> = [1, 10, 50, 100, 250, 500]. The dictionary size <i>S</i> is held at 250 and for each dictionary threshold <i>T</i> the APIs sequences are adjusted to remove APIs not present in each resulting dictionary. The average length of a sequence across both malware and benign samples in the Malgenome dataset is around 6500 APIs. Therefore the input length <i>n</i>
<sub><i>g</i></sub> is set to 10,000, including zero padding where needed. As per Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig12">12</a>, when the F1 is averaged across all values of <i>T</i>, with the variability over <i>k</i>
<sub><i>g</i></sub> represented as a standard deviation bar around the mean, <i>k</i>
<sub><i>g</i></sub> = 8 performs best overall. Thus with a high-dimensional embedding not required, <i>k</i>
<sub><i>g</i></sub> is set to 8.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-12" data-title="Fig. 12"><figure><figcaption><b id="Fig12" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 12</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/12" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig12_HTML.png?as=webp"><img aria-describedby="Fig12" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig12_HTML.png" alt="figure 12" loading="lazy" width="685" height="231"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-12-desc"><p>Hyperparameter tuning for <i>k</i>
<sub><i>g</i></sub>, bars show <i>σ</i> over <i>k</i>
<sub><i>g</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/12" data-track-dest="link:Figure12 Full size image" aria-label="Full size image figure 12" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec31"><span class="c-article-section__title-number">5.2.3 </span>Dictionary Size <i>S</i>, Invocation Threshold <i>T</i> and Input Length <i>n</i>
<sub><i>g</i></sub>
</h4><p>In order to better investigate the influence of these hyperparameters, the Intel dataset is used as it is much larger than Malgenome. Here the grid search has the following hyper-parameters: <i>S</i> = [125, 250, 500, 750, 1000] and <i>T</i> = [1, 10, 50, 100, 250, 500, 1000, 1500]. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig13">13</a> shows the average F1 across all values of <i>S</i> as <i>T</i> increases, with the variability over <i>T</i> represented as a standard deviation bar around the mean. There is no clear choice for <i>T</i> since the impact of varying it is minimal, so it is set as <i>T</i> = 1. The selection of <i>S</i> = 250 is also made as this is the closest size to the opcodes dictionary of <i>d</i>
<sub><i>o</i></sub> = 218 and saves computation compared to using a larger <i>S</i>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-13" data-title="Fig. 13"><figure><figcaption><b id="Fig13" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 13</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/13" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig13_HTML.png?as=webp"><img aria-describedby="Fig13" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig13_HTML.png" alt="figure 13" loading="lazy" width="685" height="327"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-13-desc"><p>Hyperparameter tuning for <i>T</i>, bars show <i>σ</i> over <i>T</i>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/13" data-track-dest="link:Figure13 Full size image" aria-label="Full size image figure 13" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>With <i>S</i> and <i>T</i> then held constant, <i>n</i>
<sub><i>g</i></sub> is varied to study the effect of longer API input lengths. For the malicious samples in the Intel dataset, the average length of an API sequence varies from 8500 to 26,500 APIs, and for the benign samples the average length varies from 7000 to 20,200 APIs. The average length across both malware and benign samples varies from 8200 to 23,300 APIs. In this grid search <i>n</i>
<sub><i>g</i></sub> = [10, 000, 15, 000, 20, 000]. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig14">14</a> shows the improvement for longer API input lengths is minimal, and incurs extra computational cost, hence the setting of <i>n</i>
<sub><i>g</i></sub> = 10, 000 is made. Since the Intel dataset is real-world, it is asserted these dictionary and input length hyper-parameters are optimal for the experimental evaluations.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-14" data-title="Fig. 14"><figure><figcaption><b id="Fig14" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 14</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/14" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig14_HTML.png?as=webp"><img aria-describedby="Fig14" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig14_HTML.png" alt="figure 14" loading="lazy" width="685" height="142"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-14-desc"><p>Hyperparameter tuning for <i>n</i>
<sub><i>g</i></sub>
</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/14" data-track-dest="link:Figure14 Full size image" aria-label="Full size image figure 14" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec32"><span class="c-article-section__title-number">5.3 </span>Analysis of Features Learned by the Permission View</h3><p>No hyperparameters need tuned for the permissions network as all 138 specified permissions are used as input. However, an analysis is performed to validate the architecture has learned something meaningful and explore how the network’s internal knowledge can inform the Android malware domain. Note doing the same for the opcodes CNN or APIs CNN is difficult as the input information is at a very low level—while reverting to the sequences of opcodes or APIs that max-activate each filter is possible, linking back that usage directly in a meaningful manner is highly challenging, so such CNN analysis as left as future work. By comparison, the permission view weights are easier to associate with each permission’s importance for detecting malware or benign samples, and observations can be cross-referenced with previous literature. Each permission’s importance for discriminating between malware or benign samples is ranked, giving insight into what the model has learned. This is also a sanity check for the approach, as important permissions can be checked against the literature. If the neural network is using features in a similar way to an expert human malware analyst, this builds confidence in the model’s decisions. To create this ranking, each input neuron’s weights are averaged. As the permissions input is an ordered vector, each input neuron corresponds directly to one single permission. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig15">15</a> lists all permissions ordered by average weight.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-15" data-title="Fig. 15"><figure><figcaption><b id="Fig15" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 15</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/15" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig15_HTML.png?as=webp"><img aria-describedby="Fig15" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig15_HTML.png" alt="figure 15" loading="lazy" width="685" height="349"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-15-desc"><p>Android permissions ranked by relevance for malware classification</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/15" data-track-dest="link:Figure15 Full size image" aria-label="Full size image figure 15" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Averaging the weights in matrix <i>W</i>
<sub><i>p</i></sub> connected to each input neuron gives the importance of each permission. Stronger connections, i.e. larger weight values, mean the network ascribes more importance to a given permission. To prove the permissions view is learning meaningful features, the permissions deemed to be important by the model are compared with those from previous work. The permissions SEND_SMS and RECEIVE_SMS, ranked first and third most important by the model, have high mutual-information scores for malware detection [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e6302">74</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Yerima, S., Sezer, S., McWilliams, G., Muttik, I.: A new android malware detection approach using bayesian classification. In: Advanced Information Networking and Applications (AINA), 2013 IEEE 27th International Conference on, pp. 121–128. IEEE, Piscataway (2013)" href="#ref-CR72" id="ref-link-section-d59495552e6305">72</a>]. They are also ranked in the top-ten most important permissions in several other analyses [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Sanz, B., Santos, I., Laorden, C., Ugarte-Pedrero, X., Bringas, P.G., Marañón, G.A.: Puma: Permission usage to detect malware in android. In: CISIS/ICEUTE/SOCO Special Sessions 2012, Advances in Intelligent Systems and Computing, vol. 189, pp. 289–298. Springer, Berlin (2012)" href="#ref-CR56" id="ref-link-section-d59495552e6308">56</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Liu, X., Liu, J.: A two-layered permission-based android malware detection scheme. In: 2nd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering (MobileCloud), pp. 142–148. IEEE, Piscataway (2014)" href="#ref-CR40" id="ref-link-section-d59495552e6312">40</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Rosen, S., Qian, Z., Mao, Z.M.: Appprofiler: A flexible method of exposing privacy-related behavior in android applications to end users. In: Proceedings of the Third ACM Conference on Data and Application Security and Privacy, CODASPY ’13, pp. 221–232 (2013)" href="#ref-CR55" id="ref-link-section-d59495552e6315">55</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Zonouz, S., Houmansadr, A., Berthier, R., Borisov, N., Sanders, W.: Secloud: a cloud-based comprehensive and lightweight security solution for smartphones. Comput. Secur. 37, 215–227 (2013)" href="#ref-CR80" id="ref-link-section-d59495552e6318">80</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Felt, A.P., Finifter, M., Chin, E., Hanna, S., Wagner, D.: A survey of mobile malware in the wild. In: Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices, pp. 3–14. ACM, New York (2011)" href="#ref-CR19" id="ref-link-section-d59495552e6321">19</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Grace, M., Zhou, Y., Wang, Z., Jiang, X.: Systematic detection of capability leaks in stock android smartphones. In: NDSS Symposium 2012 (2012)" href="#ref-CR28" id="ref-link-section-d59495552e6324">28</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Peng, H., Gates, C., Sarma, B., Li, N., Qi, Y., Potharaju, R., Nita-Rotaru, C., Molloy, I.: Using probabilistic generative models for ranking risks of android apps. In: Proceedings of the 2012 ACM Conference on Computer and Communications Security, pp. 241–252. ACM, New York (2012)" href="#ref-CR53" id="ref-link-section-d59495552e6327">53</a>]. Similarly, permissions with highly negative importance values according to the model are also found to be important in the literature: READ_PHONE_STATE and ACCESS_NETWORK_STATE [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e6331">74</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Yerima, S., Sezer, S., McWilliams, G., Muttik, I.: A new android malware detection approach using bayesian classification. In: Advanced Information Networking and Applications (AINA), 2013 IEEE 27th International Conference on, pp. 121–128. IEEE, Piscataway (2013)" href="#ref-CR72" id="ref-link-section-d59495552e6334">72</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Zhou, Y., Jiang, X.: Dissecting android malware: characterization and evolution. In: 2012 IEEE Symposium on Security and Privacy (SP), pp. 95–109. IEEE, Piscataway (2012)" href="#ref-CR78" id="ref-link-section-d59495552e6337">78</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Peiravian, N., Zhu, X.: Machine learning for android malware detection using permission and api calls. In: 2013 IEEE 25th International Conference on Tools with Artificial Intelligence, pp. 300–305 (2013)" href="#ref-CR52" id="ref-link-section-d59495552e6340">52</a>], CALL_PHONE [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Liu, X., Liu, J.: A two-layered permission-based android malware detection scheme. In: 2nd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering (MobileCloud), pp. 142–148. IEEE, Piscataway (2014)" href="#ref-CR40" id="ref-link-section-d59495552e6343">40</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Peiravian, N., Zhu, X.: Machine learning for android malware detection using permission and api calls. In: 2013 IEEE 25th International Conference on Tools with Artificial Intelligence, pp. 300–305 (2013)" href="#ref-CR52" id="ref-link-section-d59495552e6346">52</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e6350">74</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Yerima, S., Sezer, S., McWilliams, G., Muttik, I.: A new android malware detection approach using bayesian classification. In: Advanced Information Networking and Applications (AINA), 2013 IEEE 27th International Conference on, pp. 121–128. IEEE, Piscataway (2013)" href="#ref-CR72" id="ref-link-section-d59495552e6353">72</a>] and INTERNET [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Sanz, B., Santos, I., Laorden, C., Ugarte-Pedrero, X., Bringas, P.G., Marañón, G.A.: Puma: Permission usage to detect malware in android. In: CISIS/ICEUTE/SOCO Special Sessions 2012, Advances in Intelligent Systems and Computing, vol. 189, pp. 289–298. Springer, Berlin (2012)" href="#ref-CR56" id="ref-link-section-d59495552e6356">56</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Zhou, Y., Jiang, X.: Dissecting android malware: characterization and evolution. In: 2012 IEEE Symposium on Security and Privacy (SP), pp. 95–109. IEEE, Piscataway (2012)" href="#ref-CR78" id="ref-link-section-d59495552e6359">78</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Barrera, D., Kayacik, H.G., van Oorschot, P.C., Somayaji, A.: A methodology for empirical analysis of permission-based security models and its application to android. In: Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 73–84. ACM, New York (2010)" href="#ref-CR8" id="ref-link-section-d59495552e6362">8</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Peiravian, N., Zhu, X.: Machine learning for android malware detection using permission and api calls. In: 2013 IEEE 25th International Conference on Tools with Artificial Intelligence, pp. 300–305 (2013)" href="#ref-CR52" id="ref-link-section-d59495552e6365">52</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Felt, A.P., Greenwood, K., Wagner, D.: The effectiveness of application permissions. In: Proceedings of the 2Nd USENIX Conference on Web Application Development, p. 7 (2011)" href="#ref-CR20" id="ref-link-section-d59495552e6369">20</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Peng, H., Gates, C., Sarma, B., Li, N., Qi, Y., Potharaju, R., Nita-Rotaru, C., Molloy, I.: Using probabilistic generative models for ranking risks of android apps. In: Proceedings of the 2012 ACM Conference on Computer and Communications Security, pp. 241–252. ACM, New York (2012)" href="#ref-CR53" id="ref-link-section-d59495552e6372">53</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e6375">74</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Yerima, S., Sezer, S., McWilliams, G., Muttik, I.: A new android malware detection approach using bayesian classification. In: Advanced Information Networking and Applications (AINA), 2013 IEEE 27th International Conference on, pp. 121–128. IEEE, Piscataway (2013)" href="#ref-CR72" id="ref-link-section-d59495552e6378">72</a>]. Finally, SYSTEM_ALERT_WINDOW, given the second largest value by the model, is linked to ‘Cloak and Dagger’ attacks [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Fratantonio, Y., Qian, C., Chung, S.P., Lee, W.: Cloak and dagger: from two permissions to complete control of the UI feedback loop. In: 2017 IEEE Symposium on Security and Privacy (SP), pp. 1041–1057 (2017)" href="#ref-CR21" id="ref-link-section-d59495552e6381">21</a>].</p></div></div></section><section data-title="Experimental Results: Final Model and State-of-the-art Comparisons"><div class="c-article-section" id="Sec33-section"><h2 id="Sec33" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">6 </span>Experimental Results: Final Model and State-of-the-art Comparisons</h2><div class="c-article-section__content" id="Sec33-content"><p>A thorough evaluation of the proposed multi-view approach is now performed using the two standard publicly available benchmark datasets Drebin [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e6394">7</a>] and AMD [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Wei, F., Li, Y., Roy, S., Ou, X., Zhou, W.: Deep ground truth analysis of current android malware. In: International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA’17), pp. 252–276. Springer, Bonn (2017)" href="#ref-CR68" id="ref-link-section-d59495552e6397">68</a>]. A state-of-the-art comparison is presented and a zero-day setting evaluates the network under challenging realistic conditions. Hyperparameter values used in all experiments are set as per previous, that is, <i>n</i>
<sub><i>o</i></sub> = 8192, <i>s</i>
<sub><i>o</i></sub> = 8, <i>k</i>
<sub><i>o</i></sub> = 8, <i>m</i> = 64, <i>o</i>
<sub><i>o</i></sub> = 16, <i>n</i>
<sub><i>g</i></sub> = 10, 000, <i>s</i>
<sub><i>g</i></sub> = 8, <i>k</i>
<sub><i>g</i></sub> = 8, <i>r</i> = 64, <i>o</i>
<sub><i>g</i></sub> = 16, <i>S</i> = 250, <i>T</i> = 1, <i>o</i>
<sub><i>p</i></sub> = 64, and <i>o</i>
<sub><i>h</i></sub> = 16, plus <i>B</i> = 1, <i>α</i> = 0.001 and a filter stride in both CNNs of 1. No further tuning is carried out, and each model is trained for 75 epochs. The metrics reported are on the unseen Drebin and AMD testing splits.</p><h3 class="c-article__sub-heading" id="Sec34"><span class="c-article-section__title-number">6.1 </span>Single-View Model Detection Performance</h3><p>The evaluations start with the performance of a series of single-view models learning from only one of the input feature sets. Similarly, the three presented API feature extraction methods are compared. This creates a baseline to compare the multi-view models to, and confirms to what degree each of these feature sets are useful in isolation. For Drebin and AMD separately, each single-view model is trained using the training set and then tested with the unseen testing set.</p><p>Results in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab2">2</a> show each of the feature sets are indeed effective for malware detection, with Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig16">16</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig17">17</a> showing the F1 and FP% rate comparisons respectively.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-16" data-title="Fig. 16"><figure><figcaption><b id="Fig16" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 16</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/16" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig16_HTML.png?as=webp"><img aria-describedby="Fig16" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig16_HTML.png" alt="figure 16" loading="lazy" width="685" height="280"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-16-desc"><p>Single-view F1 comparison</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/16" data-track-dest="link:Figure16 Full size image" aria-label="Full size image figure 16" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-17" data-title="Fig. 17"><figure><figcaption><b id="Fig17" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 17</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/17" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig17_HTML.png?as=webp"><img aria-describedby="Fig17" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig17_HTML.png" alt="figure 17" loading="lazy" width="685" height="218"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-17-desc"><p>Single-view FP% rate comparison</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/17" data-track-dest="link:Figure17 Full size image" aria-label="Full size image figure 17" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div> <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption class="c-article-table__figcaption"><b id="Tab2" data-test="table-caption">Table 2 Detection performance and FP % rate of single-view models</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/2" aria-label="Full size table 2"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>For the Drebin apps, while performance is strong across the board, it can be seen that the APIs methods which use <i>GoogleAPIs</i> and <i>AndroidAPIs</i> give the best F1 scores and FP% rates. For the AMD apps, the <i>GoogleAPIs</i> and <i>AndroidAPIs</i> again perform best, with particularly low FP% rates. With the AMD dataset being five times larger than Drebin, it is perhaps to be expected the AMD metrics are better by comparison since there are more apps to learn from in the training phase. It is concluded each single-view model performs well on both the Drebin and AMD datasets. Interestingly these results show the discriminative power of the <i>AndroidAPIs</i>, despite using the limited proprietary set of only 210 APIs, much smaller than the other API methods, resulting in similar or better detection performance with lower computational cost. It is worth recalling too that the dictionaries used in <i>APIs</i> and <i>GoogleAPIs</i> need some arbitrary and/or empirical decision-making. The benefit of <i>AndroidAPIs</i> is that these decisions are avoided entirely, as there only are 210 APIs to start with.</p><h3 class="c-article__sub-heading" id="Sec35"><span class="c-article-section__title-number">6.2 </span>Multi-View Model Detection Performance</h3><p>Next the single-view features are combined in a multi-view model to assess how performance is impacted versus using only one feature set in isolation. Having established the input feature sets are of use individually in single-view, it is expected there may be some difference in performance if more than one is used, which would show the feature sets are complementary. Thus in this experiment the proposed feature sets are combined to see if detection can be improved and the FP rate reduced. Results in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab3">3</a>, Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig18">18</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig19">19</a> show that for both the Drebin and AMD datasets, combining feature sets always results in a performance improvement, since the network learns to use them in a complementary way during training.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-18" data-title="Fig. 18"><figure><figcaption><b id="Fig18" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 18</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/18" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig18_HTML.png?as=webp"><img aria-describedby="Fig18" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig18_HTML.png" alt="figure 18" loading="lazy" width="685" height="272"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-18-desc"><p>Multi-view F1 comparison</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/18" data-track-dest="link:Figure18 Full size image" aria-label="Full size image figure 18" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-19" data-title="Fig. 19"><figure><figcaption><b id="Fig19" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 19</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/19" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig19_HTML.png?as=webp"><img aria-describedby="Fig19" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig19_HTML.png" alt="figure 19" loading="lazy" width="685" height="219"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-19-desc"><p>Multi-view FP% rate comparison</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/19" data-track-dest="link:Figure19 Full size image" aria-label="Full size image figure 19" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div> <div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption class="c-article-table__figcaption"><b id="Tab3" data-test="table-caption">Table 3 Detection performance and FP% rate of multi-view models</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/3" aria-label="Full size table 3"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>Among the three API feature extraction methods, <i>AndroidAPIs</i> results in the most successful combination with a significant decrease in false positives, i.e. false alarms, which is a critical factor in real-world detector deployments. Again, <i>AndroidAPIs</i> also does not involve arbitrary decisions regarding API selection as it is a limited, pre-defined set of 210, reducing the number of hyperparameters to use and simplifying updates to the model, since the dictionary does not need to be revised or recalculated for new samples or datasets.</p><h3 class="c-article__sub-heading" id="Sec36"><span class="c-article-section__title-number">6.3 </span>State-of-the-Art Comparison: Malware Detection</h3><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab4">4</a> shows a comparison of the proposed multi-view approach against state-of-the-art methods using the Drebin and AMD benchmark datasets in a conventional detection setting, where all families are in both training and testing. Direct comparisons are performed using the Drebin detector [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e7174">7</a>], Maldozer [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Karbab, E.B., Debbabi, M., Derhab, A., Mouheb, D.: Maldozer: Automatic framework for android malware detection using deep learning. Digital Invest. 24, S48–S59 (2018)" href="#ref-CR34" id="ref-link-section-d59495552e7177">34</a>] and [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. 9(6), 313–320 (2015)" href="#ref-CR74" id="ref-link-section-d59495552e7180">74</a>] (referred to as APIs56). It is ensured the same experimental setting and dataset splits used in the experiments thus far are also used to evaluate these other methods. Note the Maldozer paper does not disclose its model’s input sequence length or batch size, and not enough detail is present to recreate their API dictionary of 100,000 APIs with embedding size 64. Thus the Maldozer network architecture for detection is replicated, including the use of word2vec [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Mikolov, T., Chen, K., Corrado, G.S., Dean, J.: Efficient estimation of word representations in vector space (2013). CoRR abs/1301.3781" href="#ref-CR46" id="ref-link-section-d59495552e7183">46</a>] when training the embedding layer, with the input features being <i>AndroidAPIs</i>. In all other cases, comparisons are made versus the reported results in the respective papers. </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption class="c-article-table__figcaption"><b id="Tab4" data-test="table-caption">Table 4 State-of-the-art comparison in conventional detection setting</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/4" aria-label="Full size table 4"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>On the Drebin dataset, the multi-view model achieves the highest F1 and the lowest FP rate of only 1.05%. This is 60% less than the Drebin FP rate, 50% less than the Maldozer FP rate, and 83% less than <i>APIs56</i>. The MaMaDroid [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Mariconti, E., Onwuzurike, L., Andriotis, P., Cristofaro, E.D., Ross, G.J., Stringhini, G.: Mamadroid: Detecting android malware by building Markov chains of behavioral models. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2017 (2017)" href="#ref-CR43" id="ref-link-section-d59495552e8243">43</a>] and DroidAPIMiner [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Aafer, Y., Du, W., Yin, H.: Droidapiminer: Mining API-level features for robust malware detection in android. In: Security and Privacy in Communication Networks. 9th International ICST Conference, SecureComm 2013 (2014)" href="#ref-CR1" id="ref-link-section-d59495552e8246">1</a>] F1 scores are 0.96 and 0.32 respectively, with [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Martinelli, F., Marulli, F., Mercaldo, F.: Evaluating convolutional neural network for effective mobile malware detection. Procedia Comput. Sci. 112(C), 2372–2381 (2017)" href="#ref-CR44" id="ref-link-section-d59495552e8249">44</a>] using only 10 of the Drebin families in evaluating their model, giving an accuracy of 0.78. These performance gains are due to the multi-view model learning better from the three input feature sets, and the fact there are no hand-crafted features, allowing the model to encapsulate internally its own representation of malware and benign characteristics without expert human analysis beforehand. With the AMD dataset, the multi-view model again achieves a near-perfect F1 whilst giving a FP rate of only 0.08%. This is a 79% reduction compared to the best performing other model in that regard, which is Maldozer, and compared to the neural net in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Ma, Z., Ge, H., Liu, Y., Zhao, M., Ma, J.: A combination method for android malware detection based on control flow graphs and machine learning algorithms. IEEE Access 7, 21235–21245 (2019)" href="#ref-CR41" id="ref-link-section-d59495552e8252">41</a>], this is a 99% reduction. The FP rate is 97% lower than the best FP rate using the LSTM reported in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Ma, Z., Ge, H., Liu, Y., Zhao, M., Ma, J.: A combination method for android malware detection based on control flow graphs and machine learning algorithms. IEEE Access 7, 21235–21245 (2019)" href="#ref-CR41" id="ref-link-section-d59495552e8256">41</a>]. Also, the multi-view model is likely to train faster than LSTMs, since recurrent architectures are known to be comparatively slow to train [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Goodfellow, I., Bengio, Y., Courville, A.: Sequence modelling: recurrent and recursive nets. In: Deep Learning, pp. 371–372. MIT Press, Cambridge (2016)" href="#ref-CR24" id="ref-link-section-d59495552e8259">24</a>]. Notably, the F1 of APIs56 on AMD samples is lower than its F1 on the Drebin samples, and indeed much lower than the multi-view model. Given the Drebin dataset consists of samples discovered from 2010 to 2012, with the AMD dataset consisting of samples discovered from 2010 to 2016, it could be said APIs56 is a possible example of a detection system that, since it uses manually hand-crafted features from a snapshot in time, is vulnerable to aging and becoming out-of-date. Lastly, considering the average figures it can be seen the multi-view model achieves the highest F1 of 0.9947 and the lowest FP rate of 0.57%, which in relative terms is 77% less on average compared to the state-of-the-art.</p><p>In addition to this compelling quantitative performance, there are further qualitative comparisons to be made regarding the differences in the amount of human domain expertise used in creating the input feature sets. The use of opcodes, permissions and <i>AndroidAPIs</i> implicitly means malware domain expertise has been decoupled, since these three input feature sets are only extracted in their raw form, not statistically ranked, refined or pre-categorised by an expert. The <i>AndroidAPIs</i> feature set is very likely to perpetuate over time as they are intrinsically linked to the core of the Android platform—they are proprietary and are much less likely to change. By comparison, from the Drebin detector codebase there appears to be handcrafting of input features to create eight different feature sets: <i>suspicious API calls, restricted API calls, hardware features, requested permissions, app components, filtered intents, used permissions, and network addresses.</i> On the other hand, the presented multi-view approach does not require any such malware detection insights. Finally, with regards to a real-world implementation of this model, once this multi-view architecture has been trained, large numbers of files can be efficiently scanned using a GPU. The model can classify an app in 1 millisecond using an NVIDIA 1080TI GPU, eight times faster than using a standard Intel Core i7-8700 CPU, which can classify an app in 8 milliseconds. In addition, a mobile app of this malware detector, running on a Google Pixel device, has been developed [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="GSMA: Mobile Scholar 2019 Finalists. &#xA;                https://vimeo.com/325173012&#xA;                &#xA;              . Accessed July 2020" href="#ref-CR29" id="ref-link-section-d59495552e8274">29</a>].</p><h3 class="c-article__sub-heading" id="Sec37"><span class="c-article-section__title-number">6.4 </span>Zero-Day Scenario Evaluation</h3><p>Arp et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e8286">7</a>] included a zero-day experiment where the top 20 largest families in the Drebin dataset were selected, with each in turn left out of the training process. That same unseen held-out family was then used in testing. Using both the Drebin and AMD datasets, this experiment is recreated using the same zero-day technique. The architecture used is the multi-view model using opcodes, permissions and <i>AndroidAPIs</i>. For the state-of-the-art comparison, the Drebin detector and Maldozer are selected. The original zero-day experiment is extended to evaluate not only the top 20 largest families per [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)" href="#ref-CR7" id="ref-link-section-d59495552e8292">7</a>], but in fact all 178 families in the Drebin dataset, and all 71 families in the AMD dataset. The metric is the detection rate, calculated as the % of malicious samples in test correctly classified as malware. A weighted average is used when reporting results as the number of samples per family varies widely, shown in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig20">20</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="#Fig21">21</a>. The detection rate for each family is therefore weighted by the number of available samples for that family in relation to the total number of samples in the dataset.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-20" data-title="Fig. 20"><figure><figcaption><b id="Fig20" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 20</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/20" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig20_HTML.png?as=webp"><img aria-describedby="Fig20" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig20_HTML.png" alt="figure 20" loading="lazy" width="685" height="327"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-20-desc"><p>Number of samples per family in the Drebin dataset</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/20" data-track-dest="link:Figure20 Full size image" aria-label="Full size image figure 20" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-21" data-title="Fig. 21"><figure><figcaption><b id="Fig21" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 21</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/21" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig21_HTML.png?as=webp"><img aria-describedby="Fig21" src="//media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-031-15030-2_10/MediaObjects/517032_1_En_10_Fig21_HTML.png" alt="figure 21" loading="lazy" width="685" height="320"></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-21-desc"><p>Number of samples per family in the AMD dataset</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="chapter-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/chapter/10.1007/978-3-031-15030-2_10/figures/21" data-track-dest="link:Figure21 Full size image" aria-label="Full size image figure 21" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<h3 class="c-article__sub-heading" id="Sec38"><span class="c-article-section__title-number">6.5 </span>State-of-the-Art Comparison: Zero-Day Scenario</h3><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec39"><span class="c-article-section__title-number">6.5.1 </span>Drebin Dataset Zero-Day Evaluation</h4><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab5">5</a> shows the results for the Drebin dataset, with detection performance calculated across the 20 largest families and also calculated across all 178 families. </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption class="c-article-table__figcaption"><b id="Tab5" data-test="table-caption">Table 5 Zero-day detection performance on Drebin dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/5" aria-label="Full size table 5"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>For the largest 20 families, the multi-view model using opcodes, permissions and <i>AndroidAPIs</i> has a weighted detection average of 91%, a significant improvement on Drebin and Maldozer, scoring 53% and 86% respectively. Furthermore, when this experiment is expanded across the whole Drebin dataset of 178 families, strong performance is maintained and the multi-view model performs best when considering the variation in family size by using the weighted average.</p><h4 class="c-article__sub-heading c-article__sub-heading--small" id="Sec40"><span class="c-article-section__title-number">6.5.2 </span>AMD Dataset Zero-Day Evaluation</h4><p>Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="#Tab6">6</a> contains the detection performance for the AMD dataset top 20 largest families and across the full 71 families. </p><div class="c-article-table" data-test="inline-table" data-container-section="table" id="table-6"><figure><figcaption class="c-article-table__figcaption"><b id="Tab6" data-test="table-caption">Table 6 Zero-day detection performance on AMD dataset</b></figcaption><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="table-link" data-track="click" data-track-action="view table" data-track-label="button" rel="nofollow" href="/chapter/10.1007/978-3-031-15030-2_10/tables/6" aria-label="Full size table 6"><span>Full size table</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
<p>It can be seen the multi-view model has a weighted detection rate of 81% for the largest 20 families, better than the Drebin detector and Maldozer. When considering all 71 families in the AMD dataset, this performance gain is maintained, with the multi-view model scoring a weighted detection rate of 81% compared to the Drebin and Maldozer scores, both of which are only 75%. The superior performance of the proposed system in this complex zero-day setting seems to confirm that the multi-view neural architecture extracts improved and more discriminative features during training with less over-fitting. This results in an approach that is able to generalise better against new threats and malware families that have never been seen, where signature-based systems will likely fail.</p></div></div></section><section data-title="Conclusions"><div class="c-article-section" id="Sec41-section"><h2 id="Sec41" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number">7 </span>Conclusions</h2><div class="c-article-section__content" id="Sec41-content"><p>This chapter presents a multi-view CNN for static Android malware analysis learning from opcodes, permissions and proprietary Android APIs. The experiments show several relevant conclusions. Firstly, the use of deep learning architectures makes it possible to reach state-of-art results in automatic malware detection, while reducing the dependency of feature engineering and domain expertise. This system can be better trained and be easily updated against new threats by simply collecting more samples. Secondly, using multi-view compared to single-view architectures improves performance since the model is exposed to simultaneous sources of information and can learn a more effective set of features. Finally, the model achieves state-of-the art detection performance in a challenging zero-day scenario compared to the Drebin and Maldozer detectors, with the key takeaway being this architecture can reduce over-fitting to the training set and generalise better to effectively detect unseen malware families. The presented model is able to protect better against these new malware families, where signature-based systems will almost certainly fail, and other more traditional ML approaches will struggle. Our method reduces false positives by 77% in relative terms on average compared to others, an important metric for potential real-world deployment, with the network also achieving state-of-the art performance in the conventional task of malware detection whilst decoupling domain insights.</p></div></div></section>
                        </div>
                    
                

                <div id="MagazineFulltextChapterBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 id="Bib1" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references" data-track-component="outbound reference"><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="1."><p class="c-article-references__text" id="ref-CR1">Aafer, Y., Du, W., Yin, H.: Droidapiminer: Mining API-level features for robust malware detection in android. In: Security and Privacy in Communication Networks. 9th International ICST Conference, SecureComm 2013 (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR1-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Aafer%2C%20Y.%2C%20Du%2C%20W.%2C%20Yin%2C%20H.%3A%20Droidapiminer%3A%20Mining%20API-level%20features%20for%20robust%20malware%20detection%20in%20android.%20In%3A%20Security%20and%20Privacy%20in%20Communication%20Networks.%209th%20International%20ICST%20Conference%2C%20SecureComm%202013%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="2."><p class="c-article-references__text" id="ref-CR2">Afonso, V., Amorim, M., Grégio, A., Junquera, G., De Geus, P.: Identifying android malware using dynamically obtained features. J. Comput. Virol. Hacking Tech. <b>11</b>, 9–17 (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR2-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s11416-014-0226-7" data-track-action="CrossRef reference" href="https://doi.org/10.1007%2Fs11416-014-0226-7" aria-label="CrossRef reference 2" data-doi="10.1007/s11416-014-0226-7">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="https://scholar.google.com/scholar_lookup?&amp;title=Identifying%20android%20malware%20using%20dynamically%20obtained%20features&amp;journal=J.%20Comput.%20Virol.%20Hacking%20Tech.&amp;volume=11&amp;pages=9-17&amp;publication_year=2014&amp;author=Afonso%2CV&amp;author=Amorim%2CM&amp;author=Gr%C3%A9gio%2CA&amp;author=Junquera%2CG&amp;author=Geus%2CP">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="3."><p class="c-article-references__text" id="ref-CR3">Alazab, M., Alazab, M., Shalaginov, A., Mesleh, A., Awajan, A.: Intelligent mobile malware detection using permission requests and API calls. Future Generation Computer Systems <b>107</b>, 509–521 (2020)</p><p class="c-article-references__links u-hide-print" id="ref-CR3-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.future.2020.02.002" data-track-action="CrossRef reference" href="https://doi.org/10.1016%2Fj.future.2020.02.002" aria-label="CrossRef reference 3" data-doi="10.1016/j.future.2020.02.002">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="https://scholar.google.com/scholar_lookup?&amp;title=Intelligent%20mobile%20malware%20detection%20using%20permission%20requests%20and%20API%20calls&amp;journal=Future%20Generation%20Computer%20Systems&amp;volume=107&amp;pages=509-521&amp;publication_year=2020&amp;author=Alazab%2CM&amp;author=Alazab%2CM&amp;author=Shalaginov%2CA&amp;author=Mesleh%2CA&amp;author=Awajan%2CA">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="4."><p class="c-article-references__text" id="ref-CR4">Allix, K., Jerome, Q., Bissyandé, T.F., Klein, J., State, R., Traon, Y.L.: A forensic analysis of android malware—how is malware written and how it could be detected? In: 2014 IEEE 38th Annual Computer Software and Applications Conference, pp. 384–393 (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR4-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Allix%2C%20K.%2C%20Jerome%2C%20Q.%2C%20Bissyand%C3%A9%2C%20T.F.%2C%20Klein%2C%20J.%2C%20State%2C%20R.%2C%20Traon%2C%20Y.L.%3A%20A%20forensic%20analysis%20of%20android%20malware%E2%80%94how%20is%20malware%20written%20and%20how%20it%20could%20be%20detected%3F%20In%3A%202014%20IEEE%2038th%20Annual%20Computer%20Software%20and%20Applications%20Conference%2C%20pp.%20384%E2%80%93393%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="5."><p class="c-article-references__text" id="ref-CR5">Alzaylaee, M.K., Yerima, S.Y., Sezer, S.: Emulator vs real phone: android malware detection using machine learning. In: Proceedings of the 3rd ACM on International Workshop on Security And Privacy Analytics, IWSPA ’17, pp. 65–72. ACM, New York (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR5-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Alzaylaee%2C%20M.K.%2C%20Yerima%2C%20S.Y.%2C%20Sezer%2C%20S.%3A%20Emulator%20vs%20real%20phone%3A%20android%20malware%20detection%20using%20machine%20learning.%20In%3A%20Proceedings%20of%20the%203rd%20ACM%20on%20International%20Workshop%20on%20Security%20And%20Privacy%20Analytics%2C%20IWSPA%20%E2%80%9917%2C%20pp.%2065%E2%80%9372.%20ACM%2C%20New%20York%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="6."><p class="c-article-references__text" id="ref-CR6">Apktool: Apktool—a tool for reverse engineering 3rd party, closed, binary Android aps. <a href="https://ibotpeaches.github.io/Apktool/">https://ibotpeaches.github.io/Apktool/</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="7."><p class="c-article-references__text" id="ref-CR7">Arp, D., Spreitzenbarth, M., Hubner, M., Gascon, H., Rieck, K.: Drebin: effective and explainable detection of android malware in your pocket. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2014 (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR7-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Arp%2C%20D.%2C%20Spreitzenbarth%2C%20M.%2C%20Hubner%2C%20M.%2C%20Gascon%2C%20H.%2C%20Rieck%2C%20K.%3A%20Drebin%3A%20effective%20and%20explainable%20detection%20of%20android%20malware%20in%20your%20pocket.%20In%3A%2024th%20Annual%20Network%20and%20Distributed%20System%20Security%20Symposium%2C%20NDSS%202014%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="8."><p class="c-article-references__text" id="ref-CR8">Barrera, D., Kayacik, H.G., van Oorschot, P.C., Somayaji, A.: A methodology for empirical analysis of permission-based security models and its application to android. In: Proceedings of the 17th ACM Conference on Computer and Communications Security, pp. 73–84. ACM, New York (2010)</p><p class="c-article-references__links u-hide-print" id="ref-CR8-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Barrera%2C%20D.%2C%20Kayacik%2C%20H.G.%2C%20van%20Oorschot%2C%20P.C.%2C%20Somayaji%2C%20A.%3A%20A%20methodology%20for%20empirical%20analysis%20of%20permission-based%20security%20models%20and%20its%20application%20to%20android.%20In%3A%20Proceedings%20of%20the%2017th%20ACM%20Conference%20on%20Computer%20and%20Communications%20Security%2C%20pp.%2073%E2%80%9384.%20ACM%2C%20New%20York%20%282010%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="9."><p class="c-article-references__text" id="ref-CR9">Burguera, I., Zurutuza, U., Nadjm-Tehrani, S.: Crowdroid: Behavior-based malware detection system for android. In: Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices, SPSM ’11, pp. 15–26. ACM, New York (2011)</p><p class="c-article-references__links u-hide-print" id="ref-CR9-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Burguera%2C%20I.%2C%20Zurutuza%2C%20U.%2C%20Nadjm-Tehrani%2C%20S.%3A%20Crowdroid%3A%20Behavior-based%20malware%20detection%20system%20for%20android.%20In%3A%20Proceedings%20of%20the%201st%20ACM%20Workshop%20on%20Security%20and%20Privacy%20in%20Smartphones%20and%20Mobile%20Devices%2C%20SPSM%20%E2%80%9911%2C%20pp.%2015%E2%80%9326.%20ACM%2C%20New%20York%20%282011%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="10."><p class="c-article-references__text" id="ref-CR10">Cai, H., Meng, N., Ryder, B., Yao, D.: Droidcat: Effective android malware detection and categorization via app-level profiling. IEEE Transactions on Information Forensics and Security <b>14</b>(6), 1455–1470 (2019)</p><p class="c-article-references__links u-hide-print" id="ref-CR10-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TIFS.2018.2879302" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTIFS.2018.2879302" aria-label="CrossRef reference 10" data-doi="10.1109/TIFS.2018.2879302">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="https://scholar.google.com/scholar_lookup?&amp;title=Droidcat%3A%20Effective%20android%20malware%20detection%20and%20categorization%20via%20app-level%20profiling&amp;journal=IEEE%20Transactions%20on%20Information%20Forensics%20and%20Security&amp;volume=14&amp;issue=6&amp;pages=1455-1470&amp;publication_year=2019&amp;author=Cai%2CH&amp;author=Meng%2CN&amp;author=Ryder%2CB&amp;author=Yao%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="11."><p class="c-article-references__text" id="ref-CR11">Canfora, G., Mercaldo, F., Visaggio, C.A.: Mobile malware detection using op-code frequency histograms. In: Proc.of Int. Conf. on Security and Cryptography (SECRYPT) (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR11-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Canfora%2C%20G.%2C%20Mercaldo%2C%20F.%2C%20Visaggio%2C%20C.A.%3A%20Mobile%20malware%20detection%20using%20op-code%20frequency%20histograms.%20In%3A%20Proc.of%20Int.%20Conf.%20on%20Security%20and%20Cryptography%20%28SECRYPT%29%20%282015%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="12."><p class="c-article-references__text" id="ref-CR12">Cashman, D., Perer, A., Chang, R., Strobelt, H.: Ablate, variate, and contemplate: Visual analytics for discovering neural architectures. IEEE Trans. Visualization Comput. Graph. <b>26</b>(1), 863–873 (2020). <a href="https://doi.org/10.1109/TVCG.2019.2934261">https://doi.org/10.1109/TVCG.2019.2934261</a>
</p><p class="c-article-references__links u-hide-print" id="ref-CR12-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TVCG.2019.2934261" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTVCG.2019.2934261" aria-label="CrossRef reference 12" data-doi="10.1109/TVCG.2019.2934261">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="https://scholar.google.com/scholar_lookup?&amp;title=Ablate%2C%20variate%2C%20and%20contemplate%3A%20Visual%20analytics%20for%20discovering%20neural%20architectures&amp;journal=IEEE%20Trans.%20Visualization%20Comput.%20Graph.&amp;volume=26&amp;issue=1&amp;pages=863-873&amp;publication_year=2020&amp;author=Cashman%2CD&amp;author=Perer%2CA&amp;author=Chang%2CR&amp;author=Strobelt%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="13."><p class="c-article-references__text" id="ref-CR13">Chen, S., Xue, M., Tang, Z., Xu, L., Zhu, H.: Stormdroid: A streaminglized machine learning-based system for detecting android malware. In: Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security, ASIA CCS ’16, pp. 377–388. ACM, New York (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR13-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Chen%2C%20S.%2C%20Xue%2C%20M.%2C%20Tang%2C%20Z.%2C%20Xu%2C%20L.%2C%20Zhu%2C%20H.%3A%20Stormdroid%3A%20A%20streaminglized%20machine%20learning-based%20system%20for%20detecting%20android%20malware.%20In%3A%20Proceedings%20of%20the%2011th%20ACM%20on%20Asia%20Conference%20on%20Computer%20and%20Communications%20Security%2C%20ASIA%20CCS%20%E2%80%9916%2C%20pp.%20377%E2%80%93388.%20ACM%2C%20New%20York%20%282016%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="14."><p class="c-article-references__text" id="ref-CR14">Chen, W., Aspinall, D., Gordon, A.D., Sutton, C., Muttik, I.: More semantics more robust: improving android malware classifiers. In: Proceedings of the 9th ACM Conference on Security &amp; Privacy in Wireless and Mobile Networks, WiSec ’16, pp. 147–158. ACM, New York (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR14-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Chen%2C%20W.%2C%20Aspinall%2C%20D.%2C%20Gordon%2C%20A.D.%2C%20Sutton%2C%20C.%2C%20Muttik%2C%20I.%3A%20More%20semantics%20more%20robust%3A%20improving%20android%20malware%20classifiers.%20In%3A%20Proceedings%20of%20the%209th%20ACM%20Conference%20on%20Security%20%26%20Privacy%20in%20Wireless%20and%20Mobile%20Networks%2C%20WiSec%20%E2%80%9916%2C%20pp.%20147%E2%80%93158.%20ACM%2C%20New%20York%20%282016%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="15."><p class="c-article-references__text" id="ref-CR15">Ding, Y., Zhao, W., Wang, Z., Wang, L.: Automaticlly learning features of android apps using CNN. In: 2018 International Conference on Machine Learning and Cybernetics (ICMLC), vol. 1, pp. 331–336 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR15-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Ding%2C%20Y.%2C%20Zhao%2C%20W.%2C%20Wang%2C%20Z.%2C%20Wang%2C%20L.%3A%20Automaticlly%20learning%20features%20of%20android%20apps%20using%20CNN.%20In%3A%202018%20International%20Conference%20on%20Machine%20Learning%20and%20Cybernetics%20%28ICMLC%29%2C%20vol.%201%2C%20pp.%20331%E2%80%93336%20%282018%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="16."><p class="c-article-references__text" id="ref-CR16">Fan, M., Liu, J., Luo, X., Chen, K., Tian, Z., Zheng, Q., Liu, T.: Android malware familial classification and representative sample selection via frequent subgraph analysis. IEEE Trans. Inform. Forensics Secur. <b>13</b>(8), 1890–1905 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR16-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TIFS.2018.2806891" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTIFS.2018.2806891" aria-label="CrossRef reference 16" data-doi="10.1109/TIFS.2018.2806891">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="https://scholar.google.com/scholar_lookup?&amp;title=Android%20malware%20familial%20classification%20and%20representative%20sample%20selection%20via%20frequent%20subgraph%20analysis&amp;journal=IEEE%20Trans.%20Inform.%20Forensics%20Secur.&amp;volume=13&amp;issue=8&amp;pages=1890-1905&amp;publication_year=2018&amp;author=Fan%2CM&amp;author=Liu%2CJ&amp;author=Luo%2CX&amp;author=Chen%2CK&amp;author=Tian%2CZ&amp;author=Zheng%2CQ&amp;author=Liu%2CT">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="17."><p class="c-article-references__text" id="ref-CR17">Faruki, P., Laxmi, V., Bharmal, A., Gaur, M., Ganmoor, V.: Androsimilar: Robust signature for detecting variants of android malware. J. Infor. Secur. Appl. <b>22</b>, 66–80 (2015). Special issue on Security of Information and Networks</p><p class="c-article-references__links u-hide-print" id="ref-CR17-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Faruki%2C%20P.%2C%20Laxmi%2C%20V.%2C%20Bharmal%2C%20A.%2C%20Gaur%2C%20M.%2C%20Ganmoor%2C%20V.%3A%20Androsimilar%3A%20Robust%20signature%20for%20detecting%20variants%20of%20android%20malware.%20J.%20Infor.%20Secur.%20Appl.%2022%2C%2066%E2%80%9380%20%282015%29.%20Special%20issue%20on%20Security%20of%20Information%20and%20Networks">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="18."><p class="c-article-references__text" id="ref-CR18">Fawcett, C., Hoos, H.H.: Analysing differences between algorithm configurations through ablation. J. Heuristics <b>22</b>(4), 431–458 (2016).</p><p class="c-article-references__links u-hide-print" id="ref-CR18-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s10732-014-9275-9" data-track-action="CrossRef reference" href="https://doi.org/10.1007%2Fs10732-014-9275-9" aria-label="CrossRef reference 18" data-doi="10.1007/s10732-014-9275-9">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="https://scholar.google.com/scholar_lookup?&amp;title=Analysing%20differences%20between%20algorithm%20configurations%20through%20ablation&amp;journal=J.%20Heuristics&amp;volume=22&amp;issue=4&amp;pages=431-458&amp;publication_year=2016&amp;author=Fawcett%2CC&amp;author=Hoos%2CHH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="19."><p class="c-article-references__text" id="ref-CR19">Felt, A.P., Finifter, M., Chin, E., Hanna, S., Wagner, D.: A survey of mobile malware in the wild. In: Proceedings of the 1st ACM Workshop on Security and Privacy in Smartphones and Mobile Devices, pp. 3–14. ACM, New York (2011)</p><p class="c-article-references__links u-hide-print" id="ref-CR19-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Felt%2C%20A.P.%2C%20Finifter%2C%20M.%2C%20Chin%2C%20E.%2C%20Hanna%2C%20S.%2C%20Wagner%2C%20D.%3A%20A%20survey%20of%20mobile%20malware%20in%20the%20wild.%20In%3A%20Proceedings%20of%20the%201st%20ACM%20Workshop%20on%20Security%20and%20Privacy%20in%20Smartphones%20and%20Mobile%20Devices%2C%20pp.%203%E2%80%9314.%20ACM%2C%20New%20York%20%282011%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="20."><p class="c-article-references__text" id="ref-CR20">Felt, A.P., Greenwood, K., Wagner, D.: The effectiveness of application permissions. In: Proceedings of the 2Nd USENIX Conference on Web Application Development, p. 7 (2011)</p><p class="c-article-references__links u-hide-print" id="ref-CR20-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Felt%2C%20A.P.%2C%20Greenwood%2C%20K.%2C%20Wagner%2C%20D.%3A%20The%20effectiveness%20of%20application%20permissions.%20In%3A%20Proceedings%20of%20the%202Nd%20USENIX%20Conference%20on%20Web%20Application%20Development%2C%20p.%207%20%282011%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="21."><p class="c-article-references__text" id="ref-CR21">Fratantonio, Y., Qian, C., Chung, S.P., Lee, W.: Cloak and dagger: from two permissions to complete control of the UI feedback loop. In: 2017 IEEE Symposium on Security and Privacy (SP), pp. 1041–1057 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR21-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Fratantonio%2C%20Y.%2C%20Qian%2C%20C.%2C%20Chung%2C%20S.P.%2C%20Lee%2C%20W.%3A%20Cloak%20and%20dagger%3A%20from%20two%20permissions%20to%20complete%20control%20of%20the%20UI%20feedback%20loop.%20In%3A%202017%20IEEE%20Symposium%20on%20Security%20and%20Privacy%20%28SP%29%2C%20pp.%201041%E2%80%931057%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="22."><p class="c-article-references__text" id="ref-CR22">Garcia, J., Hammad, M., Malek, S.: Lightweight, obfuscation-resilient detection and family identification of android malware. ACM Trans. Softw. Eng. Methodol. <b>26</b>(3), 11:1–11:29 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR22-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Garcia%2C%20J.%2C%20Hammad%2C%20M.%2C%20Malek%2C%20S.%3A%20Lightweight%2C%20obfuscation-resilient%20detection%20and%20family%20identification%20of%20android%20malware.%20ACM%20Trans.%20Softw.%20Eng.%20Methodol.%2026%283%29%2C%2011%3A1%E2%80%9311%3A29%20%282018%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="23."><p class="c-article-references__text" id="ref-CR23">Gascon, H., Yamaguchi, F., Arp, D., Rieck, K.: Structural detection of android malware using embedded call graphs. In: Proceedings of the 2013 ACM Workshop on Artificial Intelligence and Security, AISec ’13, pp. 45–54. ACM, New York (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR23-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Gascon%2C%20H.%2C%20Yamaguchi%2C%20F.%2C%20Arp%2C%20D.%2C%20Rieck%2C%20K.%3A%20Structural%20detection%20of%20android%20malware%20using%20embedded%20call%20graphs.%20In%3A%20Proceedings%20of%20the%202013%20ACM%20Workshop%20on%20Artificial%20Intelligence%20and%20Security%2C%20AISec%20%E2%80%9913%2C%20pp.%2045%E2%80%9354.%20ACM%2C%20New%20York%20%282013%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="24."><p class="c-article-references__text" id="ref-CR24">Goodfellow, I., Bengio, Y., Courville, A.: Sequence modelling: recurrent and recursive nets. In: Deep Learning, pp. 371–372. MIT Press, Cambridge (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR24-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Goodfellow%2C%20I.%2C%20Bengio%2C%20Y.%2C%20Courville%2C%20A.%3A%20Sequence%20modelling%3A%20recurrent%20and%20recursive%20nets.%20In%3A%20Deep%20Learning%2C%20pp.%20371%E2%80%93372.%20MIT%20Press%2C%20Cambridge%20%282016%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="25."><p class="c-article-references__text" id="ref-CR25">Google: Android API Developer Reference. <a href="https://developer.android.com/reference/packages">https://developer.android.com/reference/packages</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="26."><p class="c-article-references__text" id="ref-CR26">Google: Dalvik. <a href="https://source.android.com/devices/tech/dalvik/dalvik-bytecode.html">https://source.android.com/devices/tech/dalvik/dalvik-bytecode.html</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="27."><p class="c-article-references__text" id="ref-CR27">Google: Google APIs for Android. <a href="https://developers.google.com/android/reference/packages">https://developers.google.com/android/reference/packages</a> Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="28."><p class="c-article-references__text" id="ref-CR28">Grace, M., Zhou, Y., Wang, Z., Jiang, X.: Systematic detection of capability leaks in stock android smartphones. In: NDSS Symposium 2012 (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR28-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Grace%2C%20M.%2C%20Zhou%2C%20Y.%2C%20Wang%2C%20Z.%2C%20Jiang%2C%20X.%3A%20Systematic%20detection%20of%20capability%20leaks%20in%20stock%20android%20smartphones.%20In%3A%20NDSS%20Symposium%202012%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="29."><p class="c-article-references__text" id="ref-CR29">GSMA: Mobile Scholar 2019 Finalists. <a href="https://vimeo.com/325173012">https://vimeo.com/325173012</a>. Accessed July 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="30."><p class="c-article-references__text" id="ref-CR30">Intel Developer Zone: Intel 64 and IA-32 Architectures Software Developer’s Manual: Volume 2. <a href="https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4">https://software.intel.com/en-us/download/intel-64-and-ia-32-architectures-sdm-combined-volumes-1-2a-2b-2c-2d-3a-3b-3c-3d-and-4</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="31."><p class="c-article-references__text" id="ref-CR31">Jerome, Q., Allix, K., State, R., Engel, T.: Using opcode-sequences to detect malicious android applications. In: 2014 IEEE Int. Conf. on Communications (ICC) (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR31-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Jerome%2C%20Q.%2C%20Allix%2C%20K.%2C%20State%2C%20R.%2C%20Engel%2C%20T.%3A%20Using%20opcode-sequences%20to%20detect%20malicious%20android%20applications.%20In%3A%202014%20IEEE%20Int.%20Conf.%20on%20Communications%20%28ICC%29%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="32."><p class="c-article-references__text" id="ref-CR32">Jesus Freke: Baksmali. <a href="https://github.com/JesusFreke/smali">https://github.com/JesusFreke/smali</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="33."><p class="c-article-references__text" id="ref-CR33">Kang, B., Kang, B., Kim, J., Im, E.G.: Android malware classification method: Dalvik bytecode frequency analysis. In: Proc. of the 2013 Research in Adaptive and Convergent Systems (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR33-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Kang%2C%20B.%2C%20Kang%2C%20B.%2C%20Kim%2C%20J.%2C%20Im%2C%20E.G.%3A%20Android%20malware%20classification%20method%3A%20Dalvik%20bytecode%20frequency%20analysis.%20In%3A%20Proc.%20of%20the%202013%20Research%20in%20Adaptive%20and%20Convergent%20Systems%20%282013%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="34."><p class="c-article-references__text" id="ref-CR34">Karbab, E.B., Debbabi, M., Derhab, A., Mouheb, D.: Maldozer: Automatic framework for android malware detection using deep learning. Digital Invest. <b>24</b>, S48–S59 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR34-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.diin.2018.01.007" data-track-action="CrossRef reference" href="https://doi.org/10.1016%2Fj.diin.2018.01.007" aria-label="CrossRef reference 34" data-doi="10.1016/j.diin.2018.01.007">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="https://scholar.google.com/scholar_lookup?&amp;title=Maldozer%3A%20Automatic%20framework%20for%20android%20malware%20detection%20using%20deep%20learning&amp;journal=Digital%20Invest.&amp;volume=24&amp;pages=S48-S59&amp;publication_year=2018&amp;author=Karbab%2CEB&amp;author=Debbabi%2CM&amp;author=Derhab%2CA&amp;author=Mouheb%2CD">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="35."><p class="c-article-references__text" id="ref-CR35">Kim, T., Kang, B., Rho, M., Sezer, S., Im, E.G.: A multimodal deep learning method for android malware detection using various features. IEEE Trans. Inform. Forensics Secur. <b>14</b>(3), 773–788 (2019).</p><p class="c-article-references__links u-hide-print" id="ref-CR35-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TIFS.2018.2866319" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTIFS.2018.2866319" aria-label="CrossRef reference 35" data-doi="10.1109/TIFS.2018.2866319">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="https://scholar.google.com/scholar_lookup?&amp;title=A%20multimodal%20deep%20learning%20method%20for%20android%20malware%20detection%20using%20various%20features&amp;journal=IEEE%20Trans.%20Inform.%20Forensics%20Secur.&amp;volume=14&amp;issue=3&amp;pages=773-788&amp;publication_year=2019&amp;author=Kim%2CT&amp;author=Kang%2CB&amp;author=Rho%2CM&amp;author=Sezer%2CS&amp;author=Im%2CEG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="36."><p class="c-article-references__text" id="ref-CR36">Kim, Y.: Convolutional neural networks for sentence classification. In: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1746–1751. Association for Computational Linguistics (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR36-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Kim%2C%20Y.%3A%20Convolutional%20neural%20networks%20for%20sentence%20classification.%20In%3A%20Proceedings%20of%20the%202014%20Conference%20on%20Empirical%20Methods%20in%20Natural%20Language%20Processing%20%28EMNLP%29%2C%20pp.%201746%E2%80%931751.%20Association%20for%20Computational%20Linguistics%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="37."><p class="c-article-references__text" id="ref-CR37">Lashkari, A.H., A.Kadir, A.F., Gonzalez, H., Mbah, K.F., A. Ghorbani, A.: Towards a network-based framework for android malware detection and characterization. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 233–23309 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR37-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Lashkari%2C%20A.H.%2C%20A.Kadir%2C%20A.F.%2C%20Gonzalez%2C%20H.%2C%20Mbah%2C%20K.F.%2C%20A.%20Ghorbani%2C%20A.%3A%20Towards%20a%20network-based%20framework%20for%20android%20malware%20detection%20and%20characterization.%20In%3A%202017%2015th%20Annual%20Conference%20on%20Privacy%2C%20Security%20and%20Trust%20%28PST%29%2C%20pp.%20233%E2%80%9323309%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="38."><p class="c-article-references__text" id="ref-CR38">Lee, W.Y., Saxe, J., Harang, R.: Seqdroid: Obfuscated android malware detection using stacked convolutional and recurrent neural networks. In: Deep Learning Applications for Cyber Security, pp. 197–210. Springer, Cham (2019)</p><p class="c-article-references__links u-hide-print" id="ref-CR38-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Lee%2C%20W.Y.%2C%20Saxe%2C%20J.%2C%20Harang%2C%20R.%3A%20Seqdroid%3A%20Obfuscated%20android%20malware%20detection%20using%20stacked%20convolutional%20and%20recurrent%20neural%20networks.%20In%3A%20Deep%20Learning%20Applications%20for%20Cyber%20Security%2C%20pp.%20197%E2%80%93210.%20Springer%2C%20Cham%20%282019%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="39."><p class="c-article-references__text" id="ref-CR39">Liu, X., Liu, J.: A two-layered permission-based android malware detection scheme. In: 2014 2nd IEEE Int. Conf. on Mobile Cloud Computing, Services and Engineering (MobileCloud) (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR39-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Liu%2C%20X.%2C%20Liu%2C%20J.%3A%20A%20two-layered%20permission-based%20android%20malware%20detection%20scheme.%20In%3A%202014%202nd%20IEEE%20Int.%20Conf.%20on%20Mobile%20Cloud%20Computing%2C%20Services%20and%20Engineering%20%28MobileCloud%29%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="40."><p class="c-article-references__text" id="ref-CR40">Liu, X., Liu, J.: A two-layered permission-based android malware detection scheme. In: 2nd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering (MobileCloud), pp. 142–148. IEEE, Piscataway (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR40-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Liu%2C%20X.%2C%20Liu%2C%20J.%3A%20A%20two-layered%20permission-based%20android%20malware%20detection%20scheme.%20In%3A%202nd%20IEEE%20International%20Conference%20on%20Mobile%20Cloud%20Computing%2C%20Services%2C%20and%20Engineering%20%28MobileCloud%29%2C%20pp.%20142%E2%80%93148.%20IEEE%2C%20Piscataway%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="41."><p class="c-article-references__text" id="ref-CR41">Ma, Z., Ge, H., Liu, Y., Zhao, M., Ma, J.: A combination method for android malware detection based on control flow graphs and machine learning algorithms. IEEE Access <b>7</b>, 21235–21245 (2019)</p><p class="c-article-references__links u-hide-print" id="ref-CR41-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/ACCESS.2019.2896003" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FACCESS.2019.2896003" aria-label="CrossRef reference 41" data-doi="10.1109/ACCESS.2019.2896003">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="https://scholar.google.com/scholar_lookup?&amp;title=A%20combination%20method%20for%20android%20malware%20detection%20based%20on%20control%20flow%20graphs%20and%20machine%20learning%20algorithms&amp;journal=IEEE%20Access&amp;volume=7&amp;pages=21235-21245&amp;publication_year=2019&amp;author=Ma%2CZ&amp;author=Ge%2CH&amp;author=Liu%2CY&amp;author=Zhao%2CM&amp;author=Ma%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="42."><p class="c-article-references__text" id="ref-CR42">Maiorca, D., Mercaldo, F., Giacinto, G., Visaggio, C.A., Martinelli, F.: R-packdroid: Api package-based characterization and detection of mobile ransomware. In: Proceedings of the Symposium on Applied Computing, SAC ’17, pp. 1718–1723. ACM, New York (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR42-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Maiorca%2C%20D.%2C%20Mercaldo%2C%20F.%2C%20Giacinto%2C%20G.%2C%20Visaggio%2C%20C.A.%2C%20Martinelli%2C%20F.%3A%20R-packdroid%3A%20Api%20package-based%20characterization%20and%20detection%20of%20mobile%20ransomware.%20In%3A%20Proceedings%20of%20the%20Symposium%20on%20Applied%20Computing%2C%20SAC%20%E2%80%9917%2C%20pp.%201718%E2%80%931723.%20ACM%2C%20New%20York%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="43."><p class="c-article-references__text" id="ref-CR43">Mariconti, E., Onwuzurike, L., Andriotis, P., Cristofaro, E.D., Ross, G.J., Stringhini, G.: Mamadroid: Detecting android malware by building Markov chains of behavioral models. In: 24th Annual Network and Distributed System Security Symposium, NDSS 2017 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR43-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Mariconti%2C%20E.%2C%20Onwuzurike%2C%20L.%2C%20Andriotis%2C%20P.%2C%20Cristofaro%2C%20E.D.%2C%20Ross%2C%20G.J.%2C%20Stringhini%2C%20G.%3A%20Mamadroid%3A%20Detecting%20android%20malware%20by%20building%20Markov%20chains%20of%20behavioral%20models.%20In%3A%2024th%20Annual%20Network%20and%20Distributed%20System%20Security%20Symposium%2C%20NDSS%202017%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="44."><p class="c-article-references__text" id="ref-CR44">Martinelli, F., Marulli, F., Mercaldo, F.: Evaluating convolutional neural network for effective mobile malware detection. Procedia Comput. Sci. <b>112</b>(C), 2372–2381 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR44-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.procs.2017.08.216" data-track-action="CrossRef reference" href="https://doi.org/10.1016%2Fj.procs.2017.08.216" aria-label="CrossRef reference 44" data-doi="10.1016/j.procs.2017.08.216">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="https://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20convolutional%20neural%20network%20for%20effective%20mobile%20malware%20detection&amp;journal=Procedia%20Comput.%20Sci.&amp;volume=112&amp;issue=C&amp;pages=2372-2381&amp;publication_year=2017&amp;author=Martinelli%2CF&amp;author=Marulli%2CF&amp;author=Mercaldo%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="45."><p class="c-article-references__text" id="ref-CR45">McLaughlin, N., Martinez del Rincon, J., Kang, B., Yerima, S., Miller, P., Sezer, S., Safaei, Y., Trickel, E., Zhao, Z., Doupé, A., Joon Ahn, G.: Deep android malware detection. In: Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy, CODASPY ’17. ACM, New York (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR45-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=McLaughlin%2C%20N.%2C%20Martinez%20del%20Rincon%2C%20J.%2C%20Kang%2C%20B.%2C%20Yerima%2C%20S.%2C%20Miller%2C%20P.%2C%20Sezer%2C%20S.%2C%20Safaei%2C%20Y.%2C%20Trickel%2C%20E.%2C%20Zhao%2C%20Z.%2C%20Doup%C3%A9%2C%20A.%2C%20Joon%20Ahn%2C%20G.%3A%20Deep%20android%20malware%20detection.%20In%3A%20Proceedings%20of%20the%20Seventh%20ACM%20on%20Conference%20on%20Data%20and%20Application%20Security%20and%20Privacy%2C%20CODASPY%20%E2%80%9917.%20ACM%2C%20New%20York%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="46."><p class="c-article-references__text" id="ref-CR46">Mikolov, T., Chen, K., Corrado, G.S., Dean, J.: Efficient estimation of word representations in vector space (2013). CoRR abs/1301.3781</p><p class="c-article-references__links u-hide-print" id="ref-CR46-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Mikolov%2C%20T.%2C%20Chen%2C%20K.%2C%20Corrado%2C%20G.S.%2C%20Dean%2C%20J.%3A%20Efficient%20estimation%20of%20word%20representations%20in%20vector%20space%20%282013%29.%20CoRR%20abs%2F1301.3781">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="47."><p class="c-article-references__text" id="ref-CR47">Millar, S., McLaughlin, N., Martinez del Rincon, J., Miller, P., Zhao, Z.: Dandroid: a multi-view discriminative adversarial network for obfuscated android malware detection. In: Proceedings of the Tenth ACM Conference on Data and Application Security and Privacy, CODASPY ’20 (2020)</p><p class="c-article-references__links u-hide-print" id="ref-CR47-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Millar%2C%20S.%2C%20McLaughlin%2C%20N.%2C%20Martinez%20del%20Rincon%2C%20J.%2C%20Miller%2C%20P.%2C%20Zhao%2C%20Z.%3A%20Dandroid%3A%20a%20multi-view%20discriminative%20adversarial%20network%20for%20obfuscated%20android%20malware%20detection.%20In%3A%20Proceedings%20of%20the%20Tenth%20ACM%20Conference%20on%20Data%20and%20Application%20Security%20and%20Privacy%2C%20CODASPY%20%E2%80%9920%20%282020%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="48."><p class="c-article-references__text" id="ref-CR48">Nix, R., Zhang, J.: Classification of android apps and malware using deep neural networks. In: 2017 International Joint Conference on Neural Networks, IJCNN 2017, Anchorage, AK, USA, May 14–19, 2017, pp. 1871–1878 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR48-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Nix%2C%20R.%2C%20Zhang%2C%20J.%3A%20Classification%20of%20android%20apps%20and%20malware%20using%20deep%20neural%20networks.%20In%3A%202017%20International%20Joint%20Conference%20on%20Neural%20Networks%2C%20IJCNN%202017%2C%20Anchorage%2C%20AK%2C%20USA%2C%20May%2014%E2%80%9319%2C%202017%2C%20pp.%201871%E2%80%931878%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="49."><p class="c-article-references__text" id="ref-CR49">Oak, R., Du, M., Yan, D., Takawale, H., Amit, I.: Malware detection on highly imbalanced data through sequence modeling. In: Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security, AISec’19, pp. 37–48. Association for Computing Machinery (2019)</p><p class="c-article-references__links u-hide-print" id="ref-CR49-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Oak%2C%20R.%2C%20Du%2C%20M.%2C%20Yan%2C%20D.%2C%20Takawale%2C%20H.%2C%20Amit%2C%20I.%3A%20Malware%20detection%20on%20highly%20imbalanced%20data%20through%20sequence%20modeling.%20In%3A%20Proceedings%20of%20the%2012th%20ACM%20Workshop%20on%20Artificial%20Intelligence%20and%20Security%2C%20AISec%E2%80%9919%2C%20pp.%2037%E2%80%9348.%20Association%20for%20Computing%20Machinery%20%282019%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="50."><p class="c-article-references__text" id="ref-CR50">Onwuzurike, L., Almeida, M., Mariconti, E., Blackburn, J., Stringhini, G., De Cristofaro, E.: A family of droids-android malware detection via behavioral modeling: Static vs dynamic analysis. In: 2018 16th Annual Conference on Privacy, Security and Trust (PST), pp. 1–10 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR50-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Onwuzurike%2C%20L.%2C%20Almeida%2C%20M.%2C%20Mariconti%2C%20E.%2C%20Blackburn%2C%20J.%2C%20Stringhini%2C%20G.%2C%20De%20Cristofaro%2C%20E.%3A%20A%20family%20of%20droids-android%20malware%20detection%20via%20behavioral%20modeling%3A%20Static%20vs%20dynamic%20analysis.%20In%3A%202018%2016th%20Annual%20Conference%20on%20Privacy%2C%20Security%20and%20Trust%20%28PST%29%2C%20pp.%201%E2%80%9310%20%282018%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="51."><p class="c-article-references__text" id="ref-CR51">Palo Alto Networks: WildFire malware analysis service. <a href="https://docs.paloaltonetworks.com/wildfire.html">https://docs.paloaltonetworks.com/wildfire.html</a>. Accessed April 2020</p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="52."><p class="c-article-references__text" id="ref-CR52">Peiravian, N., Zhu, X.: Machine learning for android malware detection using permission and api calls. In: 2013 IEEE 25th International Conference on Tools with Artificial Intelligence, pp. 300–305 (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR52-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Peiravian%2C%20N.%2C%20Zhu%2C%20X.%3A%20Machine%20learning%20for%20android%20malware%20detection%20using%20permission%20and%20api%20calls.%20In%3A%202013%20IEEE%2025th%20International%20Conference%20on%20Tools%20with%20Artificial%20Intelligence%2C%20pp.%20300%E2%80%93305%20%282013%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="53."><p class="c-article-references__text" id="ref-CR53">Peng, H., Gates, C., Sarma, B., Li, N., Qi, Y., Potharaju, R., Nita-Rotaru, C., Molloy, I.: Using probabilistic generative models for ranking risks of android apps. In: Proceedings of the 2012 ACM Conference on Computer and Communications Security, pp. 241–252. ACM, New York (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR53-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Peng%2C%20H.%2C%20Gates%2C%20C.%2C%20Sarma%2C%20B.%2C%20Li%2C%20N.%2C%20Qi%2C%20Y.%2C%20Potharaju%2C%20R.%2C%20Nita-Rotaru%2C%20C.%2C%20Molloy%2C%20I.%3A%20Using%20probabilistic%20generative%20models%20for%20ranking%20risks%20of%20android%20apps.%20In%3A%20Proceedings%20of%20the%202012%20ACM%20Conference%20on%20Computer%20and%20Communications%20Security%2C%20pp.%20241%E2%80%93252.%20ACM%2C%20New%20York%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="54."><p class="c-article-references__text" id="ref-CR54">Raff, E., Barker, J., Sylvester, J., Brandon, R., Catanzaro, B., Nicholas, C.K.: Malware detection by eating a whole exe. In: Workshops at the Thirty-Second AAAI Conference on Artificial Intelligence (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR54-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Raff%2C%20E.%2C%20Barker%2C%20J.%2C%20Sylvester%2C%20J.%2C%20Brandon%2C%20R.%2C%20Catanzaro%2C%20B.%2C%20Nicholas%2C%20C.K.%3A%20Malware%20detection%20by%20eating%20a%20whole%20exe.%20In%3A%20Workshops%20at%20the%20Thirty-Second%20AAAI%20Conference%20on%20Artificial%20Intelligence%20%282018%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="55."><p class="c-article-references__text" id="ref-CR55">Rosen, S., Qian, Z., Mao, Z.M.: Appprofiler: A flexible method of exposing privacy-related behavior in android applications to end users. In: Proceedings of the Third ACM Conference on Data and Application Security and Privacy, CODASPY ’13, pp. 221–232 (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR55-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Rosen%2C%20S.%2C%20Qian%2C%20Z.%2C%20Mao%2C%20Z.M.%3A%20Appprofiler%3A%20A%20flexible%20method%20of%20exposing%20privacy-related%20behavior%20in%20android%20applications%20to%20end%20users.%20In%3A%20Proceedings%20of%20the%20Third%20ACM%20Conference%20on%20Data%20and%20Application%20Security%20and%20Privacy%2C%20CODASPY%20%E2%80%9913%2C%20pp.%20221%E2%80%93232%20%282013%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="56."><p class="c-article-references__text" id="ref-CR56">Sanz, B., Santos, I., Laorden, C., Ugarte-Pedrero, X., Bringas, P.G., Marañón, G.A.: Puma: Permission usage to detect malware in android. In: CISIS/ICEUTE/SOCO Special Sessions 2012, Advances in Intelligent Systems and Computing, vol. 189, pp. 289–298. Springer, Berlin (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR56-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Sanz%2C%20B.%2C%20Santos%2C%20I.%2C%20Laorden%2C%20C.%2C%20Ugarte-Pedrero%2C%20X.%2C%20Bringas%2C%20P.G.%2C%20Mara%C3%B1%C3%B3n%2C%20G.A.%3A%20Puma%3A%20Permission%20usage%20to%20detect%20malware%20in%20android.%20In%3A%20CISIS%2FICEUTE%2FSOCO%20Special%20Sessions%202012%2C%20Advances%20in%20Intelligent%20Systems%20and%20Computing%2C%20vol.%20189%2C%20pp.%20289%E2%80%93298.%20Springer%2C%20Berlin%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="57."><p class="c-article-references__text" id="ref-CR57">Sanz, B., Santos, I., Laorden, C., X. Ugarte-Pedrero, P.G.B., Alvarez, G.: Puma: permission usage to detect malware in android. In: Int. Joint Conf. CISIS’12-ICEUTE’12-SOCO’12 (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR57-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Sanz%2C%20B.%2C%20Santos%2C%20I.%2C%20Laorden%2C%20C.%2C%20X.%20Ugarte-Pedrero%2C%20P.G.B.%2C%20Alvarez%2C%20G.%3A%20Puma%3A%20permission%20usage%20to%20detect%20malware%20in%20android.%20In%3A%20Int.%20Joint%20Conf.%20CISIS%E2%80%9912-ICEUTE%E2%80%9912-SOCO%E2%80%9912%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="58."><p class="c-article-references__text" id="ref-CR58">Saracino, A., Sgandurra, D., Dini, G., Martinelli, F.: Madam: Effective and efficient behavior-based android malware detection and prevention. IEEE Trans. Dependable Secure Comput. <b>15</b>(1), 83–97 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR58-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TDSC.2016.2536605" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTDSC.2016.2536605" aria-label="CrossRef reference 58" data-doi="10.1109/TDSC.2016.2536605">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="https://scholar.google.com/scholar_lookup?&amp;title=Madam%3A%20Effective%20and%20efficient%20behavior-based%20android%20malware%20detection%20and%20prevention&amp;journal=IEEE%20Trans.%20Dependable%20Secure%20Comput.&amp;volume=15&amp;issue=1&amp;pages=83-97&amp;publication_year=2018&amp;author=Saracino%2CA&amp;author=Sgandurra%2CD&amp;author=Dini%2CG&amp;author=Martinelli%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="59."><p class="c-article-references__text" id="ref-CR59">Shabtai, A., Kanonov, U., Elovici, Y., Glezer, C., Weiss, Y.: Andromaly: a behavioral malware detection framework for android devices. J. Intell. Inform. Syst. <b>38</b>(1), 161–190 (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR59-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s10844-010-0148-x" data-track-action="CrossRef reference" href="https://doi.org/10.1007%2Fs10844-010-0148-x" aria-label="CrossRef reference 59" data-doi="10.1007/s10844-010-0148-x">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 59" href="https://scholar.google.com/scholar_lookup?&amp;title=Andromaly%3A%20a%20behavioral%20malware%20detection%20framework%20for%20android%20devices&amp;journal=J.%20Intell.%20Inform.%20Syst.&amp;volume=38&amp;issue=1&amp;pages=161-190&amp;publication_year=2012&amp;author=Shabtai%2CA&amp;author=Kanonov%2CU&amp;author=Elovici%2CY&amp;author=Glezer%2CC&amp;author=Weiss%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="60."><p class="c-article-references__text" id="ref-CR60">Sharma, A., Dash, S.K.: Mining api calls and permissions for android malware detection. In: Cryptology and Network Security (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR60-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Sharma%2C%20A.%2C%20Dash%2C%20S.K.%3A%20Mining%20api%20calls%20and%20permissions%20for%20android%20malware%20detection.%20In%3A%20Cryptology%20and%20Network%20Security%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="61."><p class="c-article-references__text" id="ref-CR61">Skovoroda, A., Gamayunov, D.: Automated static analysis and classification of android malware using permission and api calls models. In: 2017 15th Annual Conference on Privacy, Security and Trust (PST), pp. 243–24309 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR61-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Skovoroda%2C%20A.%2C%20Gamayunov%2C%20D.%3A%20Automated%20static%20analysis%20and%20classification%20of%20android%20malware%20using%20permission%20and%20api%20calls%20models.%20In%3A%202017%2015th%20Annual%20Conference%20on%20Privacy%2C%20Security%20and%20Trust%20%28PST%29%2C%20pp.%20243%E2%80%9324309%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="62."><p class="c-article-references__text" id="ref-CR62">Su, X., Chuah, M.C., Tan, G.: Smartphone dual defense protection framework: detecting malicious applications in android markets. In: 2012 Eighth Int. Conf. on Mobile Ad-hoc and Sensor Networks (MSN) (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR62-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Su%2C%20X.%2C%20Chuah%2C%20M.C.%2C%20Tan%2C%20G.%3A%20Smartphone%20dual%20defense%20protection%20framework%3A%20detecting%20malicious%20applications%20in%20android%20markets.%20In%3A%202012%20Eighth%20Int.%20Conf.%20on%20Mobile%20Ad-hoc%20and%20Sensor%20Networks%20%28MSN%29%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="63."><p class="c-article-references__text" id="ref-CR63">Sun, M., Li, X., Lui, J.C.S., Ma, R.T.B., Liang, Z.: Monet: A user-oriented behavior-based malware variants detection system for android. IEEE Trans. Inform. Forensics Secur. <b>12</b>(5), 1103–1112 (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR63-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TIFS.2016.2646641" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTIFS.2016.2646641" aria-label="CrossRef reference 63" data-doi="10.1109/TIFS.2016.2646641">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="https://scholar.google.com/scholar_lookup?&amp;title=Monet%3A%20A%20user-oriented%20behavior-based%20malware%20variants%20detection%20system%20for%20android&amp;journal=IEEE%20Trans.%20Inform.%20Forensics%20Secur.&amp;volume=12&amp;issue=5&amp;pages=1103-1112&amp;publication_year=2017&amp;author=Sun%2CM&amp;author=Li%2CX&amp;author=Lui%2CJCS&amp;author=Ma%2CRTB&amp;author=Liang%2CZ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="64."><p class="c-article-references__text" id="ref-CR64">Tian, K., Yao, D., Ryder, B.G., Tan, G., Peng, G.: Detection of repackaged android malware with code-heterogeneity features. IEEE Trans. Dependable Secure Comput. <b>17</b>(1), 64–77 (2020)</p><p class="c-article-references__links u-hide-print" id="ref-CR64-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TDSC.2017.2745575" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTDSC.2017.2745575" aria-label="CrossRef reference 64" data-doi="10.1109/TDSC.2017.2745575">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="https://scholar.google.com/scholar_lookup?&amp;title=Detection%20of%20repackaged%20android%20malware%20with%20code-heterogeneity%20features&amp;journal=IEEE%20Trans.%20Dependable%20Secure%20Comput.&amp;volume=17&amp;issue=1&amp;pages=64-77&amp;publication_year=2020&amp;author=Tian%2CK&amp;author=Yao%2CD&amp;author=Ryder%2CBG&amp;author=Tan%2CG&amp;author=Peng%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="65."><p class="c-article-references__text" id="ref-CR65">Viola, P., Jones, M.J.: Rapid object detection using a boosted cascade of simple features. In: IEEE Conference on Computer Vision and Pattern Recognition, pp. 511–518. IEEE, Piscataway (2001)</p><p class="c-article-references__links u-hide-print" id="ref-CR65-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Viola%2C%20P.%2C%20Jones%2C%20M.J.%3A%20Rapid%20object%20detection%20using%20a%20boosted%20cascade%20of%20simple%20features.%20In%3A%20IEEE%20Conference%20on%20Computer%20Vision%20and%20Pattern%20Recognition%2C%20pp.%20511%E2%80%93518.%20IEEE%2C%20Piscataway%20%282001%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="66."><p class="c-article-references__text" id="ref-CR66">Wang, C., Dong, S., Zhao, X., Papanastasiou, G., Zhang, H., Yang, G.: Saliencygan: Deep learning semisupervised salient object detection in the fog of IoT. IEEE Trans. Ind. Inform. <b>16</b>(4), 2667–2676 (2020)</p><p class="c-article-references__links u-hide-print" id="ref-CR66-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TII.2019.2945362" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTII.2019.2945362" aria-label="CrossRef reference 66" data-doi="10.1109/TII.2019.2945362">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="https://scholar.google.com/scholar_lookup?&amp;title=Saliencygan%3A%20Deep%20learning%20semisupervised%20salient%20object%20detection%20in%20the%20fog%20of%20IoT&amp;journal=IEEE%20Trans.%20Ind.%20Inform.&amp;volume=16&amp;issue=4&amp;pages=2667-2676&amp;publication_year=2020&amp;author=Wang%2CC&amp;author=Dong%2CS&amp;author=Zhao%2CX&amp;author=Papanastasiou%2CG&amp;author=Zhang%2CH&amp;author=Yang%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="67."><p class="c-article-references__text" id="ref-CR67">Wang, S., Yan, Q., Chen, Z., Yang, B., Zhao, C., Conti, M.: Detecting android malware leveraging text semantics of network flows. IEEE Trans. Inform. Forensics Secur. <b>13</b>(5), 1096–1109 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR67-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TIFS.2017.2771228" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTIFS.2017.2771228" aria-label="CrossRef reference 67" data-doi="10.1109/TIFS.2017.2771228">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="https://scholar.google.com/scholar_lookup?&amp;title=Detecting%20android%20malware%20leveraging%20text%20semantics%20of%20network%20flows&amp;journal=IEEE%20Trans.%20Inform.%20Forensics%20Secur.&amp;volume=13&amp;issue=5&amp;pages=1096-1109&amp;publication_year=2018&amp;author=Wang%2CS&amp;author=Yan%2CQ&amp;author=Chen%2CZ&amp;author=Yang%2CB&amp;author=Zhao%2CC&amp;author=Conti%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="68."><p class="c-article-references__text" id="ref-CR68">Wei, F., Li, Y., Roy, S., Ou, X., Zhou, W.: Deep ground truth analysis of current android malware. In: International Conference on Detection of Intrusions and Malware, and Vulnerability Assessment (DIMVA’17), pp. 252–276. Springer, Bonn (2017)</p><p class="c-article-references__links u-hide-print" id="ref-CR68-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Wei%2C%20F.%2C%20Li%2C%20Y.%2C%20Roy%2C%20S.%2C%20Ou%2C%20X.%2C%20Zhou%2C%20W.%3A%20Deep%20ground%20truth%20analysis%20of%20current%20android%20malware.%20In%3A%20International%20Conference%20on%20Detection%20of%20Intrusions%20and%20Malware%2C%20and%20Vulnerability%20Assessment%20%28DIMVA%E2%80%9917%29%2C%20pp.%20252%E2%80%93276.%20Springer%2C%20Bonn%20%282017%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="69."><p class="c-article-references__text" id="ref-CR69">Wong, M., Lie, D.: Intellidroid: A targeted input generator for the dynamic analysis of android malware. In: Proceedings of the 2016 Symposium on Network and Distributed System Security (NDSS) (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR69-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Wong%2C%20M.%2C%20Lie%2C%20D.%3A%20Intellidroid%3A%20A%20targeted%20input%20generator%20for%20the%20dynamic%20analysis%20of%20android%20malware.%20In%3A%20Proceedings%20of%20the%202016%20Symposium%20on%20Network%20and%20Distributed%20System%20Security%20%28NDSS%29%20%282016%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="70."><p class="c-article-references__text" id="ref-CR70">Xu, K., Li, Y., Deng, R.H., Chen, K.: Deeprefiner: Multi-layer android malware detection system applying deep neural networks. In: 2018 IEEE European Symposium on Security and Privacy (Euro SP), pp. 473–487 (2018)</p><p class="c-article-references__links u-hide-print" id="ref-CR70-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Xu%2C%20K.%2C%20Li%2C%20Y.%2C%20Deng%2C%20R.H.%2C%20Chen%2C%20K.%3A%20Deeprefiner%3A%20Multi-layer%20android%20malware%20detection%20system%20applying%20deep%20neural%20networks.%20In%3A%202018%20IEEE%20European%20Symposium%20on%20Security%20and%20Privacy%20%28Euro%20SP%29%2C%20pp.%20473%E2%80%93487%20%282018%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="71."><p class="c-article-references__text" id="ref-CR71">Ye, Y., Hou, S., Chen, L., Lei, J., Wan, W., Wang, J., Xiong, Q., Shao, F.: Out-of-sample node representation learning for heterogeneous graph in real-time android malware detection. In: Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19, pp. 4150–4156 (2019)</p><p class="c-article-references__links u-hide-print" id="ref-CR71-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="https://scholar.google.com/scholar_lookup?&amp;title=Out-of-sample%20node%20representation%20learning%20for%20heterogeneous%20graph%20in%20real-time%20android%20malware%20detection&amp;journal=In%3A%20Twenty-Eighth%20International%20Joint%20Conference%20on%20Artificial%20Intelligence&amp;volume=IJCAI-19&amp;pages=4150-4156&amp;publication_year=2019&amp;author=Ye%2CY&amp;author=Hou%2CS&amp;author=Chen%2CL&amp;author=Lei%2CJ&amp;author=Wan%2CW&amp;author=Wang%2CJ&amp;author=Xiong%2CQ&amp;author=Shao%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="72."><p class="c-article-references__text" id="ref-CR72">Yerima, S., Sezer, S., McWilliams, G., Muttik, I.: A new android malware detection approach using bayesian classification. In: Advanced Information Networking and Applications (AINA), 2013 IEEE 27th International Conference on, pp. 121–128. IEEE, Piscataway (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR72-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Yerima%2C%20S.%2C%20Sezer%2C%20S.%2C%20McWilliams%2C%20G.%2C%20Muttik%2C%20I.%3A%20A%20new%20android%20malware%20detection%20approach%20using%20bayesian%20classification.%20In%3A%20Advanced%20Information%20Networking%20and%20Applications%20%28AINA%29%2C%202013%20IEEE%2027th%20International%20Conference%20on%2C%20pp.%20121%E2%80%93128.%20IEEE%2C%20Piscataway%20%282013%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="73."><p class="c-article-references__text" id="ref-CR73">Yerima, S.Y., Sezer, S., Muttik, I.: Android malware detection using parallel machine learning classifiers. In: Proceedings of the 2014 Eighth International Conference on Next Generation Mobile Apps, Services and Technologies, NGMAST ’14, pp. 37–42. IEEE Computer Society (2014)</p><p class="c-article-references__links u-hide-print" id="ref-CR73-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Yerima%2C%20S.Y.%2C%20Sezer%2C%20S.%2C%20Muttik%2C%20I.%3A%20Android%20malware%20detection%20using%20parallel%20machine%20learning%20classifiers.%20In%3A%20Proceedings%20of%20the%202014%20Eighth%20International%20Conference%20on%20Next%20Generation%20Mobile%20Apps%2C%20Services%20and%20Technologies%2C%20NGMAST%20%E2%80%9914%2C%20pp.%2037%E2%80%9342.%20IEEE%20Computer%20Society%20%282014%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="74."><p class="c-article-references__text" id="ref-CR74">Yerima, S.Y., Sezer, S., Muttik, I.: High accuracy android malware detection using ensemble learning. IET Inform. Secur. <b>9</b>(6), 313–320 (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR74-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1049/iet-ifs.2014.0099" data-track-action="CrossRef reference" href="https://doi.org/10.1049%2Fiet-ifs.2014.0099" aria-label="CrossRef reference 74" data-doi="10.1049/iet-ifs.2014.0099">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 74" href="https://scholar.google.com/scholar_lookup?&amp;title=High%20accuracy%20android%20malware%20detection%20using%20ensemble%20learning&amp;journal=IET%20Inform.%20Secur.&amp;volume=9&amp;issue=6&amp;pages=313-320&amp;publication_year=2015&amp;author=Yerima%2CSY&amp;author=Sezer%2CS&amp;author=Muttik%2CI">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="75."><p class="c-article-references__text" id="ref-CR75">Yuan, Z., Lu, Y., Xue, Y.: Droiddetector: android malware characterization and detection using deep learning. Tsinghua Sci. Technol. <b>21</b>(1), 114–123 (2016)</p><p class="c-article-references__links u-hide-print" id="ref-CR75-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TST.2016.7399288" data-track-action="CrossRef reference" href="https://doi.org/10.1109%2FTST.2016.7399288" aria-label="CrossRef reference 75" data-doi="10.1109/TST.2016.7399288">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="https://scholar.google.com/scholar_lookup?&amp;title=Droiddetector%3A%20android%20malware%20characterization%20and%20detection%20using%20deep%20learning&amp;journal=Tsinghua%20Sci.%20Technol.&amp;volume=21&amp;issue=1&amp;pages=114-123&amp;publication_year=2016&amp;author=Yuan%2CZ&amp;author=Lu%2CY&amp;author=Xue%2CY">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="76."><p class="c-article-references__text" id="ref-CR76">Zhang, X., Zhao, J., LeCun, Y.: Character-level convolutional networks for text classification. In: Proceedings of the 28th International Conference on Neural Information Processing Systems—Volume 1, NIPS’15, pp. 649–657. MIT Press, Cambridge (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR76-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Zhang%2C%20X.%2C%20Zhao%2C%20J.%2C%20LeCun%2C%20Y.%3A%20Character-level%20convolutional%20networks%20for%20text%20classification.%20In%3A%20Proceedings%20of%20the%2028th%20International%20Conference%20on%20Neural%20Information%20Processing%20Systems%E2%80%94Volume%201%2C%20NIPS%E2%80%9915%2C%20pp.%20649%E2%80%93657.%20MIT%20Press%2C%20Cambridge%20%282015%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="77."><p class="c-article-references__text" id="ref-CR77">Zhang, Y., Wallace, B.C.: A sensitivity analysis of (and practitioners’ guide to) convolutional neural networks for sentence classification. In: IJCNLP (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR77-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Zhang%2C%20Y.%2C%20Wallace%2C%20B.C.%3A%20A%20sensitivity%20analysis%20of%20%28and%20practitioners%E2%80%99%20guide%20to%29%20convolutional%20neural%20networks%20for%20sentence%20classification.%20In%3A%20IJCNLP%20%282015%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="78."><p class="c-article-references__text" id="ref-CR78">Zhou, Y., Jiang, X.: Dissecting android malware: characterization and evolution. In: 2012 IEEE Symposium on Security and Privacy (SP), pp. 95–109. IEEE, Piscataway (2012)</p><p class="c-article-references__links u-hide-print" id="ref-CR78-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Zhou%2C%20Y.%2C%20Jiang%2C%20X.%3A%20Dissecting%20android%20malware%3A%20characterization%20and%20evolution.%20In%3A%202012%20IEEE%20Symposium%20on%20Security%20and%20Privacy%20%28SP%29%2C%20pp.%2095%E2%80%93109.%20IEEE%2C%20Piscataway%20%282012%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="79."><p class="c-article-references__text" id="ref-CR79">Zhu, J., Wu, Z., Guan, Z., Chen, Z.: Api sequences based malware detection for android. In: 2015 IEEE 12th Intl Conf on Ubiquitous Intelligence and Computing and 2015 IEEE 12th Intl Conf on Autonomic and Trusted Computing and 2015 IEEE 15th Intl Conf on Scalable Computing and Communications and its associated Workshops (UIC-ATC-ScalCom), pp. 673–676 (2015)</p><p class="c-article-references__links u-hide-print" id="ref-CR79-links"><a data-track="click" data-track-action="google scholar reference" data-track-label="link" href="https://scholar.google.com/scholar?&amp;q=Zhu%2C%20J.%2C%20Wu%2C%20Z.%2C%20Guan%2C%20Z.%2C%20Chen%2C%20Z.%3A%20Api%20sequences%20based%20malware%20detection%20for%20android.%20In%3A%202015%20IEEE%2012th%20Intl%20Conf%20on%20Ubiquitous%20Intelligence%20and%20Computing%20and%202015%20IEEE%2012th%20Intl%20Conf%20on%20Autonomic%20and%20Trusted%20Computing%20and%202015%20IEEE%2015th%20Intl%20Conf%20on%20Scalable%20Computing%20and%20Communications%20and%20its%20associated%20Workshops%20%28UIC-ATC-ScalCom%29%2C%20pp.%20673%E2%80%93676%20%282015%29">
                        Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" data-counter="80."><p class="c-article-references__text" id="ref-CR80">Zonouz, S., Houmansadr, A., Berthier, R., Borisov, N., Sanders, W.: Secloud: a cloud-based comprehensive and lightweight security solution for smartphones. Comput. Secur. <b>37</b>, 215–227 (2013)</p><p class="c-article-references__links u-hide-print" id="ref-CR80-links"><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cose.2013.02.002" data-track-action="CrossRef reference" href="https://doi.org/10.1016%2Fj.cose.2013.02.002" aria-label="CrossRef reference 80" data-doi="10.1016/j.cose.2013.02.002">CrossRef</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 80" href="https://scholar.google.com/scholar_lookup?&amp;title=Secloud%3A%20a%20cloud-based%20comprehensive%20and%20lightweight%20security%20solution%20for%20smartphones&amp;journal=Comput.%20Secur.&amp;volume=37&amp;pages=215-227&amp;publication_year=2013&amp;author=Zonouz%2CS&amp;author=Houmansadr%2CA&amp;author=Berthier%2CR&amp;author=Borisov%2CN&amp;author=Sanders%2CW">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/978-3-031-15030-2_10?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 id="author-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Authors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff4"><p class="c-article-author-affiliation__address">Rapid 7 LLC, Boston, MA, USA</p><p class="c-article-author-affiliation__authors-list">Stuart Millar</p></li><li id="Aff5"><p class="c-article-author-affiliation__address">CSIT, Queen’s University Belfast, Belfast, Northern Ireland, UK</p><p class="c-article-author-affiliation__authors-list">Niall McLaughlin, Jesus Martinez del Rincon &amp; Paul Miller</p></li></ol><div class="u-js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Stuart-Millar"><span class="c-article-authors-search__title u-h3 js-search-name">Stuart Millar</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Stuart%20Millar" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Stuart%20Millar" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Stuart%20Millar%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Niall-McLaughlin"><span class="c-article-authors-search__title u-h3 js-search-name">Niall McLaughlin</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Niall%20McLaughlin" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Niall%20McLaughlin" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Niall%20McLaughlin%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Jesus_Martinez_del-Rincon"><span class="c-article-authors-search__title u-h3 js-search-name">Jesus Martinez del Rincon</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Jesus%20Martinez%20del%20Rincon" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Jesus%20Martinez%20del%20Rincon" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Jesus%20Martinez%20del%20Rincon%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Paul-Miller"><span class="c-article-authors-search__title u-h3 js-search-name">Paul Miller</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=Paul%20Miller" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Paul%20Miller" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Paul%20Miller%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:stuart_millar@rapid7.com">Stuart Millar </a>.</p></div></div></section><section aria-labelledby="editor-information" data-title="Editor information"><div class="c-article-section" id="editor-information-section"><h2 id="editor-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Editor information</h2><div class="c-article-section__content" id="editor-information-content"><h3 class="c-article__sub-heading" id="editor-affiliations">Editors and Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">JAMK University of Applied Sciences, Jyväskylä, Finland</p><p class="c-article-author-affiliation__authors-list">Tuomo Sipola</p></li><li id="Aff2"><p class="c-article-author-affiliation__address">JAMK University of Applied Sciences, Jyväskylä, Finland</p><p class="c-article-author-affiliation__authors-list">Tero Kokkonen</p></li><li id="Aff3"><p class="c-article-author-affiliation__address">JAMK University of Applied Sciences, Jyväskylä, Finland</p><p class="c-article-author-affiliation__authors-list">Mika Karjalainen</p></li></ol></div></div></section><section data-title="Rights and permissions" lang="en"><div class="c-article-section" id="rightslink-section"><h2 id="rightslink" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content"><p class="c-article-rights" data-test="rightslink-content"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?publisherName=SpringerNature&amp;orderBeanReset=true&amp;orderSource=SpringerLink&amp;title=Android%20Malware%20Detection%20Using%20Deep%20Learning&amp;author=Stuart%20Millar%2C%20Niall%20McLaughlin%2C%20Jesus%20Martinez%20del%20Rincon%20et%20al&amp;contentID=10.1007%2F978-3-031-15030-2_10&amp;copyright=The%20Author%28s%29%2C%20under%20exclusive%20license%20to%20Springer%20Nature%20Switzerland%20AG&amp;publication=eBook&amp;publicationDate=2023&amp;startPage=209&amp;endPage=246&amp;imprint=The%20Author%28s%29%2C%20under%20exclusive%20license%20to%20Springer%20Nature%20Switzerland%20AG">Reprints and Permissions</a></p></div></div></section><section data-title="Copyright information"><div class="c-article-section" id="copyright-information-section"><h2 id="copyright-information" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>Copyright information</h2><div class="c-article-section__content" id="copyright-information-content"><p>© 2023 The Author(s), under exclusive license to Springer Nature Switzerland AG</p></div></div></section><section aria-labelledby="chapter-info" data-title="About this chapter" lang="en"><div class="c-article-section" id="chapter-info-section"><h2 id="chapter-info" class="c-article-section__title js-section-title js-c-reading-companion-sections-item"><span class="c-article-section__title-number"> </span>About this chapter</h2><div class="c-article-section__content" id="chapter-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/978-3-031-15030-2_10" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/978-3-031-15030-2_10" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this chapter</h3><p class="c-bibliographic-information__citation" data-test="bibliographic-information__cite_this_chapter">Millar, S., McLaughlin, N., Rincon, J.M.d., Miller, P. (2023).  Android Malware Detection Using Deep Learning.

                     In: Sipola, T., Kokkonen, T., Karjalainen, M. (eds) Artificial Intelligence and Cybersecurity. Springer, Cham. https://doi.org/10.1007/978-3-031-15030-2_10</p><h3 class="c-bibliographic-information__download-citation u-mb-8 u-mt-16 u-hide-print">Download citation</h3><ul class="c-bibliographic-information__download-citation-list"><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article's citation as a .RIS file" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/978-3-031-15030-2_10?format=refman&amp;flavour=citation">.RIS<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></li><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article's citation as a .ENW file" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/978-3-031-15030-2_10?format=endnote&amp;flavour=citation">.ENW<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></li><li class="c-bibliographic-information__download-citation-item"><a data-test="citation-link" data-track="click" data-track-action="download chapter citation" data-track-label="link" data-track-external="" title="Download this article's citation as a .BIB file" rel="nofollow" href="https://citation-needed.springer-com.vtutest.mapmyaccess.com/v2/references/10.1007/978-3-031-15030-2_10?format=bibtex&amp;flavour=citation">.BIB<svg width="16" height="16" focusable="false" role="img" aria-hidden="true" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></li></ul><ul class="c-bibliographic-information__list u-mb-24" data-test="publication-history"><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p data-test="bibliographic-information__doi"><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value">https://doi.org/10.1007/978-3-031-15030-2_10</span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2022-08-01">01 August 2022</time></span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__publisher-name">
                            Publisher Name<span class="u-hide">: </span><span class="c-bibliographic-information__value">Springer, Cham</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__pisbn">
                                Print ISBN<span class="u-hide">: </span><span class="c-bibliographic-information__value">978-3-031-15029-6</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__eisbn">
                                Online ISBN<span class="u-hide">: </span><span class="c-bibliographic-information__value">978-3-031-15030-2</span></p></li><li class="c-bibliographic-information__list-item"><p data-test="bibliographic-information__package">eBook Packages<span class="u-hide">: </span><span class="c-bibliographic-information__multi-value"><a href="/search?facet-content-type=%22Book%22&amp;package=11645&amp;facet-start-year=2023&amp;facet-end-year=2023">Computer Science</a></span><span class="c-bibliographic-information__multi-value"><a href="/search?facet-content-type=%22Book%22&amp;package=43710&amp;facet-start-year=2023&amp;facet-end-year=2023">Computer Science (R0)</a></span></p></li></ul><div data-component="share-box"><div class="c-article-share-box u-display-none" hidden=""><h3 class="c-article__sub-heading">Share this chapter</h3><p class="c-article-share-box__description">Anyone you share the following link with will be able to read this content:</p><button class="js-get-share-url c-article-share-box__button" id="get-share-url" data-track="click" data-track-label="button" data-track-external="" data-track-action="get shareable link">Get shareable link</button><div class="js-no-share-url-container u-display-none" hidden=""><p class="js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info">Sorry, a shareable link is not currently available for this article.</p></div><div class="js-share-url-container u-display-none" hidden=""><p class="js-share-url c-article-share-box__only-read-input" id="share-url" data-track="click" data-track-label="button" data-track-action="select share url"></p><button class="js-copy-share-url c-article-share-box__button--link-like" id="copy-share-url" data-track="click" data-track-label="button" data-track-action="copy share url" data-track-external="">Copy to clipboard</button></div><p class="js-c-article-share-box__additional-info c-article-share-box__additional-info">
                                Provided by the Springer Nature SharedIt content-sharing initiative
                            </p></div></div><div data-component="chapter-info-list"></div></div></div></div></div></section>
                
                
    

            </div>
        </article>
    </main>

    <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="chapter">
        <aside>
            
            <div data-test="download-article-link-wrapper" class="js-context-bar-sticky-point-desktop">
                
            </div>

            <div data-test="editorial-summary">
                
            </div>

            <div class="c-reading-companion">
                <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">

                    

                    <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections"></div>
                    <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                    <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                </div>
            </div>
        </aside>
    </div>
</div>



        
    <footer class="app-footer" role="contentinfo" data-test="springerlink-footer">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" data-cc-action="preferences" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a href="https://support.springer-com.vtutest.mapmyaccess.com/en/support/home">FAQ</a></li>
                <li><a id="contactus-footer-link" href="https://support.springer-com.vtutest.mapmyaccess.com/en/support/solutions/articles/6000206179-contacting-us">Contact us</a></li>
                <li><a href="https://www-springer-com.vtutest.mapmyaccess.com/gp/shop/promo/affiliate/springer-nature">Affiliate program</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 65.2.72.189</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Ekalavya Institute of Technology Ummtturu Grama (3002776046)  - GSSS  Institute of Engineering Technology for Women (3001404442)  - Adichunchanagiri Institute of Technology (3000713187)  - Oxford School of Architecture (3003228838)  - Global Academy of Technology (3000709550)  - Acharya NRV School of Architecture (3002775918)  - Rajiv Gandhi Institute of Technology, Cholanagar (3002150375)  - Malik Sandal Institute of Arts and Architecture (3002776137)  - Vidya Vikas Institute of Engineerin &amp; Technology (3001405848)  - Dr. T. Thimmaiah Institute of Technology (3000782255)  - HMS Institute of Technology (3001432192)  - SJB Institute of Technology, Bengaluru. LIBRARY &amp; INFORMATION CENTRE (3000714778)  - Gopalan School of Architecture and Planning (3003228562)  - RNS School of Architecture (3003228860)  - Bangalore College of Engineering and Technology (3002082790)  - A.C.S. College of Engineering (3000189241)  - KS School of Architecture (3003228752)  - Sampoorna Institute of Technology Technology &amp; Research (3002776044)  - K.S. Institute of Technology (3000696842)  - Vemana Institute of Technology (3000975616)  - B.N.M. Institute of Technology (3000968235)  - Maharaja Institute of Technology Mysore (3001405874)  - Sri Krishna School of Engineering and Management (3001405842)  - Visvesvaraya Technological Univ Regional Centre Bangalore RHCS Layout (3002082616)  - HMS School of Architecture (3003228603)  - Smt Kamala &amp; Sri Venkappa Agadi College Of Engineering &amp; Tech (3001792059)  - J N N College of Engineering (3002159397)  - Reva Institute of Technology &amp; management (3001405802)  - Govt. Engineering College Karawar (3002776172)  - Govt. Engineering College Raichur (3003228564)  - BMS School of Architecture (3002543604)  - Veeerappa Nisty Engineering College (3002147687)  - Shri Madhwa Vadiraja Institute of Technology &amp; Management (3001404359)  - B.V.B. College of Engineering &amp; Technology (3000228645)  - Maharaja Institute of Technology (3003228755)  - Mangalore Institute of Technology and Engineering (3001405871)  - Shridevi Institute of Engineering &amp; Technology (3001433723)  - Jyothy Institute of Technology (3000968260)  - J.S.S. Academy of Technical Education,Bengaluru-560060 (2000695425)  - ATME College of Engeering (3001432091)  - Jain Institute of Technology (3001405882)  - Visvesvaraya Technological University (3001338151)  - CITY Engineering College (3001405725)  - Achutha Institute of Technology (3002776190)  - Cambridge Institute of Technology (3001432117)  - Maratha Mandal&#x27;s Engineering College (3000718804)  - C. Byre Gowda Institute of Technology (3001405714)  - Visvesvaraya Technological Univ Regional Centre Gulbarga (3002082618)  - Shaikh College of Engineering and Technology Bhootramatti (3002082742)  - Best School of Architecture (3002776152)  - Shah-Shib College of Engineering (3002776019)  - KCT Engineering College (3003228750)  - KNS Institute of Technology (3001432199)  - Sri Venkateshwara College Of Engineering (3000707092)  - Vijaya Vittal Institute of Technology Dodda Gubbi Post (3002776201)  - Biluru Gurubasava Mahaswamiji institute of Technology Mudhol (3001405887)  - M.S. Ramaiah Inst. of Technology M.S. Ramaiah Nagar, MSRIT Post (2000628096)  - M.S Engineering College (3001404440)  - Canara Engineering College (3000705224)  - Vivekananda Iinstitute of Technology (3001404542)  - VTU Trial Account (3001412227)  - Visvesvaraya Technological Univ Regional Centre Mudenhalli (3002082670)  - Nitte School of Architecture (3003228778)  - K.L.E. Society&#x27;s College of Engineering &amp; Technology (3000711034)  - SECAB Institute of Engg. &amp; Technology (3002146695)  - P N S Women’s Institute of Technology (3002775981)  - Sri Sai Ram College of Engineering (3001665689)  - AICTE Mechanical Engineering e-Jour (3000684257)  - Nitte Meenakshi Institute of Technology (3001445249)  - Tontadarya College Of Engineering (3000716983)  - PA College of Engineering (3001432235)  - Dayananda Sagar Academy of Technology  and Management (3001405888)  - Bangalore Technological Institute (3001404478)  - Dr. M V Shetty Institute of Technology ( MVSIT) (3001405868)  - Lingaraj Appa Engineering College Bidar (3002111260)  - Dr Ambedkar Institute of Technology (3001208153)  - VSM Shri Somashekhar R Kotiwale Institute of Technology (3002082746)  - BLDEA’s College of Engineering &amp; Technology (3001405716)  - P.E.S. INSTITUTE OF  TECHNOLOGY BSK 3rd Stage (3000698719)  - Aakar Academy of Architecture (3002776196)  - S D M Institute of Techology Ujire (3001404384)  - PES Institute of Technology (3000699622)  - S L N College of Engineering (3002082718)  - Govt. Engineering College Krishnarajapete Mandya (3002165735)  - PES University (3000696456)  - Vidyavardhaka College of Engg, Mysore,Gokulam,3rd Stage (3000576101)  - Bheemanna Khandre Institute of Technology (3001404544)  - (Nitte) Nmam Institute Of Technology (3001404609)  - G Madegowda Institute of Technology (3002082713)  - East West Institute Of Technology (3000705258)  - Coorg Institute  of Technology (3001404299)  - Sri Revana Siddeshwara Institute of Technology (3000715101)  - Ghousia College of Engineering (3000735822)  - BGS School of Architecture and Planning (3003228519)  - SDM College of Engineering &amp; Technology (2000348493)  - Anjuman Institute of Technology and Management (3001404388)  - Alpha College of Engineering (3002772045)  - Visvesvaraya Technological Univ Regional Centre Mysore Hanchya (3002082619)  - BMS College of Architecture (3003240288)  - SAHYADRI COLLEGE OF ENGINEERING AND MANAGEMENT (3001028409)  - Govt. Engineering College Kushalanagar (3002776114)  - S.J.C INSTIUTE OF TECHNOLOGY (3000699561)  - NDRK Institute of Technology (3002083165)  - Don Bosco Institute of Technology (3000721776)  - APS College of Engineering (3000739515)  - Adithya Academy of Architecture and Design (3003228468)  - RR Institute of Technology (3001432298)  - S J B School of Architecture &amp; Planning BGS Health &amp; Education (3002776206)  - SRINIVAS INSTITUTE OF TECHNOLOGY (3000707094)  - Islamiah Institute of Technology (3002082777)  - SHREE DEVI INSTITUTE OF TECHNOLOGY (3000715069)  - Bapuji Institute of Engineering and Technology (3002082679)  - Govt. Engineering College Haveri (3002776159)  - Sri Vinayaka Institute of Technology (3003228832)  - Proudadevaraya Institute of Technology (3000714739)  - Vishwanathrao Deshpande Institute Of Technology (3000697745)  - M V J College of Engineering (3001405829)  - Bearys Institute of Technology (3001404573)  - Rural Institute of Tech (3002083168)  - National Institute of Engineering (3002094895)  - Kalpataru Institute of Technology (3001404576)  - Mangalore Marine College &amp; Technology (3002776005)  - Yenepoya Institute of Technology (3003228830)  - BMS College of Engineering (2000607897)  - K.V.G. College of Engineering (3000728303)  - AMC Engineering College (3001445178)  - Amruta Institute of Engineering &amp; Management Sciences (3000697620)  - Girijabai Sail Inst of Technology (3001432142)  - KS School of Engineering and Management (3000977954)  - Govt. Engineering College Ramanagara (3002082715)  - AICTE Electrical &amp; Electronics &amp; Computer Science Engineering (3000684219)  - R N S Institute of Technology (3001405884)  - BMS Institute of Technology and Management (3000705221)  - Angadi School of Architecture (3003876978)  - Alvas Institute of Engineering and Technology (3001404444)  - S.J.M. Institute of Technology NH 4 bye-pass (3001990314)  - THE OXFORD COLLEGE OF ENGINEERING (3000707115)  - PNS Institute of Technology (3001432269)  - Srinivas School of Engineering (3001405787)  - Moodlakatte Institute of Technology (3001405878)  - East West College of Engineering (3003228549)  - Channabasaveshwara Institute of Technology (3000716092)  - J A G M Institute of Technology Jagmit (3001405742)  - KLE Institution of Technology (3001405767)  - S.T.J Institute of Technology (3001405721)  - Sir M. Visvesvaraya Institute of Technology (2000607911)  - Anjuman Engineering College (3002082771)  - Appa Institute of Engineering and Technology (3002082675)  - Sri Venkateswara College of Engineering (2000505021)  - Acharya Institute Of Technology (3000699587)  - R.T.E. Society’s Rural Engineering College (3000710330)  - Government Engineering College (3003954215)  - RL Jalappa Institute of Technology (3000721794)  - Impact School of Architecture (3002776156)  - Jain College of Engineering Technology &amp; Research (3003957506)  - Sahyadri Institute of Technology N.H. 48 Adyar Mandalore (3000176277)  - Siddaganga Institute of Technology (2000651910)  - Basaveshwar Engineering College (Autonomous), Bagalkote (2000478248)  - RAO BAHADUR Y MAHABALES WARAPPA ENGINEERING COLLEGE (3000712631)  - Brindavan College of Engineering (3000773449)  - Nagarjuna College of Engineering and Technology (3001405865)  - SEA College of Engineering and Technology (3001929083)  - Akshaya Institute of Technology (3001432049)  - JAIN COLLEGE OF ENGINEERING             Tipu Sultan Nagar,  Hunchanatti ineering (3001405864)  - Nandi Institute of Technology, and Management Science (3002082779)  - Bangalore Institute of Technology (2000596435)  - Govt. Tool Room &amp; Training Center (3003228566)  - Basava Kalyan Engineering College (3002082711)  - SAPTHAGIRI COLLEGE OF ENGINEERING (3000715177)  - KLE Dr. M.S.Sheshgiri College of Engineering and Technology (3001434859)  - RR School of Architecture (3003228794)  - Bahubali College of Engineering (3002082775)  - AJ Institute of Engineering and Technology (3003228511)  - Dayananda Sagar College Of Engineering (3000696439)  - Sri Basaveshwara Inst of Technology (3003876849)  - Atria Institute of Technology (3002163984)  - Shri Dharmasthala Manjunatheshwar Educational Society (3003228819)  - New Horizon College of Engineering (3000722494)  - Govt. Tool Room &amp; Training Centre (3002775949)  - Jnana Vikas Institute of Technology (3000993881)  - H K B K Institute of Technology (3002772049)  - Cauvery Institute of Technology (3001404355)  - B V B College of Engg &amp; Tech Librarian (3001386340)  - Gov&#x27;t Engineering College (3002776176)  - Mysore School of Architecture (3003228757)  - RV College of Architecture (3003228797)  - KLE’s College of Engineering &amp; Tech (3002776130)  - Wadiyar Centre for Architecture (3003228863)  - University B.D.College of Engineering (3001405807)  - Vivekananda College of Engineering &amp; Technology (3000612157)  - IMPACT College of Engineering  and Applied Science (3001405748)  - Navodaya Institute of Technology (3002111485)  - B.T.L Institute of Technology and Management (3001405723)  - Rural Engineering College Hulkoti (3003228810)  - Hirasugar Institute of Technology (3000725070)  - Mysore Royal Institute of Technology (3003228759)  - UBDT College of Engineering (3000983198)  - Angadi Institute of Technology &amp; Management (3001405839)  - Sir. M. V. School of Architecture (3003228835)  - Jain College of Engineering and Technology (3003228728)  - Saint Joseph College of Engg. &amp; Tech. (3002776002)  - Govt. Engineering College Chamarajanagar (3002776048)  - BGS Institue of Technology (3001432111)  - Visvesvaraya Technological University (3001405906)  - Dr. Sri Sri Sri Shivakumara Mahaswamy College of Engineering (3003228546)  - Government Engineering College (3003954218)  - Bearys Environmental Architecure Design Science (3003228515)  - PDA College Of Engineering (3001405744)  - SSETSG balekundri Institute of Technology (3001405861)  - Shri Pillappa College of Engineerin (3001405901)  - Karavali Institute of Technology (3002776000)  - Shetty Institute of Technology (3003228814)  - PES College of Engineering (3000735856)  - Govt. Engineering College,Hassan (3002776009)  - Mysore College of Engineering and Management (3003228771)  - Yellamma Dasappa Institute of Tech. Raghuvanahalli (3002775890)  - R.V. College of Engineering (2000596485)  - KBN College of Engineering (3001405729)  - Sri Vidya Vinayaka Institute of Technology (3001405778)  - Nadgir Institute of Engineering and Technology (3003228775)  - Sri Krishna Institute of Technology (3001881404)  - Govt Sri Krishnarajendra Silver Jubilee Technological Institute (3001942872)  - Government Engineering College (3003952242)  - Gogte Institute of Technology (3000697987)  - Gopalan College of Engineering and Management (3001404571)  - T. John Institute of Technology (3000742166)  - RAJARAJESWARI COLLEGE OF ENGINEERING (3000711821)  - AGMR College of Engineering &amp; Technology Hubli (3001404578)  - Ballari Institute of Technology and Management (3000711790)  - Guru Nanak Dev Engineering College (3003228569)  - CMR Institute of Technology (3001404386)  - East Point College of Engineering and Technology (3000993859)  - Malnad College of Engineering (3000698707)  - Sambhram Institute of Technology (3001405826)  - Mahaswamy College of Engineering (3002775938)  - Nie Institute of Technology (3000716879)  - Rajeev Institute of Technology (3001404547)  - INDEST-AICTE-Level III (3000168247)  - Cambridge institute of technology (3002775895)  - St. Josephs College Of Engineering And Technology (Palai) (3000699641)  - G.M.Institute Of Technology (3000725056) 
        </p>

    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-b88bf25ad4.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2023 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
    </footer>



    </div>

    
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 10 10" xmlns="http://www.w3.org/2000/svg">
            <path d="m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z" fill="currentColor" fill-rule="evenodd" transform="matrix(0 -1 1 0 0 10)"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-success" viewBox="0 0 18 18">
            <path d="M9 0a9 9 0 110 18A9 9 0 019 0zm3.486 4.982l-4.718 5.506L5.14 8.465a.991.991 0 00-1.423.133 1.06 1.06 0 00.13 1.463l3.407 2.733a1 1 0 001.387-.133l5.385-6.334a1.06 1.06 0 00-.116-1.464.991.991 0 00-1.424.119z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-down" viewBox="0 0 16 16">
            <path d="m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z" fill-rule="evenodd" transform="matrix(0 1 -1 0 11 1)"/>
        </symbol>
        <symbol id="icon-warning" viewBox="0 0 18 18">
            <path d="m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-plus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-minus" viewBox="0 0 16 16">
            <path d="m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-error" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-springer-arrow-left">
            <path d="M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z"/>
        </symbol>
        <symbol id="icon-springer-arrow-right">
            <path d="M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z"/>
        </symbol>
        <symbol id="icon-arrow-up" viewBox="0 0 16 16">
            <path d="m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-tick" viewBox="0 0 24 24">
            <path d="M12,24 C5.372583,24 0,18.627417 0,12 C0,5.372583 5.372583,0 12,0 C18.627417,0 24,5.372583 24,12 C24,18.627417 18.627417,24 12,24 Z M7.657,10.79 C7.45285634,10.6137568 7.18569967,10.5283283 6.91717333,10.5534259 C6.648647,10.5785236 6.40194824,10.7119794 6.234,10.923 C5.87705269,11.3666969 5.93445559,12.0131419 6.364,12.387 L10.261,15.754 C10.6765468,16.112859 11.3037113,16.0695601 11.666,15.657 L17.759,8.713 C18.120307,8.27302248 18.0695334,7.62621189 17.644,7.248 C17.4414817,7.06995024 17.1751516,6.9821166 16.9064461,7.00476032 C16.6377406,7.02740404 16.3898655,7.15856958 16.22,7.368 L10.768,13.489 L7.657,10.79 Z"/>
        </symbol>
        <symbol id="icon-expand-image" viewBox="0 0 18 18">
            <path d="m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-close" viewBox="0 0 16 16">
            <path d="m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z" fill="currentColor" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-chevron-right" viewBox="0 0 7 12">
            <path d="M2.782 5 .3 2.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 0 1 1.417 0l4.176 4.177a1.001 1.001 0 0 1 0 1.416l-4.176 4.177a.991.991 0 0 1-1.4.016A1 1 0 0 1 .3 9.481L2.782 7l1.013-.998L2.782 5Z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-checklist-banner" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 56.69 56.69" style="enable-background:new 0 0 56.69 56.69" xml:space="preserve">
            <path style="fill:none" d="M0 0h56.69v56.69H0z"/><defs><path id="a" d="M0 .74h56.72v55.24H0z"/></defs><clipPath id="b"><use xlink:href="#a" style="overflow:visible"/></clipPath><path d="M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round"/><path d="M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5" style="clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round"/>
        </symbol>
        <symbol id="icon-get-ftr" viewBox="0 0 24 24">
            <path fill="#0D8D8A" fill-rule="nonzero" d="M24 12c0 6.627-5.373 12-12 12-2.102 0-4.078-.54-5.796-1.49l1.485-1.484A9.96 9.96 0 0 0 12 22c5.523 0 10-4.477 10-10a9.96 9.96 0 0 0-.974-4.31l1.484-1.486A11.946 11.946 0 0 1 24 12ZM12 0c2.102 0 4.079.54 5.797 1.49l-1.485 1.485A9.96 9.96 0 0 0 12 2C6.477 2 2 6.477 2 12c0 1.544.35 3.006.975 4.312L1.49 17.797A11.946 11.946 0 0 1 0 12C0 5.373 5.373 0 12 0Z"/>
            <circle cx="12" cy="12" r="5.333" fill="#096A73"/>
        </symbol>
        <symbol id="icon-github" viewBox="0 0 100 100">
            <path fill-rule="evenodd" clip-rule="evenodd" d="M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z" fill="#24292f"/>
        </symbol>
        <symbol id="icon-search-filter" viewBox="0 0 29 29">
            <defs><style>.cls-1{fill:none;}</style></defs><title/><g data-name="Layer 2" id="Layer_2"><path d="M28,9H11a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/><path d="M7,9H4A1,1,0,0,1,4,7H7A1,1,0,0,1,7,9Z"/><path d="M21,17H4a1,1,0,0,1,0-2H21a1,1,0,0,1,0,2Z"/><path d="M11,25H4a1,1,0,0,1,0-2h7a1,1,0,0,1,0,2Z"/><path d="M9,11a3,3,0,1,1,3-3A3,3,0,0,1,9,11ZM9,7a1,1,0,1,0,1,1A1,1,0,0,0,9,7Z"/><path d="M23,19a3,3,0,1,1,3-3A3,3,0,0,1,23,19Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,23,15Z"/><path d="M13,27a3,3,0,1,1,3-3A3,3,0,0,1,13,27Zm0-4a1,1,0,1,0,1,1A1,1,0,0,0,13,23Z"/><path d="M28,17H25a1,1,0,0,1,0-2h3a1,1,0,0,1,0,2Z"/><path d="M28,25H15a1,1,0,0,1,0-2H28a1,1,0,0,1,0,2Z"/></g><g id="frame"><rect class="cls-1" height="32" width="32"/></g>
        </symbol>
        <symbol id="icon-book" viewBox="0 0 18 18">
            <path
                d="m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z"
                fill-rule="evenodd"/>
        </symbol>
        <symbol id="icon-submit-open" viewBox="0 0 16 17">
            <path d="M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z" fill-rule="nonzero"/>
        </symbol>
    </svg>

<script async src='https://link-springer-com.vtutest.mapmyaccess.com/MapMyAccessProxy.js'></script></body>
</html>